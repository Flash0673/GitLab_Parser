,project_id,commit_id,commit_message,files_changed,lines_inserted,lines_deleted,diff,target,changes,add,del,web_url,Imports added,Imports deleted,path,file_new,file_past,count_py_files,array_past,array_new,key_words_code_added,key_words_code_deleted,key_words
0,155,edd6ebce,"Merge branch 'master' into 'update-package-versions-2'

# Conflicts:
#   README.md",9,174,21,"[{'new_path': 'FFMPEGFrames.py', 'diff': '@@ -14,7 +14,7 @@ class FFMPEGFrames:\n             os.makedirs(self.output)\n \n         query = ""ffmpeg -i "" + input + "" -vf fps="" + \\\n-            str(fps) + "" "" + self.output + ""output%02d.png""\n+            str(fps) + "" "" + self.output + ""/output%02d.png""\n         response = subprocess.Popen(\n             query, shell=True, stdout=subprocess.PIPE).stdout.read()\n         s = str(response).encode(\'utf-8\')\n'}, {'new_path': 'README.md', 'diff': '@@ -13,3 +13,6 @@ To run this script, you need to:\n     ```\n     This command will convert video into the series of images with 1 frame per second.\n     After that, array of images are going to be parsed into .txt file as text.\n+    ```bash\n+        python3 main.py -a files/videoplayback.mp4 output.txt\n+    ```\n'}, {'new_path': 'SpeechRecognition.py', 'diff': '@@ -1,4 +1,3 @@\n-\n # coding: utf-8\n \n # ### Функции пред- и постобработки\n@@ -10,37 +9,45 @@ from pydub import AudioSegment\n from scipy.io import wavfile\n import os\n import numpy as np\n+import speech_recognition as sr\n+import argparse\n+\n \n \n+parser = argparse.ArgumentParser(description=\'wav_to_txt\')\n+parser.add_argument(\'wav_path\', help=\'Path to .wav audio file\')\n+parser.add_argument(\'out_path\', help=\'Path to output .txt file\')\n # Делим аудио (wav) на короткие части, сохраняем в папку tmp_slices\n \n # In[2]:\n \n \n+\n+\n def divide_audio(audio_src, slice_length_ms=3000, overlap_ms=500):\n     audio = AudioSegment.from_file(audio_src, ""wav"")\n \n-    slices = np.arange(0, len(audio)-overlap_ms, slice_length_ms-overlap_ms)\n-    \n+    slices = np.arange(0, len(audio) - overlap_ms, slice_length_ms - overlap_ms)\n+\n     path = ""tmp_slices""\n     os.mkdir(path)\n     audio_slices_src = []\n     i = 0\n-    \n+\n     for start, end in zip(slices[:-1], slices[1:]):\n-        slice_ = audio[start : end+overlap_ms]\n+        slice_ = audio[start: end + overlap_ms]\n         # сохраняем кусочки аудио\n         slice_name = ""tmp_slices\\slice{0}.wav"".format(i)\n         audio_slices_src.append(slice_name)\n         slice_.export(slice_name, format=""wav"")\n-        i+=1\n-        \n+        i += 1\n+\n     if len(audio) - end > overlap_ms:\n-        slice_ = audio[end : len(audio)]\n+        slice_ = audio[end: len(audio)]\n         slice_name = ""tmp_slices\\slice{0}.wav"".format(i)\n         audio_slices_src.append(slice_name)\n         slice_.export(slice_name, format=""wav"")\n-        \n+\n     return audio_slices_src\n \n \n@@ -62,27 +69,27 @@ def delete_tmp_slices(audio_slices_src):\n \n def combine_text(text_array):\n     result_text = \'\'\n-    \n+\n     prev_splited = []\n-    \n+\n     for text in text_array:\n         processed_text = \'\'\n-        \n+\n         splited = text.lower().split()\n-        \n+\n         j = 0\n         while j < min(len(splited), len(prev_splited)):\n-            if splited[j] != prev_splited[-1-j]:\n+            if splited[j] != prev_splited[-1 - j]:\n                 break\n             j += 1\n-        \n+\n         for i in range(j, len(splited)):\n             processed_text += splited[i] + \' \'\n-        \n+\n         result_text += processed_text\n-        \n-        prev_splited = splited        \n-        \n+\n+        prev_splited = splited\n+\n     return result_text\n \n \n@@ -99,9 +106,6 @@ def combine_text(text_array):\n # In[5]:\n \n \n-import speech_recognition as sr\n-\n-\n # Распознавание без учета шума\n \n # In[6]:\n@@ -109,35 +113,35 @@ import speech_recognition as sr\n \n def recognize_no_noise(audio_src):\n     r = sr.Recognizer()\n-    \n+\n     # делим аудио на части\n     chunks_src = divide_audio(audio_src)\n     # распознаем каждую часть\n     text_array = []\n     for chunk_src in chunks_src:\n         a = sr.AudioFile(chunk_src)\n-        #print(\'analyzing \', chunk_src)\n+        # print(\'analyzing \', chunk_src)\n         with a as source:\n             audio = r.record(source)\n         try:\n             text_chunk = r.recognize_google(audio, language=\'ru\')\n             text_array.append(text_chunk)\n-            #print(\'!\',text_chunk)\n+            # print(\'!\',text_chunk)\n         except:\n             pass\n     # объединяем распознанные тексты\n     text = combine_text(text_array)\n-    \n+\n     # удаляем ненужные файлы\n     delete_tmp_slices(chunks_src)\n-    \n+\n     return text\n \n \n # In[7]:\n \n \n-#print(recognize_no_noise(\'audio/test1.wav\'))\n+# print(recognize_no_noise(\'audio/test1.wav\'))\n \n \n # Распознавание с учетом шума: уровень шума определяется автоматически\n@@ -147,35 +151,35 @@ def recognize_no_noise(audio_src):\n \n def recognize_with_noise(audio_src):\n     r = sr.Recognizer()\n-    \n+\n     # делим аудио на части\n     chunks_src = divide_audio(audio_src)\n     # распознаем каждую часть\n     text_array = []\n     for chunk_src in chunks_src:\n         a = sr.AudioFile(chunk_src)\n-        #print(\'analyzing \', chunk_src)\n+        # print(\'analyzing \', chunk_src)\n         with a as source:\n-            r.adjust_for_ambient_noise(source) # учитываем шум\n+            r.adjust_for_ambient_noise(source)  # учитываем шум\n             audio = r.record(source)\n         try:\n             text_chunk = r.recognize_google(audio, language=\'ru\')\n             text_array.append(text_chunk)\n-            #print(text_chunk)\n+            # print(text_chunk)\n         except:\n             pass\n     # объединяем распознанные тексты\n     text = combine_text(text_array)\n     # удаляем ненужные файлы\n     delete_tmp_slices(chunks_src)\n-    \n+\n     return text\n \n \n # In[9]:\n \n \n-#print(recognize_with_noise(\'audio/test1.wav\'))\n+# print(recognize_with_noise(\'audio/test1.wav\'))\n \n \n # Итоговая функция распознавания, в которой выбирается наилучший вариант распознавания\n@@ -184,18 +188,19 @@ def recognize_with_noise(audio_src):\n \n \n def wav_to_txt(audio_src, out_txt_src):\n-    \n+    print(f""Speech recognition started"")\n     no_noise_txt = recognize_no_noise(audio_src)\n     noise_txt = recognize_with_noise(audio_src)\n-    \n+\n     text = no_noise_txt\n     if len(noise_txt.split()) > len(text.split()):\n         text = noise_txt\n-        \n+\n     # записываем в файл\n     out = open(out_txt_src, \'a\')\n     out.write(text)\n     out.close()\n+    print(f""Speech recognition finished"")\n \n \n # Для интеграции в main\n@@ -203,17 +208,12 @@ def wav_to_txt(audio_src, out_txt_src):\n # In[12]:\n \n \n-#wav_to_txt(\'audio/test1.wav\', \'TEXT.txt\')\n+# wav_to_txt(\'audio/test1.wav\', \'TEXT.txt\')\n \n \n # In[ ]:\n \n \n-parser = argparse.ArgumentParser(description=\'wav_to_txt\')\n-parser.add_argument(\'wav_path\', help=\'Path to .wav audio file\')\n-parser.add_argument(\'out_path\', help=\'Path to output .txt file\')\n-\n if __name__ == \'__main__\':\n     args = parser.parse_args()\n     wav_to_txt(args.wav_path, args.out_path)\n-\n'}, {'new_path': 'SpeechRecognition_mp3_to_text.py', 'diff': '@@ -1,132 +0,0 @@\n-<<<<<<< HEAD:SpeechRecognition_2_mp3_to_text.py\n-# -*- coding: utf-8 -*-\n-=======\n-# coding: utf-8\n->>>>>>> origin/KateShestakova:SpeechRecognition_mp3_to_text.py\n-\n-# ### Функции пред- и постобработки\n-\n-from pydub import AudioSegment\n-from pydub.utils import make_chunks\n-import os\n-\n-import speech_recognition as sr\n-\n-# Перевод из формата mp3 в wav\n-\n-def mp3_to_wav(mp3_src, wav_src):\n-    sound = AudioSegment.from_mp3(mp3_src)\n-    sound.export(wav_src, format=""wav"")\n-\n-# Делим аудио (wav) на короткие части, сохраняем в папку tmp_chunks\n-\n-def divide_audio(audio_src, chunk_length_ms):\n-    audio = AudioSegment.from_file(audio_src, ""wav"") \n-    chunks = make_chunks(audio, chunk_length_ms)\n-    \n-    path = ""tmp_chunks""\n-    os.mkdir(path)\n-    \n-    chunks_src = []\n-    for i, chunk in enumerate(chunks):\n-        chunk_name = ""tmp_chunks\\chunk{0}.wav"".format(i)\n-        chunks_src.append(chunk_name)\n-        chunk.export(chunk_name, format=""wav"")\n-        \n-    return chunks_src\n-\n-\n-# Удаляем папку tmp_chunks с частями аудио\n-\n-def delete_tmp_chunks(chunks_src):\n-    for chunk in chunks_src:\n-        os.remove(chunk)\n-    os.rmdir(\'tmp_chunks\')\n-\n-# Соединяем распознанный по частям текст\n-\n-def combine_text(text_array):\n-    result_text = \'\'\n-    for text in text_array:\n-        result_text += text + \' \'\n-    return result_text\n-\n-\n-# ### Распознавание речи\n-\n-# Библиотека SpeechRecognition ( https://pypi.org/project/SpeechRecognition/ )\n-# \n-# Используется распознавание при помощи Google Speech Recognition\n-# \n-# Распознавание текста происходит непрерывно, даже когда речи нет, а есть только шум. Если распознать какие-то слова не удается, программа выдает ошибку. Поэтому нужно делить аудио на короткие части и распознавать их отдельно.\n-# \n-# Список языковых кодов для Google Speech Recognition: https://www.science.co.il/language/Locale-codes.php\n-\n-\n-# Распознавание без учета шума\n-\n-def recognize(audio_src):\n-    # делим аудио на части\n-    chunks_src = divide_audio(audio_src, 3000)\n-    # распознаем каждую часть\n-    text_array = []\n-    for chunk_src in chunks_src:\n-        a = sr.AudioFile(chunk_src)\n-        with a as source:\n-            audio = r.record(source)\n-        try:\n-            text_array.append(r.recognize_google(audio, language=\'ru\'))\n-        except:\n-            pass\n-    # объединяем распознанные тексты\n-    text = combine_text(text_array)\n-    # удаляем ненужные файлы\n-    delete_tmp_chunks(chunks_src)\n-    \n-    return text\n-\n-# Распознавание с учетом шума: уровень шума определяется автоматически\n-\n-def recognize_with_noise(audio_src):\n-    # делим аудио на части\n-    chunks_src = divide_audio(audio_src, 3000)\n-    # распознаем каждую часть\n-    text_array = []\n-    for chunk_src in chunks_src:\n-        a = sr.AudioFile(chunk_src)\n-        with a as source:\n-            r.adjust_for_ambient_noise(source) # учитываем шум\n-            audio = r.record(source)\n-        try:\n-            text_chunk = r.recognize_google(audio, language=\'ru\')\n-            text_array.append(text_chunk)\n-            #print(text_chunk)\n-        except:\n-            pass\n-    # объединяем распознанные тексты\n-    text = combine_text(text_array)\n-    # удаляем ненужные файлы\n-    delete_tmp_chunks(chunks_src)\n-    \n-    return text\n-\n-# итоговая функция распознавания\n-\n-def wav_to_txt(path):\n-    r = sr.Recognizer()\n-    recognize_with_noise(path)\n-    \n-# для интеграции в main\n-\n-parser = argparse.ArgumentParser(description=\'wav_to_txt\')\n-parser.add_argument(\'wav_path\', help=\'Path to .wav audio file\')\n-parser.add_argument(\'out_path\', help=\'Path to output text file\')\n-\n-if __name__ == \'__main__\':\n-    args = parser.parse_args()\n-    txt = wav_to_txt(args.wav_path)\n-    \n-    f = open(args.out_path, ""a"")\n-    f.write(txt) \n-    f.close() \n-\n'}, {'new_path': 'TextFromPicture.py', 'diff': ""@@ -6,6 +6,7 @@ import sys\n import os \n import argparse\n \n+\n parser = argparse.ArgumentParser(description='OCR')\n parser.add_argument('in_filenames', help='Input filenames')\n parser.add_argument('out_filename', help='Output filename')\n@@ -16,8 +17,8 @@ def Pic2Txt(listImg, outfile):\n \t# Iterate through all the image\n \tfor img in listImg: \n \n-\t\t# Recognize the text as string in image using pytesserct \n-\t\ttext = str(((pytesseract.image_to_string(cv2.imread(img),lang = 'eng+rus')))) \n+\t\t# Recognize the text as string in image using pytesserct\n+\t\ttext = str(((pytesseract.image_to_string(cv2.imread(img),lang = 'eng+rus'))))\n \n \t\t# The recognized text is stored in variable text \n \t\t# Any string processing may be applied on text \n""}, {'new_path': 'main.py', 'diff': '@@ -7,7 +7,8 @@ import socket\n from TextFromPicture import Pic2Txt\n import FFMPEGFrames\n import glob\n-\n+from SpeechRecognition import wav_to_txt\n+import video_to_audio\n \n def main():\n     parser = argparse.ArgumentParser()\n@@ -43,7 +44,20 @@ def main():\n \n         f = FFMPEGFrames.FFMPEGFrames(""images/"")\n         f.extract_frames(input, fps)\n-        Pic2Txt(glob.glob(""images/*.png""), output)\n+        Pic2Txt(glob.glob(f.output + ""/*.png""), output)\n+    elif str(sys.argv[1] in [\'-a\', \'--audio\']):\n+        parser.add_argument(\'-a\', \'--audio\', action=\'store_true\')\n+        parser.add_argument(""in_filename"", help=\'Input filename\')\n+        parser.add_argument(\'out_filename\', help=\'Output filename\')\n+        args = vars(parser.parse_args())\n+\n+        input = args[""in_filename""]\n+        output = args[""out_filename""]\n+\n+        f = video_to_audio.video_to_audio(""/WAVs"")\n+        f.video_to_wav(input)\n+        wav_to_txt(f.output, output)\n+\n     else:\n         print(error_msg)\n \n'}, {'new_path': 'mp3_to_wav.py', 'diff': '@@ -0,0 +1,37 @@\n+import subprocess\n+import argparse\n+import os\n+\n+parser = argparse.ArgumentParser(description=\'mp3_to_wav\')\n+parser.add_argument(\'in_mp3\', help=\'Input .mp3 file\')\n+\n+def mp3_to_wav(mp3_path):\n+    wavs_path = ""WAVs""\n+    wav_path = wavs_path + ""/output.wav""\n+    if not os.path.exists(wavs_path):\n+        os.mkdir(wavs_path)\n+\n+    subprocess.run([""ffmpeg"",\n+                ""-loglevel"",\n+                ""quiet"",\n+                ""-hide_banner"",\n+                ""-y"",\n+                ""-i"",\n+                mp3_path,\n+                ""-write_id3v1"",\n+                ""1"",\n+                ""-id3v2_version"",\n+                ""3"",\n+                ""-q:a"",\n+                ""0"",\n+                ""-map"",\n+                ""a"",\n+                wav_path],\n+               stderr=subprocess.DEVNULL,\n+               stdout=subprocess.DEVNULL,\n+               stdin=subprocess.PIPE)\n+\n+\n+if __name__ == \'__main__\':\n+    args = parser.parse_args()\n+    mp3_to_wav(args.in_mp3)\n\\ No newline at end of file\n'}, {'new_path': 'video2mp3.py', 'diff': '@@ -0,0 +1,40 @@\n+import subprocess\n+import argparse\n+import os\n+\n+parser = argparse.ArgumentParser(description=\'video2mp3\')\n+parser.add_argument(\'video_path\', help=\'Path to video file\')\n+\n+\n+def video2mp3(video_path):\n+    mp3s_path = ""mp3s""\n+    mp3_path = mp3s_path + ""/output.mp3""\n+    if not os.path.exists(mp3s_path):\n+        os.mkdir(mp3s_path)\n+\n+    subprocess.run([""ffmpeg"",\n+                ""-loglevel"",\n+                ""quiet"",\n+                ""-hide_banner"",\n+                ""-y"",\n+                ""-i"",\n+                video_path,\n+                ""-write_id3v1"",\n+                ""1"",\n+                ""-id3v2_version"",\n+                ""3"",\n+                ""-q:a"",\n+                ""0"",\n+                ""-map"",\n+                ""a"",\n+                mp3_path],\n+               stderr=subprocess.DEVNULL,\n+               stdout=subprocess.DEVNULL,\n+               stdin=subprocess.PIPE)\n+\n+\n+if __name__ == \'__main__\':\n+    #path = ""files/videoplayback.mp4""\n+    #video2mp3(path)\n+    args = parser.parse_args()\n+    video2mp3(args.video_path)\n'}, {'new_path': 'video_to_audio.py', 'diff': '@@ -0,0 +1,81 @@\n+import subprocess\n+import argparse\n+import os\n+import time\n+\n+parser = argparse.ArgumentParser(description=\'video_to_wav\')\n+parser.add_argument(\'video_path\', help=\'Path to video file\')\n+\n+\n+class video_to_audio:\n+\n+    def __init__(self, output):\n+        self.output = output\n+\n+    def video_to_wav(self, video_path):\n+        wavs_path = ""WAVs""\n+        name = video_path.split(\'/\')[-1].split(\'.\')[0]\n+        self.output = wavs_path + ""/"" + name + "".wav""\n+        if not os.path.exists(wavs_path):\n+            os.mkdir(wavs_path)\n+            print(f""Directory created"")\n+\n+        subprocess.run([""ffmpeg"",\n+                ""-loglevel"",\n+                ""debug"",\n+                ""-hide_banner"",\n+                ""-y"",\n+                ""-i"",\n+                video_path,\n+                ""-vn"",\n+                ""-sn"",\n+                ""-ar"",\n+                ""44100"",\n+                ""-q:a"",\n+                ""0"",\n+                ""-map"",\n+                ""a"",\n+                self.output],\n+               stderr=subprocess.DEVNULL,\n+               stdout=subprocess.DEVNULL,\n+               stdin=subprocess.PIPE)\n+\n+        print(f""Convertation to .wav finished!"")\n+\n+\n+#if __name__ == \'__main__\':\n+    #path = ""files/videoplayback.mp4""\n+    #video_to_wav(path)\n+    #args = parser.parse_args()\n+    #video_to_wav(args.video_path)\n+\n+\n+    def video2mp3(self, video_path):\n+        mp3s_path = ""mp3s""\n+        name = video_path.split(\'/\')[-1].split(\'.\')[0]\n+        self.output = mp3s_path + ""/"" + name + "".mp3""\n+        if not os.path.exists(mp3s_path):\n+            os.mkdir(mp3s_path)\n+            print(f""Directory created"")\n+\n+        subprocess.run([""ffmpeg"",\n+                ""-loglevel"",\n+                ""debug"",\n+                ""-hide_banner"",\n+                ""-y"",\n+                ""-i"",\n+                video_path,\n+                ""-write_id3v1"",\n+                ""1"",\n+                ""-id3v2_version"",\n+                ""3"",\n+                ""-q:a"",\n+                ""0"",\n+                ""-map"",\n+                ""a"",\n+                self.output],\n+               stderr=subprocess.DEVNULL,\n+               stdout=subprocess.DEVNULL,\n+               stdin=subprocess.PIPE)\n+\n+        print(f""Convertation to .mp3 finished!"")\n\\ No newline at end of file\n'}]", ;,"[{'diff': '@@ -14,7 +14,7 @@ class FFMPEGFrames:\n             os.makedirs(self.output)\n \n         query = ""ffmpeg -i "" + input + "" -vf fps="" + \\\n-            str(fps) + "" "" + self.output + ""output%02d.png""\n+            str(fps) + "" "" + self.output + ""/output%02d.png""\n         response = subprocess.Popen(\n             query, shell=True, stdout=subprocess.PIPE).stdout.read()\n         s = str(response).encode(\'utf-8\')\n'}, {'diff': '@@ -13,3 +13,6 @@ To run this script, you need to:\n     ```\n     This command will convert video into the series of images with 1 frame per second.\n     After that, array of images are going to be parsed into .txt file as text.\n+    ```bash\n+        python3 main.py -a files/videoplayback.mp4 output.txt\n+    ```\n'}, {'diff': '@@ -1,4 +1,3 @@\n-\n # coding: utf-8\n \n # ### Функции пред- и постобработки\n@@ -10,37 +9,45 @@ from pydub import AudioSegment\n from scipy.io import wavfile\n import os\n import numpy as np\n+import speech_recognition as sr\n+import argparse\n+\n \n \n+parser = argparse.ArgumentParser(description=\'wav_to_txt\')\n+parser.add_argument(\'wav_path\', help=\'Path to .wav audio file\')\n+parser.add_argument(\'out_path\', help=\'Path to output .txt file\')\n # Делим аудио (wav) на короткие части, сохраняем в папку tmp_slices\n \n # In[2]:\n \n \n+\n+\n def divide_audio(audio_src, slice_length_ms=3000, overlap_ms=500):\n     audio = AudioSegment.from_file(audio_src, ""wav"")\n \n-    slices = np.arange(0, len(audio)-overlap_ms, slice_length_ms-overlap_ms)\n-    \n+    slices = np.arange(0, len(audio) - overlap_ms, slice_length_ms - overlap_ms)\n+\n     path = ""tmp_slices""\n     os.mkdir(path)\n     audio_slices_src = []\n     i = 0\n-    \n+\n     for start, end in zip(slices[:-1], slices[1:]):\n-        slice_ = audio[start : end+overlap_ms]\n+        slice_ = audio[start: end + overlap_ms]\n         # сохраняем кусочки аудио\n         slice_name = ""tmp_slices\\slice{0}.wav"".format(i)\n         audio_slices_src.append(slice_name)\n         slice_.export(slice_name, format=""wav"")\n-        i+=1\n-        \n+        i += 1\n+\n     if len(audio) - end > overlap_ms:\n-        slice_ = audio[end : len(audio)]\n+        slice_ = audio[end: len(audio)]\n         slice_name = ""tmp_slices\\slice{0}.wav"".format(i)\n         audio_slices_src.append(slice_name)\n         slice_.export(slice_name, format=""wav"")\n-        \n+\n     return audio_slices_src\n \n \n@@ -62,27 +69,27 @@ def delete_tmp_slices(audio_slices_src):\n \n def combine_text(text_array):\n     result_text = \'\'\n-    \n+\n     prev_splited = []\n-    \n+\n     for text in text_array:\n         processed_text = \'\'\n-        \n+\n         splited = text.lower().split()\n-        \n+\n         j = 0\n         while j < min(len(splited), len(prev_splited)):\n-            if splited[j] != prev_splited[-1-j]:\n+            if splited[j] != prev_splited[-1 - j]:\n                 break\n             j += 1\n-        \n+\n         for i in range(j, len(splited)):\n             processed_text += splited[i] + \' \'\n-        \n+\n         result_text += processed_text\n-        \n-        prev_splited = splited        \n-        \n+\n+        prev_splited = splited\n+\n     return result_text\n \n \n@@ -99,9 +106,6 @@ def combine_text(text_array):\n # In[5]:\n \n \n-import speech_recognition as sr\n-\n-\n # Распознавание без учета шума\n \n # In[6]:\n@@ -109,35 +113,35 @@ import speech_recognition as sr\n \n def recognize_no_noise(audio_src):\n     r = sr.Recognizer()\n-    \n+\n     # делим аудио на части\n     chunks_src = divide_audio(audio_src)\n     # распознаем каждую часть\n     text_array = []\n     for chunk_src in chunks_src:\n         a = sr.AudioFile(chunk_src)\n-        #print(\'analyzing \', chunk_src)\n+        # print(\'analyzing \', chunk_src)\n         with a as source:\n             audio = r.record(source)\n         try:\n             text_chunk = r.recognize_google(audio, language=\'ru\')\n             text_array.append(text_chunk)\n-            #print(\'!\',text_chunk)\n+            # print(\'!\',text_chunk)\n         except:\n             pass\n     # объединяем распознанные тексты\n     text = combine_text(text_array)\n-    \n+\n     # удаляем ненужные файлы\n     delete_tmp_slices(chunks_src)\n-    \n+\n     return text\n \n \n # In[7]:\n \n \n-#print(recognize_no_noise(\'audio/test1.wav\'))\n+# print(recognize_no_noise(\'audio/test1.wav\'))\n \n \n # Распознавание с учетом шума: уровень шума определяется автоматически\n@@ -147,35 +151,35 @@ def recognize_no_noise(audio_src):\n \n def recognize_with_noise(audio_src):\n     r = sr.Recognizer()\n-    \n+\n     # делим аудио на части\n     chunks_src = divide_audio(audio_src)\n     # распознаем каждую часть\n     text_array = []\n     for chunk_src in chunks_src:\n         a = sr.AudioFile(chunk_src)\n-        #print(\'analyzing \', chunk_src)\n+        # print(\'analyzing \', chunk_src)\n         with a as source:\n-            r.adjust_for_ambient_noise(source) # учитываем шум\n+            r.adjust_for_ambient_noise(source)  # учитываем шум\n             audio = r.record(source)\n         try:\n             text_chunk = r.recognize_google(audio, language=\'ru\')\n             text_array.append(text_chunk)\n-            #print(text_chunk)\n+            # print(text_chunk)\n         except:\n             pass\n     # объединяем распознанные тексты\n     text = combine_text(text_array)\n     # удаляем ненужные файлы\n     delete_tmp_slices(chunks_src)\n-    \n+\n     return text\n \n \n # In[9]:\n \n \n-#print(recognize_with_noise(\'audio/test1.wav\'))\n+# print(recognize_with_noise(\'audio/test1.wav\'))\n \n \n # Итоговая функция распознавания, в которой выбирается наилучший вариант распознавания\n@@ -184,18 +188,19 @@ def recognize_with_noise(audio_src):\n \n \n def wav_to_txt(audio_src, out_txt_src):\n-    \n+    print(f""Speech recognition started"")\n     no_noise_txt = recognize_no_noise(audio_src)\n     noise_txt = recognize_with_noise(audio_src)\n-    \n+\n     text = no_noise_txt\n     if len(noise_txt.split()) > len(text.split()):\n         text = noise_txt\n-        \n+\n     # записываем в файл\n     out = open(out_txt_src, \'a\')\n     out.write(text)\n     out.close()\n+    print(f""Speech recognition finished"")\n \n \n # Для интеграции в main\n@@ -203,17 +208,12 @@ def wav_to_txt(audio_src, out_txt_src):\n # In[12]:\n \n \n-#wav_to_txt(\'audio/test1.wav\', \'TEXT.txt\')\n+# wav_to_txt(\'audio/test1.wav\', \'TEXT.txt\')\n \n \n # In[ ]:\n \n \n-parser = argparse.ArgumentParser(description=\'wav_to_txt\')\n-parser.add_argument(\'wav_path\', help=\'Path to .wav audio file\')\n-parser.add_argument(\'out_path\', help=\'Path to output .txt file\')\n-\n if __name__ == \'__main__\':\n     args = parser.parse_args()\n     wav_to_txt(args.wav_path, args.out_path)\n-\n'}, {'diff': '@@ -1,132 +0,0 @@\n-<<<<<<< HEAD:SpeechRecognition_2_mp3_to_text.py\n-# -*- coding: utf-8 -*-\n-=======\n-# coding: utf-8\n->>>>>>> origin/KateShestakova:SpeechRecognition_mp3_to_text.py\n-\n-# ### Функции пред- и постобработки\n-\n-from pydub import AudioSegment\n-from pydub.utils import make_chunks\n-import os\n-\n-import speech_recognition as sr\n-\n-# Перевод из формата mp3 в wav\n-\n-def mp3_to_wav(mp3_src, wav_src):\n-    sound = AudioSegment.from_mp3(mp3_src)\n-    sound.export(wav_src, format=""wav"")\n-\n-# Делим аудио (wav) на короткие части, сохраняем в папку tmp_chunks\n-\n-def divide_audio(audio_src, chunk_length_ms):\n-    audio = AudioSegment.from_file(audio_src, ""wav"") \n-    chunks = make_chunks(audio, chunk_length_ms)\n-    \n-    path = ""tmp_chunks""\n-    os.mkdir(path)\n-    \n-    chunks_src = []\n-    for i, chunk in enumerate(chunks):\n-        chunk_name = ""tmp_chunks\\chunk{0}.wav"".format(i)\n-        chunks_src.append(chunk_name)\n-        chunk.export(chunk_name, format=""wav"")\n-        \n-    return chunks_src\n-\n-\n-# Удаляем папку tmp_chunks с частями аудио\n-\n-def delete_tmp_chunks(chunks_src):\n-    for chunk in chunks_src:\n-        os.remove(chunk)\n-    os.rmdir(\'tmp_chunks\')\n-\n-# Соединяем распознанный по частям текст\n-\n-def combine_text(text_array):\n-    result_text = \'\'\n-    for text in text_array:\n-        result_text += text + \' \'\n-    return result_text\n-\n-\n-# ### Распознавание речи\n-\n-# Библиотека SpeechRecognition ( https://pypi.org/project/SpeechRecognition/ )\n-# \n-# Используется распознавание при помощи Google Speech Recognition\n-# \n-# Распознавание текста происходит непрерывно, даже когда речи нет, а есть только шум. Если распознать какие-то слова не удается, программа выдает ошибку. Поэтому нужно делить аудио на короткие части и распознавать их отдельно.\n-# \n-# Список языковых кодов для Google Speech Recognition: https://www.science.co.il/language/Locale-codes.php\n-\n-\n-# Распознавание без учета шума\n-\n-def recognize(audio_src):\n-    # делим аудио на части\n-    chunks_src = divide_audio(audio_src, 3000)\n-    # распознаем каждую часть\n-    text_array = []\n-    for chunk_src in chunks_src:\n-        a = sr.AudioFile(chunk_src)\n-        with a as source:\n-            audio = r.record(source)\n-        try:\n-            text_array.append(r.recognize_google(audio, language=\'ru\'))\n-        except:\n-            pass\n-    # объединяем распознанные тексты\n-    text = combine_text(text_array)\n-    # удаляем ненужные файлы\n-    delete_tmp_chunks(chunks_src)\n-    \n-    return text\n-\n-# Распознавание с учетом шума: уровень шума определяется автоматически\n-\n-def recognize_with_noise(audio_src):\n-    # делим аудио на части\n-    chunks_src = divide_audio(audio_src, 3000)\n-    # распознаем каждую часть\n-    text_array = []\n-    for chunk_src in chunks_src:\n-        a = sr.AudioFile(chunk_src)\n-        with a as source:\n-            r.adjust_for_ambient_noise(source) # учитываем шум\n-            audio = r.record(source)\n-        try:\n-            text_chunk = r.recognize_google(audio, language=\'ru\')\n-            text_array.append(text_chunk)\n-            #print(text_chunk)\n-        except:\n-            pass\n-    # объединяем распознанные тексты\n-    text = combine_text(text_array)\n-    # удаляем ненужные файлы\n-    delete_tmp_chunks(chunks_src)\n-    \n-    return text\n-\n-# итоговая функция распознавания\n-\n-def wav_to_txt(path):\n-    r = sr.Recognizer()\n-    recognize_with_noise(path)\n-    \n-# для интеграции в main\n-\n-parser = argparse.ArgumentParser(description=\'wav_to_txt\')\n-parser.add_argument(\'wav_path\', help=\'Path to .wav audio file\')\n-parser.add_argument(\'out_path\', help=\'Path to output text file\')\n-\n-if __name__ == \'__main__\':\n-    args = parser.parse_args()\n-    txt = wav_to_txt(args.wav_path)\n-    \n-    f = open(args.out_path, ""a"")\n-    f.write(txt) \n-    f.close() \n-\n'}, {'diff': ""@@ -6,6 +6,7 @@ import sys\n import os \n import argparse\n \n+\n parser = argparse.ArgumentParser(description='OCR')\n parser.add_argument('in_filenames', help='Input filenames')\n parser.add_argument('out_filename', help='Output filename')\n@@ -16,8 +17,8 @@ def Pic2Txt(listImg, outfile):\n \t# Iterate through all the image\n \tfor img in listImg: \n \n-\t\t# Recognize the text as string in image using pytesserct \n-\t\ttext = str(((pytesseract.image_to_string(cv2.imread(img),lang = 'eng+rus')))) \n+\t\t# Recognize the text as string in image using pytesserct\n+\t\ttext = str(((pytesseract.image_to_string(cv2.imread(img),lang = 'eng+rus'))))\n \n \t\t# The recognized text is stored in variable text \n \t\t# Any string processing may be applied on text \n""}, {'diff': '@@ -7,7 +7,8 @@ import socket\n from TextFromPicture import Pic2Txt\n import FFMPEGFrames\n import glob\n-\n+from SpeechRecognition import wav_to_txt\n+import video_to_audio\n \n def main():\n     parser = argparse.ArgumentParser()\n@@ -43,7 +44,20 @@ def main():\n \n         f = FFMPEGFrames.FFMPEGFrames(""images/"")\n         f.extract_frames(input, fps)\n-        Pic2Txt(glob.glob(""images/*.png""), output)\n+        Pic2Txt(glob.glob(f.output + ""/*.png""), output)\n+    elif str(sys.argv[1] in [\'-a\', \'--audio\']):\n+        parser.add_argument(\'-a\', \'--audio\', action=\'store_true\')\n+        parser.add_argument(""in_filename"", help=\'Input filename\')\n+        parser.add_argument(\'out_filename\', help=\'Output filename\')\n+        args = vars(parser.parse_args())\n+\n+        input = args[""in_filename""]\n+        output = args[""out_filename""]\n+\n+        f = video_to_audio.video_to_audio(""/WAVs"")\n+        f.video_to_wav(input)\n+        wav_to_txt(f.output, output)\n+\n     else:\n         print(error_msg)\n \n'}, {'diff': '@@ -0,0 +1,37 @@\n+import subprocess\n+import argparse\n+import os\n+\n+parser = argparse.ArgumentParser(description=\'mp3_to_wav\')\n+parser.add_argument(\'in_mp3\', help=\'Input .mp3 file\')\n+\n+def mp3_to_wav(mp3_path):\n+    wavs_path = ""WAVs""\n+    wav_path = wavs_path + ""/output.wav""\n+    if not os.path.exists(wavs_path):\n+        os.mkdir(wavs_path)\n+\n+    subprocess.run([""ffmpeg"",\n+                ""-loglevel"",\n+                ""quiet"",\n+                ""-hide_banner"",\n+                ""-y"",\n+                ""-i"",\n+                mp3_path,\n+                ""-write_id3v1"",\n+                ""1"",\n+                ""-id3v2_version"",\n+                ""3"",\n+                ""-q:a"",\n+                ""0"",\n+                ""-map"",\n+                ""a"",\n+                wav_path],\n+               stderr=subprocess.DEVNULL,\n+               stdout=subprocess.DEVNULL,\n+               stdin=subprocess.PIPE)\n+\n+\n+if __name__ == \'__main__\':\n+    args = parser.parse_args()\n+    mp3_to_wav(args.in_mp3)\n\\ No newline at end of file\n'}, {'diff': '@@ -0,0 +1,40 @@\n+import subprocess\n+import argparse\n+import os\n+\n+parser = argparse.ArgumentParser(description=\'video2mp3\')\n+parser.add_argument(\'video_path\', help=\'Path to video file\')\n+\n+\n+def video2mp3(video_path):\n+    mp3s_path = ""mp3s""\n+    mp3_path = mp3s_path + ""/output.mp3""\n+    if not os.path.exists(mp3s_path):\n+        os.mkdir(mp3s_path)\n+\n+    subprocess.run([""ffmpeg"",\n+                ""-loglevel"",\n+                ""quiet"",\n+                ""-hide_banner"",\n+                ""-y"",\n+                ""-i"",\n+                video_path,\n+                ""-write_id3v1"",\n+                ""1"",\n+                ""-id3v2_version"",\n+                ""3"",\n+                ""-q:a"",\n+                ""0"",\n+                ""-map"",\n+                ""a"",\n+                mp3_path],\n+               stderr=subprocess.DEVNULL,\n+               stdout=subprocess.DEVNULL,\n+               stdin=subprocess.PIPE)\n+\n+\n+if __name__ == \'__main__\':\n+    #path = ""files/videoplayback.mp4""\n+    #video2mp3(path)\n+    args = parser.parse_args()\n+    video2mp3(args.video_path)\n'}, {'diff': '@@ -0,0 +1,81 @@\n+import subprocess\n+import argparse\n+import os\n+import time\n+\n+parser = argparse.ArgumentParser(description=\'video_to_wav\')\n+parser.add_argument(\'video_path\', help=\'Path to video file\')\n+\n+\n+class video_to_audio:\n+\n+    def __init__(self, output):\n+        self.output = output\n+\n+    def video_to_wav(self, video_path):\n+        wavs_path = ""WAVs""\n+        name = video_path.split(\'/\')[-1].split(\'.\')[0]\n+        self.output = wavs_path + ""/"" + name + "".wav""\n+        if not os.path.exists(wavs_path):\n+            os.mkdir(wavs_path)\n+            print(f""Directory created"")\n+\n+        subprocess.run([""ffmpeg"",\n+                ""-loglevel"",\n+                ""debug"",\n+                ""-hide_banner"",\n+                ""-y"",\n+                ""-i"",\n+                video_path,\n+                ""-vn"",\n+                ""-sn"",\n+                ""-ar"",\n+                ""44100"",\n+                ""-q:a"",\n+                ""0"",\n+                ""-map"",\n+                ""a"",\n+                self.output],\n+               stderr=subprocess.DEVNULL,\n+               stdout=subprocess.DEVNULL,\n+               stdin=subprocess.PIPE)\n+\n+        print(f""Convertation to .wav finished!"")\n+\n+\n+#if __name__ == \'__main__\':\n+    #path = ""files/videoplayback.mp4""\n+    #video_to_wav(path)\n+    #args = parser.parse_args()\n+    #video_to_wav(args.video_path)\n+\n+\n+    def video2mp3(self, video_path):\n+        mp3s_path = ""mp3s""\n+        name = video_path.split(\'/\')[-1].split(\'.\')[0]\n+        self.output = mp3s_path + ""/"" + name + "".mp3""\n+        if not os.path.exists(mp3s_path):\n+            os.mkdir(mp3s_path)\n+            print(f""Directory created"")\n+\n+        subprocess.run([""ffmpeg"",\n+                ""-loglevel"",\n+                ""debug"",\n+                ""-hide_banner"",\n+                ""-y"",\n+                ""-i"",\n+                video_path,\n+                ""-write_id3v1"",\n+                ""1"",\n+                ""-id3v2_version"",\n+                ""3"",\n+                ""-q:a"",\n+                ""0"",\n+                ""-map"",\n+                ""a"",\n+                self.output],\n+               stderr=subprocess.DEVNULL,\n+               stdout=subprocess.DEVNULL,\n+               stdin=subprocess.PIPE)\n+\n+        print(f""Convertation to .mp3 finished!"")\n\\ No newline at end of file\n'}]","            str(fps) + "" "" + self.output + ""/output%02d.png"";    ```bash;        python3 main.py -a files/videoplayback.mp4 output.txt;    ```;import speech_recognition as sr;import argparse;parser = argparse.ArgumentParser(description='wav_to_txt');parser.add_argument('wav_path', help='Path to .wav audio file');parser.add_argument('out_path', help='Path to output .txt file');    slices = np.arange(0, len(audio) - overlap_ms, slice_length_ms - overlap_ms);        slice_ = audio[start: end + overlap_ms];        i += 1;        slice_ = audio[end: len(audio)];            if splited[j] != prev_splited[-1 - j]:;        prev_splited = splited;        # print('analyzing ', chunk_src);            # print('!',text_chunk);# print(recognize_no_noise('audio/test1.wav'));        # print('analyzing ', chunk_src);            r.adjust_for_ambient_noise(source)  # учитываем шум;            # print(text_chunk);# print(recognize_with_noise('audio/test1.wav'));    print(f""Speech recognition started"");    print(f""Speech recognition finished"");# wav_to_txt('audio/test1.wav', 'TEXT.txt');		# Recognize the text as string in image using pytesserct;		text = str(((pytesseract.image_to_string(cv2.imread(img),lang = 'eng+rus'))));from SpeechRecognition import wav_to_txt;import video_to_audio;        Pic2Txt(glob.glob(f.output + ""/*.png""), output);    elif str(sys.argv[1] in ['-a', '--audio']):;        parser.add_argument('-a', '--audio', action='store_true');        parser.add_argument(""in_filename"", help='Input filename');        parser.add_argument('out_filename', help='Output filename');        args = vars(parser.parse_args());        input = args[""in_filename""];        output = args[""out_filename""];        f = video_to_audio.video_to_audio(""/WAVs"");        f.video_to_wav(input);        wav_to_txt(f.output, output);import subprocess;import argparse;import os;parser = argparse.ArgumentParser(description='mp3_to_wav');parser.add_argument('in_mp3', help='Input .mp3 file');def mp3_to_wav(mp3_path):;    wavs_path = ""WAVs"";    wav_path = wavs_path + ""/output.wav"";    if not os.path.exists(wavs_path):;        os.mkdir(wavs_path);    subprocess.run([""ffmpeg"",;                ""-loglevel"",;                ""quiet"",;                ""-hide_banner"",;                ""-y"",;                ""-i"",;                mp3_path,;                ""-write_id3v1"",;                ""1"",;                ""-id3v2_version"",;                ""3"",;                ""-q:a"",;                ""0"",;                ""-map"",;                ""a"",;                wav_path],;               stderr=subprocess.DEVNULL,;               stdout=subprocess.DEVNULL,;               stdin=subprocess.PIPE);if __name__ == '__main__':;    args = parser.parse_args();    mp3_to_wav(args.in_mp3);import subprocess;import argparse;import os;parser = argparse.ArgumentParser(description='video2mp3');parser.add_argument('video_path', help='Path to video file');def video2mp3(video_path):;    mp3s_path = ""mp3s"";    mp3_path = mp3s_path + ""/output.mp3"";    if not os.path.exists(mp3s_path):;        os.mkdir(mp3s_path);    subprocess.run([""ffmpeg"",;                ""-loglevel"",;                ""quiet"",;                ""-hide_banner"",;                ""-y"",;                ""-i"",;                video_path,;                ""-write_id3v1"",;                ""1"",;                ""-id3v2_version"",;                ""3"",;                ""-q:a"",;                ""0"",;                ""-map"",;                ""a"",;                mp3_path],;               stderr=subprocess.DEVNULL,;               stdout=subprocess.DEVNULL,;               stdin=subprocess.PIPE);if __name__ == '__main__':;    #path = ""files/videoplayback.mp4"";    #video2mp3(path);    args = parser.parse_args();    video2mp3(args.video_path);import subprocess;import argparse;import os;import time;parser = argparse.ArgumentParser(description='video_to_wav');parser.add_argument('video_path', help='Path to video file');class video_to_audio:;    def __init__(self, output):;        self.output = output;    def video_to_wav(self, video_path):;        wavs_path = ""WAVs"";        name = video_path.split('/')[-1].split('.')[0];        self.output = wavs_path + ""/"" + name + "".wav"";        if not os.path.exists(wavs_path):;            os.mkdir(wavs_path);            print(f""Directory created"");        subprocess.run([""ffmpeg"",;                ""-loglevel"",;                ""debug"",;                ""-hide_banner"",;                ""-y"",;                ""-i"",;                video_path,;                ""-vn"",;                ""-sn"",;                ""-ar"",;                ""44100"",;                ""-q:a"",;                ""0"",;                ""-map"",;                ""a"",;                self.output],;               stderr=subprocess.DEVNULL,;               stdout=subprocess.DEVNULL,;               stdin=subprocess.PIPE);        print(f""Convertation to .wav finished!"");#if __name__ == '__main__':;    #path = ""files/videoplayback.mp4"";    #video_to_wav(path);    #args = parser.parse_args();    #video_to_wav(args.video_path);    def video2mp3(self, video_path):;        mp3s_path = ""mp3s"";        name = video_path.split('/')[-1].split('.')[0];        self.output = mp3s_path + ""/"" + name + "".mp3"";        if not os.path.exists(mp3s_path):;            os.mkdir(mp3s_path);            print(f""Directory created"");        subprocess.run([""ffmpeg"",;                ""-loglevel"",;                ""debug"",;                ""-hide_banner"",;                ""-y"",;                ""-i"",;                video_path,;                ""-write_id3v1"",;                ""1"",;                ""-id3v2_version"",;                ""3"",;                ""-q:a"",;                ""0"",;                ""-map"",;                ""a"",;                self.output],;               stderr=subprocess.DEVNULL,;               stdout=subprocess.DEVNULL,;               stdin=subprocess.PIPE);        print(f""Convertation to .mp3 finished!"");","            str(fps) + "" "" + self.output + ""output%02d.png"";    slices = np.arange(0, len(audio)-overlap_ms, slice_length_ms-overlap_ms);    ;    ;        slice_ = audio[start : end+overlap_ms];        i+=1;        ;        slice_ = audio[end : len(audio)];        ;    ;    ;        ;        ;            if splited[j] != prev_splited[-1-j]:;        ;        ;        ;        prev_splited = splited        ;        ;    ;        #print('analyzing ', chunk_src);            #print('!',text_chunk);    ;    ;#print(recognize_no_noise('audio/test1.wav'));    ;        #print('analyzing ', chunk_src);            r.adjust_for_ambient_noise(source) # учитываем шум;            #print(text_chunk);    ;#print(recognize_with_noise('audio/test1.wav'));    ;    ;        ;#wav_to_txt('audio/test1.wav', 'TEXT.txt');parser = argparse.ArgumentParser(description='wav_to_txt');parser.add_argument('wav_path', help='Path to .wav audio file');parser.add_argument('out_path', help='Path to output .txt file');		# Recognize the text as string in image using pytesserct ;		text = str(((pytesseract.image_to_string(cv2.imread(img),lang = 'eng+rus')))) ;        Pic2Txt(glob.glob(""images/*.png""), output);",https://git.miem.hse.ru/19121/recognition_miem/-/commit/edd6ebcecb5da66d513debf4d37d99281432c309,14,0,"['FFMPEGFrames.py', 'README.md', 'SpeechRecognition.py', 'SpeechRecognition_mp3_to_text.py', 'TextFromPicture.py', 'main.py', 'mp3_to_wav.py', 'video2mp3.py', 'video_to_audio.py']","import os
import subprocess


class FFMPEGFrames:

    def __init__(self, output):
        self.output = output

    def extract_frames(self, input, fps):
        self.output = input.split('/')[-1].split('.')[0]

        if not os.path.exists(self.output):
            os.makedirs(self.output)

        query = ""ffmpeg -i "" + input + "" -vf fps="" + \
            str(fps) + "" "" + self.output + ""/output%02d.png""
        response = subprocess.Popen(
            query, shell=True, stdout=subprocess.PIPE).stdout.read()
        s = str(response).encode('utf-8')

;
# coding: utf-8

# ### Функции пред- и постобработки

# In[1]:


from pydub import AudioSegment
from scipy.io import wavfile
import os
import numpy as np
import speech_recognition as sr
import argparse



parser = argparse.ArgumentParser(description='wav_to_txt')
parser.add_argument('wav_path', help='Path to .wav audio file')
parser.add_argument('out_path', help='Path to output .txt file')
# Делим аудио (wav) на короткие части, сохраняем в папку tmp_slices

# In[2]:




def divide_audio(audio_src, slice_length_ms=3000, overlap_ms=500):
    audio = AudioSegment.from_file(audio_src, ""wav"")

    slices = np.arange(0, len(audio) - overlap_ms, slice_length_ms - overlap_ms)

    path = ""tmp_slices""
    os.mkdir(path)
    audio_slices_src = []
    i = 0

    for start, end in zip(slices[:-1], slices[1:]):
        slice_ = audio[start: end + overlap_ms]
        # сохраняем кусочки аудио
        slice_name = ""tmp_slices\slice{0}.wav"".format(i)
        audio_slices_src.append(slice_name)
        slice_.export(slice_name, format=""wav"")
        i += 1

    if len(audio) - end > overlap_ms:
        slice_ = audio[end: len(audio)]
        slice_name = ""tmp_slices\slice{0}.wav"".format(i)
        audio_slices_src.append(slice_name)
        slice_.export(slice_name, format=""wav"")

    return audio_slices_src


# Удаляем папку tmp_slices с частями аудио

# In[3]:


def delete_tmp_slices(audio_slices_src):
    for slice_ in audio_slices_src:
        os.remove(slice_)
    os.rmdir('tmp_slices')


# Соединяем распознанный по частям текст

# In[4]:


def combine_text(text_array):
    result_text = ''

    prev_splited = []

    for text in text_array:
        processed_text = ''

        splited = text.lower().split()

        j = 0
        while j < min(len(splited), len(prev_splited)):
            if splited[j] != prev_splited[-1 - j]:
                break
            j += 1

        for i in range(j, len(splited)):
            processed_text += splited[i] + ' '

        result_text += processed_text

        prev_splited = splited

    return result_text


# ### Распознавание речи

# Библиотека SpeechRecognition ( https://pypi.org/project/SpeechRecognition/ )
# 
# Используется распознавание при помощи Google Speech Recognition
# 
# Распознавание текста происходит непрерывно, даже когда речи нет, а есть только шум. Если распознать какие-то слова не удается, программа выдает ошибку. Поэтому нужно делить аудио на короткие части и распознавать их отдельно.
# 
# Список языковых кодов для Google Speech Recognition: https://www.science.co.il/language/Locale-codes.php

# In[5]:


# Распознавание без учета шума

# In[6]:


def recognize_no_noise(audio_src):
    r = sr.Recognizer()

    # делим аудио на части
    chunks_src = divide_audio(audio_src)
    # распознаем каждую часть
    text_array = []
    for chunk_src in chunks_src:
        a = sr.AudioFile(chunk_src)
        # print('analyzing ', chunk_src)
        with a as source:
            audio = r.record(source)
        try:
            text_chunk = r.recognize_google(audio, language='ru')
            text_array.append(text_chunk)
            # print('!',text_chunk)
        except:
            pass
    # объединяем распознанные тексты
    text = combine_text(text_array)

    # удаляем ненужные файлы
    delete_tmp_slices(chunks_src)

    return text


# In[7]:


# print(recognize_no_noise('audio/test1.wav'))


# Распознавание с учетом шума: уровень шума определяется автоматически

# In[8]:


def recognize_with_noise(audio_src):
    r = sr.Recognizer()

    # делим аудио на части
    chunks_src = divide_audio(audio_src)
    # распознаем каждую часть
    text_array = []
    for chunk_src in chunks_src:
        a = sr.AudioFile(chunk_src)
        # print('analyzing ', chunk_src)
        with a as source:
            r.adjust_for_ambient_noise(source)  # учитываем шум
            audio = r.record(source)
        try:
            text_chunk = r.recognize_google(audio, language='ru')
            text_array.append(text_chunk)
            # print(text_chunk)
        except:
            pass
    # объединяем распознанные тексты
    text = combine_text(text_array)
    # удаляем ненужные файлы
    delete_tmp_slices(chunks_src)

    return text


# In[9]:


# print(recognize_with_noise('audio/test1.wav'))


# Итоговая функция распознавания, в которой выбирается наилучший вариант распознавания

# In[10]:


def wav_to_txt(audio_src, out_txt_src):
    print(f""Speech recognition started"")
    no_noise_txt = recognize_no_noise(audio_src)
    noise_txt = recognize_with_noise(audio_src)

    text = no_noise_txt
    if len(noise_txt.split()) > len(text.split()):
        text = noise_txt

    # записываем в файл
    out = open(out_txt_src, 'a')
    out.write(text)
    out.close()
    print(f""Speech recognition finished"")


# Для интеграции в main

# In[12]:


# wav_to_txt('audio/test1.wav', 'TEXT.txt')


# In[ ]:


if __name__ == '__main__':
    args = parser.parse_args()
    wav_to_txt(args.wav_path, args.out_path)

;
# Import libraries
# from PIL import Image хуже распознается
import cv2 
import pytesseract 
import sys 
import os 
import argparse


parser = argparse.ArgumentParser(description='OCR')
parser.add_argument('in_filenames', help='Input filenames')
parser.add_argument('out_filename', help='Output filename')

def Pic2Txt(listImg, outfile):

	f = open(outfile, ""a"") 
	# Iterate through all the image
	for img in listImg: 

		# Recognize the text as string in image using pytesserct
		text = str(((pytesseract.image_to_string(cv2.imread(img),lang = 'eng+rus'))))

		# The recognized text is stored in variable text 
		# Any string processing may be applied on text 
		# Here, basic formatting has been done: 
		# In many PDFs, at line ending, if a word can't 
		# be written fully, a 'hyphen' is added. 
		# The rest of the word is written in the next line 
		# Eg: This is a sample text this word here GeeksF- 
		# orGeeks is half on first line, remaining on next. 
		# To remove this, we replace every '-\n' to ''. 
		text = text.replace('-\n', '')	 

		# Finally, write the processed text to the file. 
		#with open(fname, ""w"", encoding=""utf-8"") as f:
		f.write(text) 

	# Close the file after writing all the text. 
	f.close() 

if __name__ == '__main__':
    args = parser.parse_args()
    Pic2Txt(args.in_filenames.split(','), args.out_filename)
;
# -*- coding: utf-8 -*-

from test import Hello
import argparse
import sys
import socket
from TextFromPicture import Pic2Txt
import FFMPEGFrames
import glob
from SpeechRecognition import wav_to_txt
import video_to_audio

def main():
    parser = argparse.ArgumentParser()

    error_msg = ""Invalid Arguments\n\n"" \
                ""Commands: \n"" \
                ""  -t, --test                 Let's test it!\n"" \
                ""       Optional: --name='your_arg'  -   that'll print your string your_arg\n"" \
                ""  -v, --video             Convert video to pictures and then convert to text\n"" \
                ""       Mandatory: --in_filename='files/video.mp4' --out_filename='output.txt'  --fps='1'-  set input video, output file, frames per second ""

    if len(sys.argv) == 1:
        print(error_msg)

    elif str(sys.argv[1]) in ['-t', '--test']:
        parser.add_argument('-t', '--test', action='store_true')
        parser.add_argument(""--name"", default=socket.gethostname())

        args = parser.parse_args()

        test_class = Hello(args.name)
        test_class.print_hello()
    elif str(sys.argv[1]) in ['-v', '--video']:
        parser.add_argument('-v', '--video', action='store_true')
        parser.add_argument(""in_filename"", help='Input filename')
        parser.add_argument('out_filename', help='Output filename')
        parser.add_argument(""fps"", help='fps')
        args = vars(parser.parse_args())

        input = args[""in_filename""]
        output = args[""out_filename""]
        fps = args[""fps""]

        f = FFMPEGFrames.FFMPEGFrames(""images/"")
        f.extract_frames(input, fps)
        Pic2Txt(glob.glob(f.output + ""/*.png""), output)
    elif str(sys.argv[1] in ['-a', '--audio']):
        parser.add_argument('-a', '--audio', action='store_true')
        parser.add_argument(""in_filename"", help='Input filename')
        parser.add_argument('out_filename', help='Output filename')
        args = vars(parser.parse_args())

        input = args[""in_filename""]
        output = args[""out_filename""]

        f = video_to_audio.video_to_audio(""/WAVs"")
        f.video_to_wav(input)
        wav_to_txt(f.output, output)

    else:
        print(error_msg)


if __name__ == '__main__':
    main()

;
import subprocess
import argparse
import os

parser = argparse.ArgumentParser(description='mp3_to_wav')
parser.add_argument('in_mp3', help='Input .mp3 file')

def mp3_to_wav(mp3_path):
    wavs_path = ""WAVs""
    wav_path = wavs_path + ""/output.wav""
    if not os.path.exists(wavs_path):
        os.mkdir(wavs_path)

    subprocess.run([""ffmpeg"",
                ""-loglevel"",
                ""quiet"",
                ""-hide_banner"",
                ""-y"",
                ""-i"",
                mp3_path,
                ""-write_id3v1"",
                ""1"",
                ""-id3v2_version"",
                ""3"",
                ""-q:a"",
                ""0"",
                ""-map"",
                ""a"",
                wav_path],
               stderr=subprocess.DEVNULL,
               stdout=subprocess.DEVNULL,
               stdin=subprocess.PIPE)


if __name__ == '__main__':
    args = parser.parse_args()
    mp3_to_wav(args.in_mp3)
;
'''конвертация видеофайлов различных форматов в mp3'''

import os
import sys
import subprocess
from multiprocessing.pool import ThreadPool
from multiprocessing import cpu_count
import time
import datetime

def videotomp3(task):
    '''запускает новый подпроцесс ffmpeg, используя pipe и сохраняет файлы в формате mp3 в ту жу директорию, где хранятся оригинальные файлы '''
    root_path = task[0]
    filename = task[1]
    full_path = os.path.join(root_path, filename)
    new_filename = os.path.splitext(filename)[0] +"".mp3""
    new_path = os.path.join(root_path,
                            os.path.basename(root_path) + ""-"" + FOLDER_NAME,
                            new_filename)

    completed = subprocess.run([""ffmpeg"",
                                ""-loglevel"",
                                ""quiet"",
                                ""-hide_banner"",
                                ""-y"",
                                ""-i"",
                                full_path,
                                ""-write_id3v1"",
                                ""1"",
                                ""-id3v2_version"",
                                ""3"",
                                ""-q:a"",
                                ""0"",
                                ""-map"",
                                ""a"",
                                new_path],
                               stderr=subprocess.DEVNULL,
                               stdout=subprocess.DEVNULL,
                               stdin=subprocess.PIPE)
    #Если не предоставить pipe каналу stdin, то ffmpeg не закроется корректно
    #при конвертировании нескольких файлов и будет необходимо перезагрузить
    #терминал после авершения выполнения этого скрипта
    #удалить исходные файлы после их конвертации
    #if completed.returncode == 0:
        #subprocess.call([""rm"", full_path]) # удаляет исходный файл после конвертации
    print(f""'{new_path}' - return code {completed.returncode}"")
    if completed.returncode != 0:
        completed.timestamp = datetime.datetime.now().ctime()
    return completed

if __name__ == ""__main__"":
    FOLDERS = []
    FOLDER_NAME = ""MP3s""
    AUDIO_FILE_TYPES = (""webm"",
                        ""mpeg"",
                        ""ogg"",
                        ""mp4"",
                        ""m4p"",
                        ""m4v"",
                        ""avi"",
                        ""wmv"",
                        ""mov"",
                        ""flv"")
    STARTTIME = time.time()
    #get all of the source audio filenames
    for root, dirs, files in os.walk(os.getcwd()):
        source_audio_filenames = []
        for file in files:
            if file.endswith(AUDIO_FILE_TYPES):
                source_audio_filenames.append((root, file))
        FOLDERS.append((root, source_audio_filenames))

    with ThreadPool(cpu_count())as p:
        PROCESSES = []
        for Folder in FOLDERS:
            try:
                #Stop directories being created within the output directories
                if FOLDER_NAME in Folder[0]:
                    continue
                NewFolderName = os.path.basename(Folder[0]) + ""-"" + FOLDER_NAME
                os.mkdir(os.path.join(Folder[0], NewFolderName))
            except FileExistsError:
                pass
            PROCESSES += Folder[1]
        print(f""Transcoding {len(PROCESSES)} Audio files"")
        JOBS = p.map(converttomp3, PROCESSES)
        FAILED_JOBS = []
        for job in JOBS:
            if job.returncode != 0:
                FAILED_JOBS.append(job)
        MESSAGE = (f""Transcode Finished! \r {len(PROCESSES)-len(FAILED_JOBS)}/{len(PROCESSES)} ""
                   f""Audio files transcoded in \r{time.time() - STARTTIME:.4f} seconds"")
        subprocess.run([""notify-send"", ""--urgency=low"", MESSAGE])
        if len(FAILED_JOBS) > 0:       
            with open(""nautilus-transcode.log"", 'a+') as f:
                for failedJob in FAILED_JOBS:
                    f.write(f""{failedJob.timestamp} args:{failedJob.args}""
                            f""return code:{failedJob.returncode}\n"")

    print(""Done"")
    sys.exit(0)



;
import subprocess
import argparse
import os

parser = argparse.ArgumentParser(description='video2mp3')
parser.add_argument('video_path', help='Path to video file')


def video2mp3(video_path):
    mp3s_path = ""mp3s""
    mp3_path = mp3s_path + ""/output.mp3""
    if not os.path.exists(mp3s_path):
        os.mkdir(mp3s_path)

    subprocess.run([""ffmpeg"",
                ""-loglevel"",
                ""quiet"",
                ""-hide_banner"",
                ""-y"",
                ""-i"",
                video_path,
                ""-write_id3v1"",
                ""1"",
                ""-id3v2_version"",
                ""3"",
                ""-q:a"",
                ""0"",
                ""-map"",
                ""a"",
                mp3_path],
               stderr=subprocess.DEVNULL,
               stdout=subprocess.DEVNULL,
               stdin=subprocess.PIPE)


if __name__ == '__main__':
    #path = ""files/videoplayback.mp4""
    #video2mp3(path)
    args = parser.parse_args()
    video2mp3(args.video_path)

;
import subprocess
import argparse
import os
import time

parser = argparse.ArgumentParser(description='video_to_wav')
parser.add_argument('video_path', help='Path to video file')


class video_to_audio:

    def __init__(self, output):
        self.output = output

    def video_to_wav(self, video_path):
        wavs_path = ""WAVs""
        name = video_path.split('/')[-1].split('.')[0]
        self.output = wavs_path + ""/"" + name + "".wav""
        if not os.path.exists(wavs_path):
            os.mkdir(wavs_path)
            print(f""Directory created"")

        subprocess.run([""ffmpeg"",
                ""-loglevel"",
                ""debug"",
                ""-hide_banner"",
                ""-y"",
                ""-i"",
                video_path,
                ""-vn"",
                ""-sn"",
                ""-ar"",
                ""44100"",
                ""-q:a"",
                ""0"",
                ""-map"",
                ""a"",
                self.output],
               stderr=subprocess.DEVNULL,
               stdout=subprocess.DEVNULL,
               stdin=subprocess.PIPE)

        print(f""Convertation to .wav finished!"")


#if __name__ == '__main__':
    #path = ""files/videoplayback.mp4""
    #video_to_wav(path)
    #args = parser.parse_args()
    #video_to_wav(args.video_path)


    def video2mp3(self, video_path):
        mp3s_path = ""mp3s""
        name = video_path.split('/')[-1].split('.')[0]
        self.output = mp3s_path + ""/"" + name + "".mp3""
        if not os.path.exists(mp3s_path):
            os.mkdir(mp3s_path)
            print(f""Directory created"")

        subprocess.run([""ffmpeg"",
                ""-loglevel"",
                ""debug"",
                ""-hide_banner"",
                ""-y"",
                ""-i"",
                video_path,
                ""-write_id3v1"",
                ""1"",
                ""-id3v2_version"",
                ""3"",
                ""-q:a"",
                ""0"",
                ""-map"",
                ""a"",
                self.output],
               stderr=subprocess.DEVNULL,
               stdout=subprocess.DEVNULL,
               stdin=subprocess.PIPE)

        print(f""Convertation to .mp3 finished!"")
;
","import os
import subprocess


class FFMPEGFrames:

    def __init__(self, output):
        self.output = output

    def extract_frames(self, input, fps):
        self.output = input.split('/')[-1].split('.')[0]

        if not os.path.exists(self.output):
            os.makedirs(self.output)

        query = ""ffmpeg -i "" + input + "" -vf fps="" + \
            str(fps) + "" "" + self.output + ""output%02d.png""
        response = subprocess.Popen(
            query, shell=True, stdout=subprocess.PIPE).stdout.read()
        s = str(response).encode('utf-8')

;

# coding: utf-8

# ### Функции пред- и постобработки

# In[1]:


from pydub import AudioSegment
from scipy.io import wavfile
import os
import numpy as np


# Делим аудио (wav) на короткие части, сохраняем в папку tmp_slices

# In[2]:


def divide_audio(audio_src, slice_length_ms=3000, overlap_ms=500):
    audio = AudioSegment.from_file(audio_src, ""wav"")

    slices = np.arange(0, len(audio)-overlap_ms, slice_length_ms-overlap_ms)
    
    path = ""tmp_slices""
    os.mkdir(path)
    audio_slices_src = []
    i = 0
    
    for start, end in zip(slices[:-1], slices[1:]):
        slice_ = audio[start : end+overlap_ms]
        # сохраняем кусочки аудио
        slice_name = ""tmp_slices\slice{0}.wav"".format(i)
        audio_slices_src.append(slice_name)
        slice_.export(slice_name, format=""wav"")
        i+=1
        
    if len(audio) - end > overlap_ms:
        slice_ = audio[end : len(audio)]
        slice_name = ""tmp_slices\slice{0}.wav"".format(i)
        audio_slices_src.append(slice_name)
        slice_.export(slice_name, format=""wav"")
        
    return audio_slices_src


# Удаляем папку tmp_slices с частями аудио

# In[3]:


def delete_tmp_slices(audio_slices_src):
    for slice_ in audio_slices_src:
        os.remove(slice_)
    os.rmdir('tmp_slices')


# Соединяем распознанный по частям текст

# In[4]:


def combine_text(text_array):
    result_text = ''
    
    prev_splited = []
    
    for text in text_array:
        processed_text = ''
        
        splited = text.lower().split()
        
        j = 0
        while j < min(len(splited), len(prev_splited)):
            if splited[j] != prev_splited[-1-j]:
                break
            j += 1
        
        for i in range(j, len(splited)):
            processed_text += splited[i] + ' '
        
        result_text += processed_text
        
        prev_splited = splited        
        
    return result_text


# ### Распознавание речи

# Библиотека SpeechRecognition ( https://pypi.org/project/SpeechRecognition/ )
# 
# Используется распознавание при помощи Google Speech Recognition
# 
# Распознавание текста происходит непрерывно, даже когда речи нет, а есть только шум. Если распознать какие-то слова не удается, программа выдает ошибку. Поэтому нужно делить аудио на короткие части и распознавать их отдельно.
# 
# Список языковых кодов для Google Speech Recognition: https://www.science.co.il/language/Locale-codes.php

# In[5]:


import speech_recognition as sr


# Распознавание без учета шума

# In[6]:


def recognize_no_noise(audio_src):
    r = sr.Recognizer()
    
    # делим аудио на части
    chunks_src = divide_audio(audio_src)
    # распознаем каждую часть
    text_array = []
    for chunk_src in chunks_src:
        a = sr.AudioFile(chunk_src)
        #print('analyzing ', chunk_src)
        with a as source:
            audio = r.record(source)
        try:
            text_chunk = r.recognize_google(audio, language='ru')
            text_array.append(text_chunk)
            #print('!',text_chunk)
        except:
            pass
    # объединяем распознанные тексты
    text = combine_text(text_array)
    
    # удаляем ненужные файлы
    delete_tmp_slices(chunks_src)
    
    return text


# In[7]:


#print(recognize_no_noise('audio/test1.wav'))


# Распознавание с учетом шума: уровень шума определяется автоматически

# In[8]:


def recognize_with_noise(audio_src):
    r = sr.Recognizer()
    
    # делим аудио на части
    chunks_src = divide_audio(audio_src)
    # распознаем каждую часть
    text_array = []
    for chunk_src in chunks_src:
        a = sr.AudioFile(chunk_src)
        #print('analyzing ', chunk_src)
        with a as source:
            r.adjust_for_ambient_noise(source) # учитываем шум
            audio = r.record(source)
        try:
            text_chunk = r.recognize_google(audio, language='ru')
            text_array.append(text_chunk)
            #print(text_chunk)
        except:
            pass
    # объединяем распознанные тексты
    text = combine_text(text_array)
    # удаляем ненужные файлы
    delete_tmp_slices(chunks_src)
    
    return text


# In[9]:


#print(recognize_with_noise('audio/test1.wav'))


# Итоговая функция распознавания, в которой выбирается наилучший вариант распознавания

# In[10]:


def wav_to_txt(audio_src, out_txt_src):
    
    no_noise_txt = recognize_no_noise(audio_src)
    noise_txt = recognize_with_noise(audio_src)
    
    text = no_noise_txt
    if len(noise_txt.split()) > len(text.split()):
        text = noise_txt
        
    # записываем в файл
    out = open(out_txt_src, 'a')
    out.write(text)
    out.close()


# Для интеграции в main

# In[12]:


#wav_to_txt('audio/test1.wav', 'TEXT.txt')


# In[ ]:


parser = argparse.ArgumentParser(description='wav_to_txt')
parser.add_argument('wav_path', help='Path to .wav audio file')
parser.add_argument('out_path', help='Path to output .txt file')

if __name__ == '__main__':
    args = parser.parse_args()
    wav_to_txt(args.wav_path, args.out_path)


;
<<<<<<< HEAD:SpeechRecognition_2_mp3_to_text.py
# -*- coding: utf-8 -*-
=======
# coding: utf-8
>>>>>>> origin/KateShestakova:SpeechRecognition_mp3_to_text.py

# ### Функции пред- и постобработки

from pydub import AudioSegment
from pydub.utils import make_chunks
import os

import speech_recognition as sr

# Перевод из формата mp3 в wav

def mp3_to_wav(mp3_src, wav_src):
    sound = AudioSegment.from_mp3(mp3_src)
    sound.export(wav_src, format=""wav"")

# Делим аудио (wav) на короткие части, сохраняем в папку tmp_chunks

def divide_audio(audio_src, chunk_length_ms):
    audio = AudioSegment.from_file(audio_src, ""wav"") 
    chunks = make_chunks(audio, chunk_length_ms)
    
    path = ""tmp_chunks""
    os.mkdir(path)
    
    chunks_src = []
    for i, chunk in enumerate(chunks):
        chunk_name = ""tmp_chunks\chunk{0}.wav"".format(i)
        chunks_src.append(chunk_name)
        chunk.export(chunk_name, format=""wav"")
        
    return chunks_src


# Удаляем папку tmp_chunks с частями аудио

def delete_tmp_chunks(chunks_src):
    for chunk in chunks_src:
        os.remove(chunk)
    os.rmdir('tmp_chunks')

# Соединяем распознанный по частям текст

def combine_text(text_array):
    result_text = ''
    for text in text_array:
        result_text += text + ' '
    return result_text


# ### Распознавание речи

# Библиотека SpeechRecognition ( https://pypi.org/project/SpeechRecognition/ )
# 
# Используется распознавание при помощи Google Speech Recognition
# 
# Распознавание текста происходит непрерывно, даже когда речи нет, а есть только шум. Если распознать какие-то слова не удается, программа выдает ошибку. Поэтому нужно делить аудио на короткие части и распознавать их отдельно.
# 
# Список языковых кодов для Google Speech Recognition: https://www.science.co.il/language/Locale-codes.php


# Распознавание без учета шума

def recognize(audio_src):
    # делим аудио на части
    chunks_src = divide_audio(audio_src, 3000)
    # распознаем каждую часть
    text_array = []
    for chunk_src in chunks_src:
        a = sr.AudioFile(chunk_src)
        with a as source:
            audio = r.record(source)
        try:
            text_array.append(r.recognize_google(audio, language='ru'))
        except:
            pass
    # объединяем распознанные тексты
    text = combine_text(text_array)
    # удаляем ненужные файлы
    delete_tmp_chunks(chunks_src)
    
    return text

# Распознавание с учетом шума: уровень шума определяется автоматически

def recognize_with_noise(audio_src):
    # делим аудио на части
    chunks_src = divide_audio(audio_src, 3000)
    # распознаем каждую часть
    text_array = []
    for chunk_src in chunks_src:
        a = sr.AudioFile(chunk_src)
        with a as source:
            r.adjust_for_ambient_noise(source) # учитываем шум
            audio = r.record(source)
        try:
            text_chunk = r.recognize_google(audio, language='ru')
            text_array.append(text_chunk)
            #print(text_chunk)
        except:
            pass
    # объединяем распознанные тексты
    text = combine_text(text_array)
    # удаляем ненужные файлы
    delete_tmp_chunks(chunks_src)
    
    return text

# итоговая функция распознавания

def wav_to_txt(path):
    r = sr.Recognizer()
    recognize_with_noise(path)
    
# для интеграции в main

parser = argparse.ArgumentParser(description='wav_to_txt')
parser.add_argument('wav_path', help='Path to .wav audio file')
parser.add_argument('out_path', help='Path to output text file')

if __name__ == '__main__':
    args = parser.parse_args()
    txt = wav_to_txt(args.wav_path)
    
    f = open(args.out_path, ""a"")
    f.write(txt) 
    f.close() 


;
# Import libraries
# from PIL import Image хуже распознается
import cv2 
import pytesseract 
import sys 
import os 
import argparse

parser = argparse.ArgumentParser(description='OCR')
parser.add_argument('in_filenames', help='Input filenames')
parser.add_argument('out_filename', help='Output filename')

def Pic2Txt(listImg, outfile):

	f = open(outfile, ""a"") 
	# Iterate through all the image
	for img in listImg: 

		# Recognize the text as string in image using pytesserct 
		text = str(((pytesseract.image_to_string(cv2.imread(img),lang = 'eng+rus')))) 

		# The recognized text is stored in variable text 
		# Any string processing may be applied on text 
		# Here, basic formatting has been done: 
		# In many PDFs, at line ending, if a word can't 
		# be written fully, a 'hyphen' is added. 
		# The rest of the word is written in the next line 
		# Eg: This is a sample text this word here GeeksF- 
		# orGeeks is half on first line, remaining on next. 
		# To remove this, we replace every '-\n' to ''. 
		text = text.replace('-\n', '')	 

		# Finally, write the processed text to the file. 
		#with open(fname, ""w"", encoding=""utf-8"") as f:
		f.write(text) 

	# Close the file after writing all the text. 
	f.close() 

if __name__ == '__main__':
    args = parser.parse_args()
    Pic2Txt(args.in_filenames.split(','), args.out_filename)
;
# -*- coding: utf-8 -*-

from test import Hello
import argparse
import sys
import socket
from TextFromPicture import Pic2Txt
import FFMPEGFrames
import glob


def main():
    parser = argparse.ArgumentParser()

    error_msg = ""Invalid Arguments\n\n"" \
                ""Commands: \n"" \
                ""  -t, --test                 Let's test it!\n"" \
                ""       Optional: --name='your_arg'  -   that'll print your string your_arg\n"" \
                ""  -v, --video             Convert video to pictures and then convert to text\n"" \
                ""       Mandatory: --in_filename='files/video.mp4' --out_filename='output.txt'  --fps='1'-  set input video, output file, frames per second ""

    if len(sys.argv) == 1:
        print(error_msg)

    elif str(sys.argv[1]) in ['-t', '--test']:
        parser.add_argument('-t', '--test', action='store_true')
        parser.add_argument(""--name"", default=socket.gethostname())

        args = parser.parse_args()

        test_class = Hello(args.name)
        test_class.print_hello()
    elif str(sys.argv[1]) in ['-v', '--video']:
        parser.add_argument('-v', '--video', action='store_true')
        parser.add_argument(""in_filename"", help='Input filename')
        parser.add_argument('out_filename', help='Output filename')
        parser.add_argument(""fps"", help='fps')
        args = vars(parser.parse_args())

        input = args[""in_filename""]
        output = args[""out_filename""]
        fps = args[""fps""]

        f = FFMPEGFrames.FFMPEGFrames(""images/"")
        f.extract_frames(input, fps)
        Pic2Txt(glob.glob(""images/*.png""), output)
    else:
        print(error_msg)


if __name__ == '__main__':
    main()

;
'''конвертация видеофайлов различных форматов в mp3'''

import os
import sys
import subprocess
from multiprocessing.pool import ThreadPool
from multiprocessing import cpu_count
import time
import datetime

def videotomp3(task):
    '''запускает новый подпроцесс ffmpeg, используя pipe и сохраняет файлы в формате mp3 в ту жу директорию, где хранятся оригинальные файлы '''
    root_path = task[0]
    filename = task[1]
    full_path = os.path.join(root_path, filename)
    new_filename = os.path.splitext(filename)[0] +"".mp3""
    new_path = os.path.join(root_path,
                            os.path.basename(root_path) + ""-"" + FOLDER_NAME,
                            new_filename)

    completed = subprocess.run([""ffmpeg"",
                                ""-loglevel"",
                                ""quiet"",
                                ""-hide_banner"",
                                ""-y"",
                                ""-i"",
                                full_path,
                                ""-write_id3v1"",
                                ""1"",
                                ""-id3v2_version"",
                                ""3"",
                                ""-q:a"",
                                ""0"",
                                ""-map"",
                                ""a"",
                                new_path],
                               stderr=subprocess.DEVNULL,
                               stdout=subprocess.DEVNULL,
                               stdin=subprocess.PIPE)
    #Если не предоставить pipe каналу stdin, то ffmpeg не закроется корректно
    #при конвертировании нескольких файлов и будет необходимо перезагрузить
    #терминал после авершения выполнения этого скрипта
    #удалить исходные файлы после их конвертации
    #if completed.returncode == 0:
        #subprocess.call([""rm"", full_path]) # удаляет исходный файл после конвертации
    print(f""'{new_path}' - return code {completed.returncode}"")
    if completed.returncode != 0:
        completed.timestamp = datetime.datetime.now().ctime()
    return completed

if __name__ == ""__main__"":
    FOLDERS = []
    FOLDER_NAME = ""MP3s""
    AUDIO_FILE_TYPES = (""webm"",
                        ""mpeg"",
                        ""ogg"",
                        ""mp4"",
                        ""m4p"",
                        ""m4v"",
                        ""avi"",
                        ""wmv"",
                        ""mov"",
                        ""flv"")
    STARTTIME = time.time()
    #get all of the source audio filenames
    for root, dirs, files in os.walk(os.getcwd()):
        source_audio_filenames = []
        for file in files:
            if file.endswith(AUDIO_FILE_TYPES):
                source_audio_filenames.append((root, file))
        FOLDERS.append((root, source_audio_filenames))

    with ThreadPool(cpu_count())as p:
        PROCESSES = []
        for Folder in FOLDERS:
            try:
                #Stop directories being created within the output directories
                if FOLDER_NAME in Folder[0]:
                    continue
                NewFolderName = os.path.basename(Folder[0]) + ""-"" + FOLDER_NAME
                os.mkdir(os.path.join(Folder[0], NewFolderName))
            except FileExistsError:
                pass
            PROCESSES += Folder[1]
        print(f""Transcoding {len(PROCESSES)} Audio files"")
        JOBS = p.map(converttomp3, PROCESSES)
        FAILED_JOBS = []
        for job in JOBS:
            if job.returncode != 0:
                FAILED_JOBS.append(job)
        MESSAGE = (f""Transcode Finished! \r {len(PROCESSES)-len(FAILED_JOBS)}/{len(PROCESSES)} ""
                   f""Audio files transcoded in \r{time.time() - STARTTIME:.4f} seconds"")
        subprocess.run([""notify-send"", ""--urgency=low"", MESSAGE])
        if len(FAILED_JOBS) > 0:       
            with open(""nautilus-transcode.log"", 'a+') as f:
                for failedJob in FAILED_JOBS:
                    f.write(f""{failedJob.timestamp} args:{failedJob.args}""
                            f""return code:{failedJob.returncode}\n"")

    print(""Done"")
    sys.exit(0)



;
",8,"[{'FFMPEGFrames.py': 'import os\nimport subprocess\n\n\nclass FFMPEGFrames:\n\n    def __init__(self, output):\n        self.output = output\n\n    def extract_frames(self, input, fps):\n        self.output = input.split(\'/\')[-1].split(\'.\')[0]\n\n        if not os.path.exists(self.output):\n            os.makedirs(self.output)\n\n        query = ""ffmpeg -i "" + input + "" -vf fps="" + \\\n            str(fps) + "" "" + self.output + ""output%02d.png""\n        response = subprocess.Popen(\n            query, shell=True, stdout=subprocess.PIPE).stdout.read()\n        s = str(response).encode(\'utf-8\')\n\n;\n'}, {'SpeechRecognition.py': '\n# coding: utf-8\n\n# ### Функции пред- и постобработки\n\n# In[1]:\n\n\nfrom pydub import AudioSegment\nfrom scipy.io import wavfile\nimport os\nimport numpy as np\n\n\n# Делим аудио (wav) на короткие части, сохраняем в папку tmp_slices\n\n# In[2]:\n\n\ndef divide_audio(audio_src, slice_length_ms=3000, overlap_ms=500):\n    audio = AudioSegment.from_file(audio_src, ""wav"")\n\n    slices = np.arange(0, len(audio)-overlap_ms, slice_length_ms-overlap_ms)\n    \n    path = ""tmp_slices""\n    os.mkdir(path)\n    audio_slices_src = []\n    i = 0\n    \n    for start, end in zip(slices[:-1], slices[1:]):\n        slice_ = audio[start : end+overlap_ms]\n        # сохраняем кусочки аудио\n        slice_name = ""tmp_slices\\slice{0}.wav"".format(i)\n        audio_slices_src.append(slice_name)\n        slice_.export(slice_name, format=""wav"")\n        i+=1\n        \n    if len(audio) - end > overlap_ms:\n        slice_ = audio[end : len(audio)]\n        slice_name = ""tmp_slices\\slice{0}.wav"".format(i)\n        audio_slices_src.append(slice_name)\n        slice_.export(slice_name, format=""wav"")\n        \n    return audio_slices_src\n\n\n# Удаляем папку tmp_slices с частями аудио\n\n# In[3]:\n\n\ndef delete_tmp_slices(audio_slices_src):\n    for slice_ in audio_slices_src:\n        os.remove(slice_)\n    os.rmdir(\'tmp_slices\')\n\n\n# Соединяем распознанный по частям текст\n\n# In[4]:\n\n\ndef combine_text(text_array):\n    result_text = \'\'\n    \n    prev_splited = []\n    \n    for text in text_array:\n        processed_text = \'\'\n        \n        splited = text.lower().split()\n        \n        j = 0\n        while j < min(len(splited), len(prev_splited)):\n            if splited[j] != prev_splited[-1-j]:\n                break\n            j += 1\n        \n        for i in range(j, len(splited)):\n            processed_text += splited[i] + \' \'\n        \n        result_text += processed_text\n        \n        prev_splited = splited        \n        \n    return result_text\n\n\n# ### Распознавание речи\n\n# Библиотека SpeechRecognition ( https://pypi.org/project/SpeechRecognition/ )\n# \n# Используется распознавание при помощи Google Speech Recognition\n# \n# Распознавание текста происходит непрерывно, даже когда речи нет, а есть только шум. Если распознать какие-то слова не удается, программа выдает ошибку. Поэтому нужно делить аудио на короткие части и распознавать их отдельно.\n# \n# Список языковых кодов для Google Speech Recognition: https://www.science.co.il/language/Locale-codes.php\n\n# In[5]:\n\n\nimport speech_recognition as sr\n\n\n# Распознавание без учета шума\n\n# In[6]:\n\n\ndef recognize_no_noise(audio_src):\n    r = sr.Recognizer()\n    \n    # делим аудио на части\n    chunks_src = divide_audio(audio_src)\n    # распознаем каждую часть\n    text_array = []\n    for chunk_src in chunks_src:\n        a = sr.AudioFile(chunk_src)\n        #print(\'analyzing \', chunk_src)\n        with a as source:\n            audio = r.record(source)\n        try:\n            text_chunk = r.recognize_google(audio, language=\'ru\')\n            text_array.append(text_chunk)\n            #print(\'!\',text_chunk)\n        except:\n            pass\n    # объединяем распознанные тексты\n    text = combine_text(text_array)\n    \n    # удаляем ненужные файлы\n    delete_tmp_slices(chunks_src)\n    \n    return text\n\n\n# In[7]:\n\n\n#print(recognize_no_noise(\'audio/test1.wav\'))\n\n\n# Распознавание с учетом шума: уровень шума определяется автоматически\n\n# In[8]:\n\n\ndef recognize_with_noise(audio_src):\n    r = sr.Recognizer()\n    \n    # делим аудио на части\n    chunks_src = divide_audio(audio_src)\n    # распознаем каждую часть\n    text_array = []\n    for chunk_src in chunks_src:\n        a = sr.AudioFile(chunk_src)\n        #print(\'analyzing \', chunk_src)\n        with a as source:\n            r.adjust_for_ambient_noise(source) # учитываем шум\n            audio = r.record(source)\n        try:\n            text_chunk = r.recognize_google(audio, language=\'ru\')\n            text_array.append(text_chunk)\n            #print(text_chunk)\n        except:\n            pass\n    # объединяем распознанные тексты\n    text = combine_text(text_array)\n    # удаляем ненужные файлы\n    delete_tmp_slices(chunks_src)\n    \n    return text\n\n\n# In[9]:\n\n\n#print(recognize_with_noise(\'audio/test1.wav\'))\n\n\n# Итоговая функция распознавания, в которой выбирается наилучший вариант распознавания\n\n# In[10]:\n\n\ndef wav_to_txt(audio_src, out_txt_src):\n    \n    no_noise_txt = recognize_no_noise(audio_src)\n    noise_txt = recognize_with_noise(audio_src)\n    \n    text = no_noise_txt\n    if len(noise_txt.split()) > len(text.split()):\n        text = noise_txt\n        \n    # записываем в файл\n    out = open(out_txt_src, \'a\')\n    out.write(text)\n    out.close()\n\n\n# Для интеграции в main\n\n# In[12]:\n\n\n#wav_to_txt(\'audio/test1.wav\', \'TEXT.txt\')\n\n\n# In[ ]:\n\n\nparser = argparse.ArgumentParser(description=\'wav_to_txt\')\nparser.add_argument(\'wav_path\', help=\'Path to .wav audio file\')\nparser.add_argument(\'out_path\', help=\'Path to output .txt file\')\n\nif __name__ == \'__main__\':\n    args = parser.parse_args()\n    wav_to_txt(args.wav_path, args.out_path)\n\n\n;\n'}, {'SpeechRecognition_mp3_to_text.py': '<<<<<<< HEAD:SpeechRecognition_2_mp3_to_text.py\n# -*- coding: utf-8 -*-\n=======\n# coding: utf-8\n>>>>>>> origin/KateShestakova:SpeechRecognition_mp3_to_text.py\n\n# ### Функции пред- и постобработки\n\nfrom pydub import AudioSegment\nfrom pydub.utils import make_chunks\nimport os\n\nimport speech_recognition as sr\n\n# Перевод из формата mp3 в wav\n\ndef mp3_to_wav(mp3_src, wav_src):\n    sound = AudioSegment.from_mp3(mp3_src)\n    sound.export(wav_src, format=""wav"")\n\n# Делим аудио (wav) на короткие части, сохраняем в папку tmp_chunks\n\ndef divide_audio(audio_src, chunk_length_ms):\n    audio = AudioSegment.from_file(audio_src, ""wav"") \n    chunks = make_chunks(audio, chunk_length_ms)\n    \n    path = ""tmp_chunks""\n    os.mkdir(path)\n    \n    chunks_src = []\n    for i, chunk in enumerate(chunks):\n        chunk_name = ""tmp_chunks\\chunk{0}.wav"".format(i)\n        chunks_src.append(chunk_name)\n        chunk.export(chunk_name, format=""wav"")\n        \n    return chunks_src\n\n\n# Удаляем папку tmp_chunks с частями аудио\n\ndef delete_tmp_chunks(chunks_src):\n    for chunk in chunks_src:\n        os.remove(chunk)\n    os.rmdir(\'tmp_chunks\')\n\n# Соединяем распознанный по частям текст\n\ndef combine_text(text_array):\n    result_text = \'\'\n    for text in text_array:\n        result_text += text + \' \'\n    return result_text\n\n\n# ### Распознавание речи\n\n# Библиотека SpeechRecognition ( https://pypi.org/project/SpeechRecognition/ )\n# \n# Используется распознавание при помощи Google Speech Recognition\n# \n# Распознавание текста происходит непрерывно, даже когда речи нет, а есть только шум. Если распознать какие-то слова не удается, программа выдает ошибку. Поэтому нужно делить аудио на короткие части и распознавать их отдельно.\n# \n# Список языковых кодов для Google Speech Recognition: https://www.science.co.il/language/Locale-codes.php\n\n\n# Распознавание без учета шума\n\ndef recognize(audio_src):\n    # делим аудио на части\n    chunks_src = divide_audio(audio_src, 3000)\n    # распознаем каждую часть\n    text_array = []\n    for chunk_src in chunks_src:\n        a = sr.AudioFile(chunk_src)\n        with a as source:\n            audio = r.record(source)\n        try:\n            text_array.append(r.recognize_google(audio, language=\'ru\'))\n        except:\n            pass\n    # объединяем распознанные тексты\n    text = combine_text(text_array)\n    # удаляем ненужные файлы\n    delete_tmp_chunks(chunks_src)\n    \n    return text\n\n# Распознавание с учетом шума: уровень шума определяется автоматически\n\ndef recognize_with_noise(audio_src):\n    # делим аудио на части\n    chunks_src = divide_audio(audio_src, 3000)\n    # распознаем каждую часть\n    text_array = []\n    for chunk_src in chunks_src:\n        a = sr.AudioFile(chunk_src)\n        with a as source:\n            r.adjust_for_ambient_noise(source) # учитываем шум\n            audio = r.record(source)\n        try:\n            text_chunk = r.recognize_google(audio, language=\'ru\')\n            text_array.append(text_chunk)\n            #print(text_chunk)\n        except:\n            pass\n    # объединяем распознанные тексты\n    text = combine_text(text_array)\n    # удаляем ненужные файлы\n    delete_tmp_chunks(chunks_src)\n    \n    return text\n\n# итоговая функция распознавания\n\ndef wav_to_txt(path):\n    r = sr.Recognizer()\n    recognize_with_noise(path)\n    \n# для интеграции в main\n\nparser = argparse.ArgumentParser(description=\'wav_to_txt\')\nparser.add_argument(\'wav_path\', help=\'Path to .wav audio file\')\nparser.add_argument(\'out_path\', help=\'Path to output text file\')\n\nif __name__ == \'__main__\':\n    args = parser.parse_args()\n    txt = wav_to_txt(args.wav_path)\n    \n    f = open(args.out_path, ""a"")\n    f.write(txt) \n    f.close() \n\n\n;\n'}, {'TextFromPicture.py': '# Import libraries\n# from PIL import Image хуже распознается\nimport cv2 \nimport pytesseract \nimport sys \nimport os \nimport argparse\n\nparser = argparse.ArgumentParser(description=\'OCR\')\nparser.add_argument(\'in_filenames\', help=\'Input filenames\')\nparser.add_argument(\'out_filename\', help=\'Output filename\')\n\ndef Pic2Txt(listImg, outfile):\n\n\tf = open(outfile, ""a"") \n\t# Iterate through all the image\n\tfor img in listImg: \n\n\t\t# Recognize the text as string in image using pytesserct \n\t\ttext = str(((pytesseract.image_to_string(cv2.imread(img),lang = \'eng+rus\')))) \n\n\t\t# The recognized text is stored in variable text \n\t\t# Any string processing may be applied on text \n\t\t# Here, basic formatting has been done: \n\t\t# In many PDFs, at line ending, if a word can\'t \n\t\t# be written fully, a \'hyphen\' is added. \n\t\t# The rest of the word is written in the next line \n\t\t# Eg: This is a sample text this word here GeeksF- \n\t\t# orGeeks is half on first line, remaining on next. \n\t\t# To remove this, we replace every \'-\\n\' to \'\'. \n\t\ttext = text.replace(\'-\\n\', \'\')\t \n\n\t\t# Finally, write the processed text to the file. \n\t\t#with open(fname, ""w"", encoding=""utf-8"") as f:\n\t\tf.write(text) \n\n\t# Close the file after writing all the text. \n\tf.close() \n\nif __name__ == \'__main__\':\n    args = parser.parse_args()\n    Pic2Txt(args.in_filenames.split(\',\'), args.out_filename)\n;\n'}, {'main.py': '# -*- coding: utf-8 -*-\n\nfrom test import Hello\nimport argparse\nimport sys\nimport socket\nfrom TextFromPicture import Pic2Txt\nimport FFMPEGFrames\nimport glob\n\n\ndef main():\n    parser = argparse.ArgumentParser()\n\n    error_msg = ""Invalid Arguments\\n\\n"" \\\n                ""Commands: \\n"" \\\n                ""  -t, --test                 Let\'s test it!\\n"" \\\n                ""       Optional: --name=\'your_arg\'  -   that\'ll print your string your_arg\\n"" \\\n                ""  -v, --video             Convert video to pictures and then convert to text\\n"" \\\n                ""       Mandatory: --in_filename=\'files/video.mp4\' --out_filename=\'output.txt\'  --fps=\'1\'-  set input video, output file, frames per second ""\n\n    if len(sys.argv) == 1:\n        print(error_msg)\n\n    elif str(sys.argv[1]) in [\'-t\', \'--test\']:\n        parser.add_argument(\'-t\', \'--test\', action=\'store_true\')\n        parser.add_argument(""--name"", default=socket.gethostname())\n\n        args = parser.parse_args()\n\n        test_class = Hello(args.name)\n        test_class.print_hello()\n    elif str(sys.argv[1]) in [\'-v\', \'--video\']:\n        parser.add_argument(\'-v\', \'--video\', action=\'store_true\')\n        parser.add_argument(""in_filename"", help=\'Input filename\')\n        parser.add_argument(\'out_filename\', help=\'Output filename\')\n        parser.add_argument(""fps"", help=\'fps\')\n        args = vars(parser.parse_args())\n\n        input = args[""in_filename""]\n        output = args[""out_filename""]\n        fps = args[""fps""]\n\n        f = FFMPEGFrames.FFMPEGFrames(""images/"")\n        f.extract_frames(input, fps)\n        Pic2Txt(glob.glob(""images/*.png""), output)\n    else:\n        print(error_msg)\n\n\nif __name__ == \'__main__\':\n    main()\n\n;\n'}, {'mp3_to_wav.py': ''}, {'video2mp3.py': '\'\'\'конвертация видеофайлов различных форматов в mp3\'\'\'\n\nimport os\nimport sys\nimport subprocess\nfrom multiprocessing.pool import ThreadPool\nfrom multiprocessing import cpu_count\nimport time\nimport datetime\n\ndef videotomp3(task):\n    \'\'\'запускает новый подпроцесс ffmpeg, используя pipe и сохраняет файлы в формате mp3 в ту жу директорию, где хранятся оригинальные файлы \'\'\'\n    root_path = task[0]\n    filename = task[1]\n    full_path = os.path.join(root_path, filename)\n    new_filename = os.path.splitext(filename)[0] +"".mp3""\n    new_path = os.path.join(root_path,\n                            os.path.basename(root_path) + ""-"" + FOLDER_NAME,\n                            new_filename)\n\n    completed = subprocess.run([""ffmpeg"",\n                                ""-loglevel"",\n                                ""quiet"",\n                                ""-hide_banner"",\n                                ""-y"",\n                                ""-i"",\n                                full_path,\n                                ""-write_id3v1"",\n                                ""1"",\n                                ""-id3v2_version"",\n                                ""3"",\n                                ""-q:a"",\n                                ""0"",\n                                ""-map"",\n                                ""a"",\n                                new_path],\n                               stderr=subprocess.DEVNULL,\n                               stdout=subprocess.DEVNULL,\n                               stdin=subprocess.PIPE)\n    #Если не предоставить pipe каналу stdin, то ffmpeg не закроется корректно\n    #при конвертировании нескольких файлов и будет необходимо перезагрузить\n    #терминал после авершения выполнения этого скрипта\n    #удалить исходные файлы после их конвертации\n    #if completed.returncode == 0:\n        #subprocess.call([""rm"", full_path]) # удаляет исходный файл после конвертации\n    print(f""\'{new_path}\' - return code {completed.returncode}"")\n    if completed.returncode != 0:\n        completed.timestamp = datetime.datetime.now().ctime()\n    return completed\n\nif __name__ == ""__main__"":\n    FOLDERS = []\n    FOLDER_NAME = ""MP3s""\n    AUDIO_FILE_TYPES = (""webm"",\n                        ""mpeg"",\n                        ""ogg"",\n                        ""mp4"",\n                        ""m4p"",\n                        ""m4v"",\n                        ""avi"",\n                        ""wmv"",\n                        ""mov"",\n                        ""flv"")\n    STARTTIME = time.time()\n    #get all of the source audio filenames\n    for root, dirs, files in os.walk(os.getcwd()):\n        source_audio_filenames = []\n        for file in files:\n            if file.endswith(AUDIO_FILE_TYPES):\n                source_audio_filenames.append((root, file))\n        FOLDERS.append((root, source_audio_filenames))\n\n    with ThreadPool(cpu_count())as p:\n        PROCESSES = []\n        for Folder in FOLDERS:\n            try:\n                #Stop directories being created within the output directories\n                if FOLDER_NAME in Folder[0]:\n                    continue\n                NewFolderName = os.path.basename(Folder[0]) + ""-"" + FOLDER_NAME\n                os.mkdir(os.path.join(Folder[0], NewFolderName))\n            except FileExistsError:\n                pass\n            PROCESSES += Folder[1]\n        print(f""Transcoding {len(PROCESSES)} Audio files"")\n        JOBS = p.map(converttomp3, PROCESSES)\n        FAILED_JOBS = []\n        for job in JOBS:\n            if job.returncode != 0:\n                FAILED_JOBS.append(job)\n        MESSAGE = (f""Transcode Finished! \\r {len(PROCESSES)-len(FAILED_JOBS)}/{len(PROCESSES)} ""\n                   f""Audio files transcoded in \\r{time.time() - STARTTIME:.4f} seconds"")\n        subprocess.run([""notify-send"", ""--urgency=low"", MESSAGE])\n        if len(FAILED_JOBS) > 0:       \n            with open(""nautilus-transcode.log"", \'a+\') as f:\n                for failedJob in FAILED_JOBS:\n                    f.write(f""{failedJob.timestamp} args:{failedJob.args}""\n                            f""return code:{failedJob.returncode}\\n"")\n\n    print(""Done"")\n    sys.exit(0)\n\n\n\n;\n'}, {'video_to_audio.py': ''}]","[{'FFMPEGFrames.py': 'import os\nimport subprocess\n\n\nclass FFMPEGFrames:\n\n    def __init__(self, output):\n        self.output = output\n\n    def extract_frames(self, input, fps):\n        self.output = input.split(\'/\')[-1].split(\'.\')[0]\n\n        if not os.path.exists(self.output):\n            os.makedirs(self.output)\n\n        query = ""ffmpeg -i "" + input + "" -vf fps="" + \\\n            str(fps) + "" "" + self.output + ""/output%02d.png""\n        response = subprocess.Popen(\n            query, shell=True, stdout=subprocess.PIPE).stdout.read()\n        s = str(response).encode(\'utf-8\')\n\n;\n'}, {'SpeechRecognition.py': '# coding: utf-8\n\n# ### Функции пред- и постобработки\n\n# In[1]:\n\n\nfrom pydub import AudioSegment\nfrom scipy.io import wavfile\nimport os\nimport numpy as np\nimport speech_recognition as sr\nimport argparse\n\n\n\nparser = argparse.ArgumentParser(description=\'wav_to_txt\')\nparser.add_argument(\'wav_path\', help=\'Path to .wav audio file\')\nparser.add_argument(\'out_path\', help=\'Path to output .txt file\')\n# Делим аудио (wav) на короткие части, сохраняем в папку tmp_slices\n\n# In[2]:\n\n\n\n\ndef divide_audio(audio_src, slice_length_ms=3000, overlap_ms=500):\n    audio = AudioSegment.from_file(audio_src, ""wav"")\n\n    slices = np.arange(0, len(audio) - overlap_ms, slice_length_ms - overlap_ms)\n\n    path = ""tmp_slices""\n    os.mkdir(path)\n    audio_slices_src = []\n    i = 0\n\n    for start, end in zip(slices[:-1], slices[1:]):\n        slice_ = audio[start: end + overlap_ms]\n        # сохраняем кусочки аудио\n        slice_name = ""tmp_slices\\slice{0}.wav"".format(i)\n        audio_slices_src.append(slice_name)\n        slice_.export(slice_name, format=""wav"")\n        i += 1\n\n    if len(audio) - end > overlap_ms:\n        slice_ = audio[end: len(audio)]\n        slice_name = ""tmp_slices\\slice{0}.wav"".format(i)\n        audio_slices_src.append(slice_name)\n        slice_.export(slice_name, format=""wav"")\n\n    return audio_slices_src\n\n\n# Удаляем папку tmp_slices с частями аудио\n\n# In[3]:\n\n\ndef delete_tmp_slices(audio_slices_src):\n    for slice_ in audio_slices_src:\n        os.remove(slice_)\n    os.rmdir(\'tmp_slices\')\n\n\n# Соединяем распознанный по частям текст\n\n# In[4]:\n\n\ndef combine_text(text_array):\n    result_text = \'\'\n\n    prev_splited = []\n\n    for text in text_array:\n        processed_text = \'\'\n\n        splited = text.lower().split()\n\n        j = 0\n        while j < min(len(splited), len(prev_splited)):\n            if splited[j] != prev_splited[-1 - j]:\n                break\n            j += 1\n\n        for i in range(j, len(splited)):\n            processed_text += splited[i] + \' \'\n\n        result_text += processed_text\n\n        prev_splited = splited\n\n    return result_text\n\n\n# ### Распознавание речи\n\n# Библиотека SpeechRecognition ( https://pypi.org/project/SpeechRecognition/ )\n# \n# Используется распознавание при помощи Google Speech Recognition\n# \n# Распознавание текста происходит непрерывно, даже когда речи нет, а есть только шум. Если распознать какие-то слова не удается, программа выдает ошибку. Поэтому нужно делить аудио на короткие части и распознавать их отдельно.\n# \n# Список языковых кодов для Google Speech Recognition: https://www.science.co.il/language/Locale-codes.php\n\n# In[5]:\n\n\n# Распознавание без учета шума\n\n# In[6]:\n\n\ndef recognize_no_noise(audio_src):\n    r = sr.Recognizer()\n\n    # делим аудио на части\n    chunks_src = divide_audio(audio_src)\n    # распознаем каждую часть\n    text_array = []\n    for chunk_src in chunks_src:\n        a = sr.AudioFile(chunk_src)\n        # print(\'analyzing \', chunk_src)\n        with a as source:\n            audio = r.record(source)\n        try:\n            text_chunk = r.recognize_google(audio, language=\'ru\')\n            text_array.append(text_chunk)\n            # print(\'!\',text_chunk)\n        except:\n            pass\n    # объединяем распознанные тексты\n    text = combine_text(text_array)\n\n    # удаляем ненужные файлы\n    delete_tmp_slices(chunks_src)\n\n    return text\n\n\n# In[7]:\n\n\n# print(recognize_no_noise(\'audio/test1.wav\'))\n\n\n# Распознавание с учетом шума: уровень шума определяется автоматически\n\n# In[8]:\n\n\ndef recognize_with_noise(audio_src):\n    r = sr.Recognizer()\n\n    # делим аудио на части\n    chunks_src = divide_audio(audio_src)\n    # распознаем каждую часть\n    text_array = []\n    for chunk_src in chunks_src:\n        a = sr.AudioFile(chunk_src)\n        # print(\'analyzing \', chunk_src)\n        with a as source:\n            r.adjust_for_ambient_noise(source)  # учитываем шум\n            audio = r.record(source)\n        try:\n            text_chunk = r.recognize_google(audio, language=\'ru\')\n            text_array.append(text_chunk)\n            # print(text_chunk)\n        except:\n            pass\n    # объединяем распознанные тексты\n    text = combine_text(text_array)\n    # удаляем ненужные файлы\n    delete_tmp_slices(chunks_src)\n\n    return text\n\n\n# In[9]:\n\n\n# print(recognize_with_noise(\'audio/test1.wav\'))\n\n\n# Итоговая функция распознавания, в которой выбирается наилучший вариант распознавания\n\n# In[10]:\n\n\ndef wav_to_txt(audio_src, out_txt_src):\n    print(f""Speech recognition started"")\n    no_noise_txt = recognize_no_noise(audio_src)\n    noise_txt = recognize_with_noise(audio_src)\n\n    text = no_noise_txt\n    if len(noise_txt.split()) > len(text.split()):\n        text = noise_txt\n\n    # записываем в файл\n    out = open(out_txt_src, \'a\')\n    out.write(text)\n    out.close()\n    print(f""Speech recognition finished"")\n\n\n# Для интеграции в main\n\n# In[12]:\n\n\n# wav_to_txt(\'audio/test1.wav\', \'TEXT.txt\')\n\n\n# In[ ]:\n\n\nif __name__ == \'__main__\':\n    args = parser.parse_args()\n    wav_to_txt(args.wav_path, args.out_path)\n\n;\n'}, {'SpeechRecognition_mp3_to_text.py': ''}, {'TextFromPicture.py': '# Import libraries\n# from PIL import Image хуже распознается\nimport cv2 \nimport pytesseract \nimport sys \nimport os \nimport argparse\n\n\nparser = argparse.ArgumentParser(description=\'OCR\')\nparser.add_argument(\'in_filenames\', help=\'Input filenames\')\nparser.add_argument(\'out_filename\', help=\'Output filename\')\n\ndef Pic2Txt(listImg, outfile):\n\n\tf = open(outfile, ""a"") \n\t# Iterate through all the image\n\tfor img in listImg: \n\n\t\t# Recognize the text as string in image using pytesserct\n\t\ttext = str(((pytesseract.image_to_string(cv2.imread(img),lang = \'eng+rus\'))))\n\n\t\t# The recognized text is stored in variable text \n\t\t# Any string processing may be applied on text \n\t\t# Here, basic formatting has been done: \n\t\t# In many PDFs, at line ending, if a word can\'t \n\t\t# be written fully, a \'hyphen\' is added. \n\t\t# The rest of the word is written in the next line \n\t\t# Eg: This is a sample text this word here GeeksF- \n\t\t# orGeeks is half on first line, remaining on next. \n\t\t# To remove this, we replace every \'-\\n\' to \'\'. \n\t\ttext = text.replace(\'-\\n\', \'\')\t \n\n\t\t# Finally, write the processed text to the file. \n\t\t#with open(fname, ""w"", encoding=""utf-8"") as f:\n\t\tf.write(text) \n\n\t# Close the file after writing all the text. \n\tf.close() \n\nif __name__ == \'__main__\':\n    args = parser.parse_args()\n    Pic2Txt(args.in_filenames.split(\',\'), args.out_filename)\n;\n'}, {'main.py': '# -*- coding: utf-8 -*-\n\nfrom test import Hello\nimport argparse\nimport sys\nimport socket\nfrom TextFromPicture import Pic2Txt\nimport FFMPEGFrames\nimport glob\nfrom SpeechRecognition import wav_to_txt\nimport video_to_audio\n\ndef main():\n    parser = argparse.ArgumentParser()\n\n    error_msg = ""Invalid Arguments\\n\\n"" \\\n                ""Commands: \\n"" \\\n                ""  -t, --test                 Let\'s test it!\\n"" \\\n                ""       Optional: --name=\'your_arg\'  -   that\'ll print your string your_arg\\n"" \\\n                ""  -v, --video             Convert video to pictures and then convert to text\\n"" \\\n                ""       Mandatory: --in_filename=\'files/video.mp4\' --out_filename=\'output.txt\'  --fps=\'1\'-  set input video, output file, frames per second ""\n\n    if len(sys.argv) == 1:\n        print(error_msg)\n\n    elif str(sys.argv[1]) in [\'-t\', \'--test\']:\n        parser.add_argument(\'-t\', \'--test\', action=\'store_true\')\n        parser.add_argument(""--name"", default=socket.gethostname())\n\n        args = parser.parse_args()\n\n        test_class = Hello(args.name)\n        test_class.print_hello()\n    elif str(sys.argv[1]) in [\'-v\', \'--video\']:\n        parser.add_argument(\'-v\', \'--video\', action=\'store_true\')\n        parser.add_argument(""in_filename"", help=\'Input filename\')\n        parser.add_argument(\'out_filename\', help=\'Output filename\')\n        parser.add_argument(""fps"", help=\'fps\')\n        args = vars(parser.parse_args())\n\n        input = args[""in_filename""]\n        output = args[""out_filename""]\n        fps = args[""fps""]\n\n        f = FFMPEGFrames.FFMPEGFrames(""images/"")\n        f.extract_frames(input, fps)\n        Pic2Txt(glob.glob(f.output + ""/*.png""), output)\n    elif str(sys.argv[1] in [\'-a\', \'--audio\']):\n        parser.add_argument(\'-a\', \'--audio\', action=\'store_true\')\n        parser.add_argument(""in_filename"", help=\'Input filename\')\n        parser.add_argument(\'out_filename\', help=\'Output filename\')\n        args = vars(parser.parse_args())\n\n        input = args[""in_filename""]\n        output = args[""out_filename""]\n\n        f = video_to_audio.video_to_audio(""/WAVs"")\n        f.video_to_wav(input)\n        wav_to_txt(f.output, output)\n\n    else:\n        print(error_msg)\n\n\nif __name__ == \'__main__\':\n    main()\n\n;\n'}, {'mp3_to_wav.py': 'import subprocess\nimport argparse\nimport os\n\nparser = argparse.ArgumentParser(description=\'mp3_to_wav\')\nparser.add_argument(\'in_mp3\', help=\'Input .mp3 file\')\n\ndef mp3_to_wav(mp3_path):\n    wavs_path = ""WAVs""\n    wav_path = wavs_path + ""/output.wav""\n    if not os.path.exists(wavs_path):\n        os.mkdir(wavs_path)\n\n    subprocess.run([""ffmpeg"",\n                ""-loglevel"",\n                ""quiet"",\n                ""-hide_banner"",\n                ""-y"",\n                ""-i"",\n                mp3_path,\n                ""-write_id3v1"",\n                ""1"",\n                ""-id3v2_version"",\n                ""3"",\n                ""-q:a"",\n                ""0"",\n                ""-map"",\n                ""a"",\n                wav_path],\n               stderr=subprocess.DEVNULL,\n               stdout=subprocess.DEVNULL,\n               stdin=subprocess.PIPE)\n\n\nif __name__ == \'__main__\':\n    args = parser.parse_args()\n    mp3_to_wav(args.in_mp3)\n;\n'}, {'video2mp3.py': '\'\'\'конвертация видеофайлов различных форматов в mp3\'\'\'\n\nimport os\nimport sys\nimport subprocess\nfrom multiprocessing.pool import ThreadPool\nfrom multiprocessing import cpu_count\nimport time\nimport datetime\n\ndef videotomp3(task):\n    \'\'\'запускает новый подпроцесс ffmpeg, используя pipe и сохраняет файлы в формате mp3 в ту жу директорию, где хранятся оригинальные файлы \'\'\'\n    root_path = task[0]\n    filename = task[1]\n    full_path = os.path.join(root_path, filename)\n    new_filename = os.path.splitext(filename)[0] +"".mp3""\n    new_path = os.path.join(root_path,\n                            os.path.basename(root_path) + ""-"" + FOLDER_NAME,\n                            new_filename)\n\n    completed = subprocess.run([""ffmpeg"",\n                                ""-loglevel"",\n                                ""quiet"",\n                                ""-hide_banner"",\n                                ""-y"",\n                                ""-i"",\n                                full_path,\n                                ""-write_id3v1"",\n                                ""1"",\n                                ""-id3v2_version"",\n                                ""3"",\n                                ""-q:a"",\n                                ""0"",\n                                ""-map"",\n                                ""a"",\n                                new_path],\n                               stderr=subprocess.DEVNULL,\n                               stdout=subprocess.DEVNULL,\n                               stdin=subprocess.PIPE)\n    #Если не предоставить pipe каналу stdin, то ffmpeg не закроется корректно\n    #при конвертировании нескольких файлов и будет необходимо перезагрузить\n    #терминал после авершения выполнения этого скрипта\n    #удалить исходные файлы после их конвертации\n    #if completed.returncode == 0:\n        #subprocess.call([""rm"", full_path]) # удаляет исходный файл после конвертации\n    print(f""\'{new_path}\' - return code {completed.returncode}"")\n    if completed.returncode != 0:\n        completed.timestamp = datetime.datetime.now().ctime()\n    return completed\n\nif __name__ == ""__main__"":\n    FOLDERS = []\n    FOLDER_NAME = ""MP3s""\n    AUDIO_FILE_TYPES = (""webm"",\n                        ""mpeg"",\n                        ""ogg"",\n                        ""mp4"",\n                        ""m4p"",\n                        ""m4v"",\n                        ""avi"",\n                        ""wmv"",\n                        ""mov"",\n                        ""flv"")\n    STARTTIME = time.time()\n    #get all of the source audio filenames\n    for root, dirs, files in os.walk(os.getcwd()):\n        source_audio_filenames = []\n        for file in files:\n            if file.endswith(AUDIO_FILE_TYPES):\n                source_audio_filenames.append((root, file))\n        FOLDERS.append((root, source_audio_filenames))\n\n    with ThreadPool(cpu_count())as p:\n        PROCESSES = []\n        for Folder in FOLDERS:\n            try:\n                #Stop directories being created within the output directories\n                if FOLDER_NAME in Folder[0]:\n                    continue\n                NewFolderName = os.path.basename(Folder[0]) + ""-"" + FOLDER_NAME\n                os.mkdir(os.path.join(Folder[0], NewFolderName))\n            except FileExistsError:\n                pass\n            PROCESSES += Folder[1]\n        print(f""Transcoding {len(PROCESSES)} Audio files"")\n        JOBS = p.map(converttomp3, PROCESSES)\n        FAILED_JOBS = []\n        for job in JOBS:\n            if job.returncode != 0:\n                FAILED_JOBS.append(job)\n        MESSAGE = (f""Transcode Finished! \\r {len(PROCESSES)-len(FAILED_JOBS)}/{len(PROCESSES)} ""\n                   f""Audio files transcoded in \\r{time.time() - STARTTIME:.4f} seconds"")\n        subprocess.run([""notify-send"", ""--urgency=low"", MESSAGE])\n        if len(FAILED_JOBS) > 0:       \n            with open(""nautilus-transcode.log"", \'a+\') as f:\n                for failedJob in FAILED_JOBS:\n                    f.write(f""{failedJob.timestamp} args:{failedJob.args}""\n                            f""return code:{failedJob.returncode}\\n"")\n\n    print(""Done"")\n    sys.exit(0)\n\n\n\n;\nimport subprocess\nimport argparse\nimport os\n\nparser = argparse.ArgumentParser(description=\'video2mp3\')\nparser.add_argument(\'video_path\', help=\'Path to video file\')\n\n\ndef video2mp3(video_path):\n    mp3s_path = ""mp3s""\n    mp3_path = mp3s_path + ""/output.mp3""\n    if not os.path.exists(mp3s_path):\n        os.mkdir(mp3s_path)\n\n    subprocess.run([""ffmpeg"",\n                ""-loglevel"",\n                ""quiet"",\n                ""-hide_banner"",\n                ""-y"",\n                ""-i"",\n                video_path,\n                ""-write_id3v1"",\n                ""1"",\n                ""-id3v2_version"",\n                ""3"",\n                ""-q:a"",\n                ""0"",\n                ""-map"",\n                ""a"",\n                mp3_path],\n               stderr=subprocess.DEVNULL,\n               stdout=subprocess.DEVNULL,\n               stdin=subprocess.PIPE)\n\n\nif __name__ == \'__main__\':\n    #path = ""files/videoplayback.mp4""\n    #video2mp3(path)\n    args = parser.parse_args()\n    video2mp3(args.video_path)\n\n;\n'}, {'video_to_audio.py': 'import subprocess\nimport argparse\nimport os\nimport time\n\nparser = argparse.ArgumentParser(description=\'video_to_wav\')\nparser.add_argument(\'video_path\', help=\'Path to video file\')\n\n\nclass video_to_audio:\n\n    def __init__(self, output):\n        self.output = output\n\n    def video_to_wav(self, video_path):\n        wavs_path = ""WAVs""\n        name = video_path.split(\'/\')[-1].split(\'.\')[0]\n        self.output = wavs_path + ""/"" + name + "".wav""\n        if not os.path.exists(wavs_path):\n            os.mkdir(wavs_path)\n            print(f""Directory created"")\n\n        subprocess.run([""ffmpeg"",\n                ""-loglevel"",\n                ""debug"",\n                ""-hide_banner"",\n                ""-y"",\n                ""-i"",\n                video_path,\n                ""-vn"",\n                ""-sn"",\n                ""-ar"",\n                ""44100"",\n                ""-q:a"",\n                ""0"",\n                ""-map"",\n                ""a"",\n                self.output],\n               stderr=subprocess.DEVNULL,\n               stdout=subprocess.DEVNULL,\n               stdin=subprocess.PIPE)\n\n        print(f""Convertation to .wav finished!"")\n\n\n#if __name__ == \'__main__\':\n    #path = ""files/videoplayback.mp4""\n    #video_to_wav(path)\n    #args = parser.parse_args()\n    #video_to_wav(args.video_path)\n\n\n    def video2mp3(self, video_path):\n        mp3s_path = ""mp3s""\n        name = video_path.split(\'/\')[-1].split(\'.\')[0]\n        self.output = mp3s_path + ""/"" + name + "".mp3""\n        if not os.path.exists(mp3s_path):\n            os.mkdir(mp3s_path)\n            print(f""Directory created"")\n\n        subprocess.run([""ffmpeg"",\n                ""-loglevel"",\n                ""debug"",\n                ""-hide_banner"",\n                ""-y"",\n                ""-i"",\n                video_path,\n                ""-write_id3v1"",\n                ""1"",\n                ""-id3v2_version"",\n                ""3"",\n                ""-q:a"",\n                ""0"",\n                ""-map"",\n                ""a"",\n                self.output],\n               stderr=subprocess.DEVNULL,\n               stdout=subprocess.DEVNULL,\n               stdin=subprocess.PIPE)\n\n        print(f""Convertation to .mp3 finished!"")\n;\n'}]","{'def': 5, 'class': 1}","{'def': 5, 'class': 1}",[]
1,155,cf4882df,"updated package versions and first install script
",5,41,30,"[{'new_path': 'README.md', 'diff': '@@ -4,7 +4,7 @@ To run this script, you need to:\n \n 1. Install ffmpeg, pytesseract, cv2\n     ```bash\n-        sudo pip3 install ffmpeg-python pytesseract opencv-python\n+        sudo pip3 install ffmpeg-python pytesseract opencv-python pydub scipy SpeechRecognition\n     ```\n 2. Put your video file into the folder ./files in the root of the project\n 3. Run from cli\n@@ -12,4 +12,4 @@ To run this script, you need to:\n         python3 main.py -v files/videoplayback.mp4 output.txt 1\n     ```\n     This command will convert video into the series of images with 1 frame per second.\n-    After that, array of images are going to be parsed into .txt file as text.\n\\ No newline at end of file\n+    After that, array of images are going to be parsed into .txt file as text.\n'}, {'new_path': 'SpeechRecognition.py', 'diff': '@@ -1,4 +1,3 @@\n-\n # coding: utf-8\n \n # ### Функции пред- и постобработки\n@@ -10,8 +9,12 @@ from pydub import AudioSegment\n from scipy.io import wavfile\n import os\n import numpy as np\n+import speech_recognition as sr\n+import argparse\n \n-\n+parser = argparse.ArgumentParser(description=""wav_to_txt"")\n+parser.add_argument(""wav_path"", help=""Path to .wav audio file"")\n+parser.add_argument(""out_path"", help=""Path to output .txt file"")\n # Делим аудио (wav) на короткие части, сохраняем в папку tmp_slices\n \n # In[2]:\n@@ -20,27 +23,27 @@ import numpy as np\n def divide_audio(audio_src, slice_length_ms=3000, overlap_ms=500):\n     audio = AudioSegment.from_file(audio_src, ""wav"")\n \n-    slices = np.arange(0, len(audio)-overlap_ms, slice_length_ms-overlap_ms)\n-    \n+    slices = np.arange(0, len(audio) - overlap_ms, slice_length_ms - overlap_ms)\n+\n     path = ""tmp_slices""\n     os.mkdir(path)\n     audio_slices_src = []\n     i = 0\n-    \n+\n     for start, end in zip(slices[:-1], slices[1:]):\n-        slice_ = audio[start : end+overlap_ms]\n+        slice_ = audio[start : end + overlap_ms]\n         # сохраняем кусочки аудио\n         slice_name = ""tmp_slices\\slice{0}.wav"".format(i)\n         audio_slices_src.append(slice_name)\n         slice_.export(slice_name, format=""wav"")\n-        i+=1\n-        \n+        i += 1\n+\n     if len(audio) - end > overlap_ms:\n         slice_ = audio[end : len(audio)]\n         slice_name = ""tmp_slices\\slice{0}.wav"".format(i)\n         audio_slices_src.append(slice_name)\n         slice_.export(slice_name, format=""wav"")\n-        \n+\n     return audio_slices_src\n \n \n@@ -52,7 +55,7 @@ def divide_audio(audio_src, slice_length_ms=3000, overlap_ms=500):\n def delete_tmp_slices(audio_slices_src):\n     for slice_ in audio_slices_src:\n         os.remove(slice_)\n-    os.rmdir(\'tmp_slices\')\n+    os.rmdir(""tmp_slices"")\n \n \n # Соединяем распознанный по частям текст\n@@ -61,47 +64,44 @@ def delete_tmp_slices(audio_slices_src):\n \n \n def combine_text(text_array):\n-    result_text = \'\'\n-    \n+    result_text = """"\n+\n     prev_splited = []\n-    \n+\n     for text in text_array:\n-        processed_text = \'\'\n-        \n+        processed_text = """"\n+\n         splited = text.lower().split()\n-        \n+\n         j = 0\n         while j < min(len(splited), len(prev_splited)):\n-            if splited[j] != prev_splited[-1-j]:\n+            if splited[j] != prev_splited[-1 - j]:\n                 break\n             j += 1\n-        \n+\n         for i in range(j, len(splited)):\n-            processed_text += splited[i] + \' \'\n-        \n+            processed_text += splited[i] + "" ""\n+\n         result_text += processed_text\n-        \n-        prev_splited = splited        \n-        \n+\n+        prev_splited = splited\n+\n     return result_text\n \n \n # ### Распознавание речи\n \n # Библиотека SpeechRecognition ( https://pypi.org/project/SpeechRecognition/ )\n-# \n+#\n # Используется распознавание при помощи Google Speech Recognition\n-# \n+#\n # Распознавание текста происходит непрерывно, даже когда речи нет, а есть только шум. Если распознать какие-то слова не удается, программа выдает ошибку. Поэтому нужно делить аудио на короткие части и распознавать их отдельно.\n-# \n+#\n # Список языковых кодов для Google Speech Recognition: https://www.science.co.il/language/Locale-codes.php\n \n # In[5]:\n \n \n-import speech_recognition as sr\n-\n-\n # Распознавание без учета шума\n \n # In[6]:\n@@ -109,35 +109,35 @@ import speech_recognition as sr\n \n def recognize_no_noise(audio_src):\n     r = sr.Recognizer()\n-    \n+\n     # делим аудио на части\n     chunks_src = divide_audio(audio_src)\n     # распознаем каждую часть\n     text_array = []\n     for chunk_src in chunks_src:\n         a = sr.AudioFile(chunk_src)\n-        #print(\'analyzing \', chunk_src)\n+        # print(\'analyzing \', chunk_src)\n         with a as source:\n             audio = r.record(source)\n         try:\n-            text_chunk = r.recognize_google(audio, language=\'ru\')\n+            text_chunk = r.recognize_google(audio, language=""ru"")\n             text_array.append(text_chunk)\n-            #print(\'!\',text_chunk)\n+            # print(\'!\',text_chunk)\n         except:\n             pass\n     # объединяем распознанные тексты\n     text = combine_text(text_array)\n-    \n+\n     # удаляем ненужные файлы\n     delete_tmp_slices(chunks_src)\n-    \n+\n     return text\n \n \n # In[7]:\n \n \n-#print(recognize_no_noise(\'audio/test1.wav\'))\n+# print(recognize_no_noise(\'audio/test1.wav\'))\n \n \n # Распознавание с учетом шума: уровень шума определяется автоматически\n@@ -147,35 +147,35 @@ def recognize_no_noise(audio_src):\n \n def recognize_with_noise(audio_src):\n     r = sr.Recognizer()\n-    \n+\n     # делим аудио на части\n     chunks_src = divide_audio(audio_src)\n     # распознаем каждую часть\n     text_array = []\n     for chunk_src in chunks_src:\n         a = sr.AudioFile(chunk_src)\n-        #print(\'analyzing \', chunk_src)\n+        # print(\'analyzing \', chunk_src)\n         with a as source:\n-            r.adjust_for_ambient_noise(source) # учитываем шум\n+            r.adjust_for_ambient_noise(source)  # учитываем шум\n             audio = r.record(source)\n         try:\n-            text_chunk = r.recognize_google(audio, language=\'ru\')\n+            text_chunk = r.recognize_google(audio, language=""ru"")\n             text_array.append(text_chunk)\n-            #print(text_chunk)\n+            # print(text_chunk)\n         except:\n             pass\n     # объединяем распознанные тексты\n     text = combine_text(text_array)\n     # удаляем ненужные файлы\n     delete_tmp_slices(chunks_src)\n-    \n+\n     return text\n \n \n # In[9]:\n \n \n-#print(recognize_with_noise(\'audio/test1.wav\'))\n+# print(recognize_with_noise(\'audio/test1.wav\'))\n \n \n # Итоговая функция распознавания, в которой выбирается наилучший вариант распознавания\n@@ -184,16 +184,15 @@ def recognize_with_noise(audio_src):\n \n \n def wav_to_txt(audio_src, out_txt_src):\n-    \n     no_noise_txt = recognize_no_noise(audio_src)\n     noise_txt = recognize_with_noise(audio_src)\n-    \n+\n     text = no_noise_txt\n     if len(noise_txt.split()) > len(text.split()):\n         text = noise_txt\n-        \n+\n     # записываем в файл\n-    out = open(out_txt_src, \'a\')\n+    out = open(out_txt_src, ""a"")\n     out.write(text)\n     out.close()\n \n@@ -203,17 +202,11 @@ def wav_to_txt(audio_src, out_txt_src):\n # In[12]:\n \n \n-#wav_to_txt(\'audio/test1.wav\', \'TEXT.txt\')\n+# wav_to_txt(\'audio/test1.wav\', \'TEXT.txt\')\n \n \n # In[ ]:\n \n-\n-parser = argparse.ArgumentParser(description=\'wav_to_txt\')\n-parser.add_argument(\'wav_path\', help=\'Path to .wav audio file\')\n-parser.add_argument(\'out_path\', help=\'Path to output .txt file\')\n-\n-if __name__ == \'__main__\':\n+if __name__ == ""__main__"":\n     args = parser.parse_args()\n     wav_to_txt(args.wav_path, args.out_path)\n-\n'}, {'new_path': 'SpeechRecognition_mp3_to_text.py', 'diff': '@@ -1,132 +0,0 @@\n-<<<<<<< HEAD:SpeechRecognition_2_mp3_to_text.py\n-# -*- coding: utf-8 -*-\n-=======\n-# coding: utf-8\n->>>>>>> origin/KateShestakova:SpeechRecognition_mp3_to_text.py\n-\n-# ### Функции пред- и постобработки\n-\n-from pydub import AudioSegment\n-from pydub.utils import make_chunks\n-import os\n-\n-import speech_recognition as sr\n-\n-# Перевод из формата mp3 в wav\n-\n-def mp3_to_wav(mp3_src, wav_src):\n-    sound = AudioSegment.from_mp3(mp3_src)\n-    sound.export(wav_src, format=""wav"")\n-\n-# Делим аудио (wav) на короткие части, сохраняем в папку tmp_chunks\n-\n-def divide_audio(audio_src, chunk_length_ms):\n-    audio = AudioSegment.from_file(audio_src, ""wav"") \n-    chunks = make_chunks(audio, chunk_length_ms)\n-    \n-    path = ""tmp_chunks""\n-    os.mkdir(path)\n-    \n-    chunks_src = []\n-    for i, chunk in enumerate(chunks):\n-        chunk_name = ""tmp_chunks\\chunk{0}.wav"".format(i)\n-        chunks_src.append(chunk_name)\n-        chunk.export(chunk_name, format=""wav"")\n-        \n-    return chunks_src\n-\n-\n-# Удаляем папку tmp_chunks с частями аудио\n-\n-def delete_tmp_chunks(chunks_src):\n-    for chunk in chunks_src:\n-        os.remove(chunk)\n-    os.rmdir(\'tmp_chunks\')\n-\n-# Соединяем распознанный по частям текст\n-\n-def combine_text(text_array):\n-    result_text = \'\'\n-    for text in text_array:\n-        result_text += text + \' \'\n-    return result_text\n-\n-\n-# ### Распознавание речи\n-\n-# Библиотека SpeechRecognition ( https://pypi.org/project/SpeechRecognition/ )\n-# \n-# Используется распознавание при помощи Google Speech Recognition\n-# \n-# Распознавание текста происходит непрерывно, даже когда речи нет, а есть только шум. Если распознать какие-то слова не удается, программа выдает ошибку. Поэтому нужно делить аудио на короткие части и распознавать их отдельно.\n-# \n-# Список языковых кодов для Google Speech Recognition: https://www.science.co.il/language/Locale-codes.php\n-\n-\n-# Распознавание без учета шума\n-\n-def recognize(audio_src):\n-    # делим аудио на части\n-    chunks_src = divide_audio(audio_src, 3000)\n-    # распознаем каждую часть\n-    text_array = []\n-    for chunk_src in chunks_src:\n-        a = sr.AudioFile(chunk_src)\n-        with a as source:\n-            audio = r.record(source)\n-        try:\n-            text_array.append(r.recognize_google(audio, language=\'ru\'))\n-        except:\n-            pass\n-    # объединяем распознанные тексты\n-    text = combine_text(text_array)\n-    # удаляем ненужные файлы\n-    delete_tmp_chunks(chunks_src)\n-    \n-    return text\n-\n-# Распознавание с учетом шума: уровень шума определяется автоматически\n-\n-def recognize_with_noise(audio_src):\n-    # делим аудио на части\n-    chunks_src = divide_audio(audio_src, 3000)\n-    # распознаем каждую часть\n-    text_array = []\n-    for chunk_src in chunks_src:\n-        a = sr.AudioFile(chunk_src)\n-        with a as source:\n-            r.adjust_for_ambient_noise(source) # учитываем шум\n-            audio = r.record(source)\n-        try:\n-            text_chunk = r.recognize_google(audio, language=\'ru\')\n-            text_array.append(text_chunk)\n-            #print(text_chunk)\n-        except:\n-            pass\n-    # объединяем распознанные тексты\n-    text = combine_text(text_array)\n-    # удаляем ненужные файлы\n-    delete_tmp_chunks(chunks_src)\n-    \n-    return text\n-\n-# итоговая функция распознавания\n-\n-def wav_to_txt(path):\n-    r = sr.Recognizer()\n-    recognize_with_noise(path)\n-    \n-# для интеграции в main\n-\n-parser = argparse.ArgumentParser(description=\'wav_to_txt\')\n-parser.add_argument(\'wav_path\', help=\'Path to .wav audio file\')\n-parser.add_argument(\'out_path\', help=\'Path to output text file\')\n-\n-if __name__ == \'__main__\':\n-    args = parser.parse_args()\n-    txt = wav_to_txt(args.wav_path)\n-    \n-    f = open(args.out_path, ""a"")\n-    f.write(txt) \n-    f.close() \n-\n'}, {'new_path': 'main.py', 'diff': '@@ -8,6 +8,7 @@ from TextFromPicture import Pic2Txt\n import FFMPEGFrames\n import glob\n \n+from SpeechRecognition import wav_to_txt\n \n def main():\n     parser = argparse.ArgumentParser()\n@@ -44,6 +45,16 @@ def main():\n         f = FFMPEGFrames.FFMPEGFrames(""images/"")\n         f.extract_frames(input, fps)\n         Pic2Txt(glob.glob(""images/*.png""), output)\n+    elif str(sys.argv[1] in [\'-a\', \'--audio\']):\n+        parser.add_argument(\'-a\', \'--audio\', action=\'store_true\')\n+        parser.add_argument(""in_filename"", help=\'Input filename\')\n+        parser.add_argument(\'out_filename\', help=\'Output filename\')\n+        args = vars(parser.parse_args())\n+\n+        input = args[""in_filename""]\n+        output = args[""out_filename""]\n+\n+        wav_to_txt(input, output)\n     else:\n         print(error_msg)\n \n'}, {'new_path': 'requirements.txt', 'diff': '@@ -3,4 +3,5 @@ ffmpeg-python==0.2.0\n opencv-python==4.2.0.32\n pdf2image==1.12.1\n pydub==0.23.1\n+scipy==1.4.1\n pytesseract==0.3.3\n'}]", ;,"[{'diff': '@@ -4,7 +4,7 @@ To run this script, you need to:\n \n 1. Install ffmpeg, pytesseract, cv2\n     ```bash\n-        sudo pip3 install ffmpeg-python pytesseract opencv-python\n+        sudo pip3 install ffmpeg-python pytesseract opencv-python pydub scipy SpeechRecognition\n     ```\n 2. Put your video file into the folder ./files in the root of the project\n 3. Run from cli\n@@ -12,4 +12,4 @@ To run this script, you need to:\n         python3 main.py -v files/videoplayback.mp4 output.txt 1\n     ```\n     This command will convert video into the series of images with 1 frame per second.\n-    After that, array of images are going to be parsed into .txt file as text.\n\\ No newline at end of file\n+    After that, array of images are going to be parsed into .txt file as text.\n'}, {'diff': '@@ -1,4 +1,3 @@\n-\n # coding: utf-8\n \n # ### Функции пред- и постобработки\n@@ -10,8 +9,12 @@ from pydub import AudioSegment\n from scipy.io import wavfile\n import os\n import numpy as np\n+import speech_recognition as sr\n+import argparse\n \n-\n+parser = argparse.ArgumentParser(description=""wav_to_txt"")\n+parser.add_argument(""wav_path"", help=""Path to .wav audio file"")\n+parser.add_argument(""out_path"", help=""Path to output .txt file"")\n # Делим аудио (wav) на короткие части, сохраняем в папку tmp_slices\n \n # In[2]:\n@@ -20,27 +23,27 @@ import numpy as np\n def divide_audio(audio_src, slice_length_ms=3000, overlap_ms=500):\n     audio = AudioSegment.from_file(audio_src, ""wav"")\n \n-    slices = np.arange(0, len(audio)-overlap_ms, slice_length_ms-overlap_ms)\n-    \n+    slices = np.arange(0, len(audio) - overlap_ms, slice_length_ms - overlap_ms)\n+\n     path = ""tmp_slices""\n     os.mkdir(path)\n     audio_slices_src = []\n     i = 0\n-    \n+\n     for start, end in zip(slices[:-1], slices[1:]):\n-        slice_ = audio[start : end+overlap_ms]\n+        slice_ = audio[start : end + overlap_ms]\n         # сохраняем кусочки аудио\n         slice_name = ""tmp_slices\\slice{0}.wav"".format(i)\n         audio_slices_src.append(slice_name)\n         slice_.export(slice_name, format=""wav"")\n-        i+=1\n-        \n+        i += 1\n+\n     if len(audio) - end > overlap_ms:\n         slice_ = audio[end : len(audio)]\n         slice_name = ""tmp_slices\\slice{0}.wav"".format(i)\n         audio_slices_src.append(slice_name)\n         slice_.export(slice_name, format=""wav"")\n-        \n+\n     return audio_slices_src\n \n \n@@ -52,7 +55,7 @@ def divide_audio(audio_src, slice_length_ms=3000, overlap_ms=500):\n def delete_tmp_slices(audio_slices_src):\n     for slice_ in audio_slices_src:\n         os.remove(slice_)\n-    os.rmdir(\'tmp_slices\')\n+    os.rmdir(""tmp_slices"")\n \n \n # Соединяем распознанный по частям текст\n@@ -61,47 +64,44 @@ def delete_tmp_slices(audio_slices_src):\n \n \n def combine_text(text_array):\n-    result_text = \'\'\n-    \n+    result_text = """"\n+\n     prev_splited = []\n-    \n+\n     for text in text_array:\n-        processed_text = \'\'\n-        \n+        processed_text = """"\n+\n         splited = text.lower().split()\n-        \n+\n         j = 0\n         while j < min(len(splited), len(prev_splited)):\n-            if splited[j] != prev_splited[-1-j]:\n+            if splited[j] != prev_splited[-1 - j]:\n                 break\n             j += 1\n-        \n+\n         for i in range(j, len(splited)):\n-            processed_text += splited[i] + \' \'\n-        \n+            processed_text += splited[i] + "" ""\n+\n         result_text += processed_text\n-        \n-        prev_splited = splited        \n-        \n+\n+        prev_splited = splited\n+\n     return result_text\n \n \n # ### Распознавание речи\n \n # Библиотека SpeechRecognition ( https://pypi.org/project/SpeechRecognition/ )\n-# \n+#\n # Используется распознавание при помощи Google Speech Recognition\n-# \n+#\n # Распознавание текста происходит непрерывно, даже когда речи нет, а есть только шум. Если распознать какие-то слова не удается, программа выдает ошибку. Поэтому нужно делить аудио на короткие части и распознавать их отдельно.\n-# \n+#\n # Список языковых кодов для Google Speech Recognition: https://www.science.co.il/language/Locale-codes.php\n \n # In[5]:\n \n \n-import speech_recognition as sr\n-\n-\n # Распознавание без учета шума\n \n # In[6]:\n@@ -109,35 +109,35 @@ import speech_recognition as sr\n \n def recognize_no_noise(audio_src):\n     r = sr.Recognizer()\n-    \n+\n     # делим аудио на части\n     chunks_src = divide_audio(audio_src)\n     # распознаем каждую часть\n     text_array = []\n     for chunk_src in chunks_src:\n         a = sr.AudioFile(chunk_src)\n-        #print(\'analyzing \', chunk_src)\n+        # print(\'analyzing \', chunk_src)\n         with a as source:\n             audio = r.record(source)\n         try:\n-            text_chunk = r.recognize_google(audio, language=\'ru\')\n+            text_chunk = r.recognize_google(audio, language=""ru"")\n             text_array.append(text_chunk)\n-            #print(\'!\',text_chunk)\n+            # print(\'!\',text_chunk)\n         except:\n             pass\n     # объединяем распознанные тексты\n     text = combine_text(text_array)\n-    \n+\n     # удаляем ненужные файлы\n     delete_tmp_slices(chunks_src)\n-    \n+\n     return text\n \n \n # In[7]:\n \n \n-#print(recognize_no_noise(\'audio/test1.wav\'))\n+# print(recognize_no_noise(\'audio/test1.wav\'))\n \n \n # Распознавание с учетом шума: уровень шума определяется автоматически\n@@ -147,35 +147,35 @@ def recognize_no_noise(audio_src):\n \n def recognize_with_noise(audio_src):\n     r = sr.Recognizer()\n-    \n+\n     # делим аудио на части\n     chunks_src = divide_audio(audio_src)\n     # распознаем каждую часть\n     text_array = []\n     for chunk_src in chunks_src:\n         a = sr.AudioFile(chunk_src)\n-        #print(\'analyzing \', chunk_src)\n+        # print(\'analyzing \', chunk_src)\n         with a as source:\n-            r.adjust_for_ambient_noise(source) # учитываем шум\n+            r.adjust_for_ambient_noise(source)  # учитываем шум\n             audio = r.record(source)\n         try:\n-            text_chunk = r.recognize_google(audio, language=\'ru\')\n+            text_chunk = r.recognize_google(audio, language=""ru"")\n             text_array.append(text_chunk)\n-            #print(text_chunk)\n+            # print(text_chunk)\n         except:\n             pass\n     # объединяем распознанные тексты\n     text = combine_text(text_array)\n     # удаляем ненужные файлы\n     delete_tmp_slices(chunks_src)\n-    \n+\n     return text\n \n \n # In[9]:\n \n \n-#print(recognize_with_noise(\'audio/test1.wav\'))\n+# print(recognize_with_noise(\'audio/test1.wav\'))\n \n \n # Итоговая функция распознавания, в которой выбирается наилучший вариант распознавания\n@@ -184,16 +184,15 @@ def recognize_with_noise(audio_src):\n \n \n def wav_to_txt(audio_src, out_txt_src):\n-    \n     no_noise_txt = recognize_no_noise(audio_src)\n     noise_txt = recognize_with_noise(audio_src)\n-    \n+\n     text = no_noise_txt\n     if len(noise_txt.split()) > len(text.split()):\n         text = noise_txt\n-        \n+\n     # записываем в файл\n-    out = open(out_txt_src, \'a\')\n+    out = open(out_txt_src, ""a"")\n     out.write(text)\n     out.close()\n \n@@ -203,17 +202,11 @@ def wav_to_txt(audio_src, out_txt_src):\n # In[12]:\n \n \n-#wav_to_txt(\'audio/test1.wav\', \'TEXT.txt\')\n+# wav_to_txt(\'audio/test1.wav\', \'TEXT.txt\')\n \n \n # In[ ]:\n \n-\n-parser = argparse.ArgumentParser(description=\'wav_to_txt\')\n-parser.add_argument(\'wav_path\', help=\'Path to .wav audio file\')\n-parser.add_argument(\'out_path\', help=\'Path to output .txt file\')\n-\n-if __name__ == \'__main__\':\n+if __name__ == ""__main__"":\n     args = parser.parse_args()\n     wav_to_txt(args.wav_path, args.out_path)\n-\n'}, {'diff': '@@ -1,132 +0,0 @@\n-<<<<<<< HEAD:SpeechRecognition_2_mp3_to_text.py\n-# -*- coding: utf-8 -*-\n-=======\n-# coding: utf-8\n->>>>>>> origin/KateShestakova:SpeechRecognition_mp3_to_text.py\n-\n-# ### Функции пред- и постобработки\n-\n-from pydub import AudioSegment\n-from pydub.utils import make_chunks\n-import os\n-\n-import speech_recognition as sr\n-\n-# Перевод из формата mp3 в wav\n-\n-def mp3_to_wav(mp3_src, wav_src):\n-    sound = AudioSegment.from_mp3(mp3_src)\n-    sound.export(wav_src, format=""wav"")\n-\n-# Делим аудио (wav) на короткие части, сохраняем в папку tmp_chunks\n-\n-def divide_audio(audio_src, chunk_length_ms):\n-    audio = AudioSegment.from_file(audio_src, ""wav"") \n-    chunks = make_chunks(audio, chunk_length_ms)\n-    \n-    path = ""tmp_chunks""\n-    os.mkdir(path)\n-    \n-    chunks_src = []\n-    for i, chunk in enumerate(chunks):\n-        chunk_name = ""tmp_chunks\\chunk{0}.wav"".format(i)\n-        chunks_src.append(chunk_name)\n-        chunk.export(chunk_name, format=""wav"")\n-        \n-    return chunks_src\n-\n-\n-# Удаляем папку tmp_chunks с частями аудио\n-\n-def delete_tmp_chunks(chunks_src):\n-    for chunk in chunks_src:\n-        os.remove(chunk)\n-    os.rmdir(\'tmp_chunks\')\n-\n-# Соединяем распознанный по частям текст\n-\n-def combine_text(text_array):\n-    result_text = \'\'\n-    for text in text_array:\n-        result_text += text + \' \'\n-    return result_text\n-\n-\n-# ### Распознавание речи\n-\n-# Библиотека SpeechRecognition ( https://pypi.org/project/SpeechRecognition/ )\n-# \n-# Используется распознавание при помощи Google Speech Recognition\n-# \n-# Распознавание текста происходит непрерывно, даже когда речи нет, а есть только шум. Если распознать какие-то слова не удается, программа выдает ошибку. Поэтому нужно делить аудио на короткие части и распознавать их отдельно.\n-# \n-# Список языковых кодов для Google Speech Recognition: https://www.science.co.il/language/Locale-codes.php\n-\n-\n-# Распознавание без учета шума\n-\n-def recognize(audio_src):\n-    # делим аудио на части\n-    chunks_src = divide_audio(audio_src, 3000)\n-    # распознаем каждую часть\n-    text_array = []\n-    for chunk_src in chunks_src:\n-        a = sr.AudioFile(chunk_src)\n-        with a as source:\n-            audio = r.record(source)\n-        try:\n-            text_array.append(r.recognize_google(audio, language=\'ru\'))\n-        except:\n-            pass\n-    # объединяем распознанные тексты\n-    text = combine_text(text_array)\n-    # удаляем ненужные файлы\n-    delete_tmp_chunks(chunks_src)\n-    \n-    return text\n-\n-# Распознавание с учетом шума: уровень шума определяется автоматически\n-\n-def recognize_with_noise(audio_src):\n-    # делим аудио на части\n-    chunks_src = divide_audio(audio_src, 3000)\n-    # распознаем каждую часть\n-    text_array = []\n-    for chunk_src in chunks_src:\n-        a = sr.AudioFile(chunk_src)\n-        with a as source:\n-            r.adjust_for_ambient_noise(source) # учитываем шум\n-            audio = r.record(source)\n-        try:\n-            text_chunk = r.recognize_google(audio, language=\'ru\')\n-            text_array.append(text_chunk)\n-            #print(text_chunk)\n-        except:\n-            pass\n-    # объединяем распознанные тексты\n-    text = combine_text(text_array)\n-    # удаляем ненужные файлы\n-    delete_tmp_chunks(chunks_src)\n-    \n-    return text\n-\n-# итоговая функция распознавания\n-\n-def wav_to_txt(path):\n-    r = sr.Recognizer()\n-    recognize_with_noise(path)\n-    \n-# для интеграции в main\n-\n-parser = argparse.ArgumentParser(description=\'wav_to_txt\')\n-parser.add_argument(\'wav_path\', help=\'Path to .wav audio file\')\n-parser.add_argument(\'out_path\', help=\'Path to output text file\')\n-\n-if __name__ == \'__main__\':\n-    args = parser.parse_args()\n-    txt = wav_to_txt(args.wav_path)\n-    \n-    f = open(args.out_path, ""a"")\n-    f.write(txt) \n-    f.close() \n-\n'}, {'diff': '@@ -8,6 +8,7 @@ from TextFromPicture import Pic2Txt\n import FFMPEGFrames\n import glob\n \n+from SpeechRecognition import wav_to_txt\n \n def main():\n     parser = argparse.ArgumentParser()\n@@ -44,6 +45,16 @@ def main():\n         f = FFMPEGFrames.FFMPEGFrames(""images/"")\n         f.extract_frames(input, fps)\n         Pic2Txt(glob.glob(""images/*.png""), output)\n+    elif str(sys.argv[1] in [\'-a\', \'--audio\']):\n+        parser.add_argument(\'-a\', \'--audio\', action=\'store_true\')\n+        parser.add_argument(""in_filename"", help=\'Input filename\')\n+        parser.add_argument(\'out_filename\', help=\'Output filename\')\n+        args = vars(parser.parse_args())\n+\n+        input = args[""in_filename""]\n+        output = args[""out_filename""]\n+\n+        wav_to_txt(input, output)\n     else:\n         print(error_msg)\n \n'}, {'diff': '@@ -3,4 +3,5 @@ ffmpeg-python==0.2.0\n opencv-python==4.2.0.32\n pdf2image==1.12.1\n pydub==0.23.1\n+scipy==1.4.1\n pytesseract==0.3.3\n'}]","        sudo pip3 install ffmpeg-python pytesseract opencv-python pydub scipy SpeechRecognition;    After that, array of images are going to be parsed into .txt file as text.;import speech_recognition as sr;import argparse;parser = argparse.ArgumentParser(description=""wav_to_txt"");parser.add_argument(""wav_path"", help=""Path to .wav audio file"");parser.add_argument(""out_path"", help=""Path to output .txt file"");    slices = np.arange(0, len(audio) - overlap_ms, slice_length_ms - overlap_ms);        slice_ = audio[start : end + overlap_ms];        i += 1;    os.rmdir(""tmp_slices"");    result_text = """";        processed_text = """";            if splited[j] != prev_splited[-1 - j]:;            processed_text += splited[i] + "" "";        prev_splited = splited;#;#;#;        # print('analyzing ', chunk_src);            text_chunk = r.recognize_google(audio, language=""ru"");            # print('!',text_chunk);# print(recognize_no_noise('audio/test1.wav'));        # print('analyzing ', chunk_src);            r.adjust_for_ambient_noise(source)  # учитываем шум;            text_chunk = r.recognize_google(audio, language=""ru"");            # print(text_chunk);# print(recognize_with_noise('audio/test1.wav'));    out = open(out_txt_src, ""a"");# wav_to_txt('audio/test1.wav', 'TEXT.txt');if __name__ == ""__main__"":;from SpeechRecognition import wav_to_txt;    elif str(sys.argv[1] in ['-a', '--audio']):;        parser.add_argument('-a', '--audio', action='store_true');        parser.add_argument(""in_filename"", help='Input filename');        parser.add_argument('out_filename', help='Output filename');        args = vars(parser.parse_args());        input = args[""in_filename""];        output = args[""out_filename""];        wav_to_txt(input, output);scipy==1.4.1;","        sudo pip3 install ffmpeg-python pytesseract opencv-python;    After that, array of images are going to be parsed into .txt file as text.;    slices = np.arange(0, len(audio)-overlap_ms, slice_length_ms-overlap_ms);    ;    ;        slice_ = audio[start : end+overlap_ms];        i+=1;        ;        ;    os.rmdir('tmp_slices');    result_text = '';    ;    ;        processed_text = '';        ;        ;            if splited[j] != prev_splited[-1-j]:;        ;            processed_text += splited[i] + ' ';        ;        ;        prev_splited = splited        ;        ;# ;# ;# ;import speech_recognition as sr;    ;        #print('analyzing ', chunk_src);            text_chunk = r.recognize_google(audio, language='ru');            #print('!',text_chunk);    ;    ;#print(recognize_no_noise('audio/test1.wav'));    ;        #print('analyzing ', chunk_src);            r.adjust_for_ambient_noise(source) # учитываем шум;            text_chunk = r.recognize_google(audio, language='ru');            #print(text_chunk);    ;#print(recognize_with_noise('audio/test1.wav'));    ;    ;        ;    out = open(out_txt_src, 'a');#wav_to_txt('audio/test1.wav', 'TEXT.txt');parser = argparse.ArgumentParser(description='wav_to_txt');parser.add_argument('wav_path', help='Path to .wav audio file');parser.add_argument('out_path', help='Path to output .txt file');if __name__ == '__main__':;",https://git.miem.hse.ru/19121/recognition_miem/-/commit/cf4882dfe1e190f9aff83b548cfd54ba954a9e0e,3,1,"['README.md', 'SpeechRecognition.py', 'SpeechRecognition_mp3_to_text.py', 'main.py', 'requirements.txt']","# coding: utf-8

# ### Функции пред- и постобработки

# In[1]:


from pydub import AudioSegment
from scipy.io import wavfile
import os
import numpy as np
import speech_recognition as sr
import argparse

parser = argparse.ArgumentParser(description=""wav_to_txt"")
parser.add_argument(""wav_path"", help=""Path to .wav audio file"")
parser.add_argument(""out_path"", help=""Path to output .txt file"")
# Делим аудио (wav) на короткие части, сохраняем в папку tmp_slices

# In[2]:


def divide_audio(audio_src, slice_length_ms=3000, overlap_ms=500):
    audio = AudioSegment.from_file(audio_src, ""wav"")

    slices = np.arange(0, len(audio) - overlap_ms, slice_length_ms - overlap_ms)

    path = ""tmp_slices""
    os.mkdir(path)
    audio_slices_src = []
    i = 0

    for start, end in zip(slices[:-1], slices[1:]):
        slice_ = audio[start : end + overlap_ms]
        # сохраняем кусочки аудио
        slice_name = ""tmp_slices\slice{0}.wav"".format(i)
        audio_slices_src.append(slice_name)
        slice_.export(slice_name, format=""wav"")
        i += 1

    if len(audio) - end > overlap_ms:
        slice_ = audio[end : len(audio)]
        slice_name = ""tmp_slices\slice{0}.wav"".format(i)
        audio_slices_src.append(slice_name)
        slice_.export(slice_name, format=""wav"")

    return audio_slices_src


# Удаляем папку tmp_slices с частями аудио

# In[3]:


def delete_tmp_slices(audio_slices_src):
    for slice_ in audio_slices_src:
        os.remove(slice_)
    os.rmdir(""tmp_slices"")


# Соединяем распознанный по частям текст

# In[4]:


def combine_text(text_array):
    result_text = """"

    prev_splited = []

    for text in text_array:
        processed_text = """"

        splited = text.lower().split()

        j = 0
        while j < min(len(splited), len(prev_splited)):
            if splited[j] != prev_splited[-1 - j]:
                break
            j += 1

        for i in range(j, len(splited)):
            processed_text += splited[i] + "" ""

        result_text += processed_text

        prev_splited = splited

    return result_text


# ### Распознавание речи

# Библиотека SpeechRecognition ( https://pypi.org/project/SpeechRecognition/ )
#
# Используется распознавание при помощи Google Speech Recognition
#
# Распознавание текста происходит непрерывно, даже когда речи нет, а есть только шум. Если распознать какие-то слова не удается, программа выдает ошибку. Поэтому нужно делить аудио на короткие части и распознавать их отдельно.
#
# Список языковых кодов для Google Speech Recognition: https://www.science.co.il/language/Locale-codes.php

# In[5]:


# Распознавание без учета шума

# In[6]:


def recognize_no_noise(audio_src):
    r = sr.Recognizer()

    # делим аудио на части
    chunks_src = divide_audio(audio_src)
    # распознаем каждую часть
    text_array = []
    for chunk_src in chunks_src:
        a = sr.AudioFile(chunk_src)
        # print('analyzing ', chunk_src)
        with a as source:
            audio = r.record(source)
        try:
            text_chunk = r.recognize_google(audio, language=""ru"")
            text_array.append(text_chunk)
            # print('!',text_chunk)
        except:
            pass
    # объединяем распознанные тексты
    text = combine_text(text_array)

    # удаляем ненужные файлы
    delete_tmp_slices(chunks_src)

    return text


# In[7]:


# print(recognize_no_noise('audio/test1.wav'))


# Распознавание с учетом шума: уровень шума определяется автоматически

# In[8]:


def recognize_with_noise(audio_src):
    r = sr.Recognizer()

    # делим аудио на части
    chunks_src = divide_audio(audio_src)
    # распознаем каждую часть
    text_array = []
    for chunk_src in chunks_src:
        a = sr.AudioFile(chunk_src)
        # print('analyzing ', chunk_src)
        with a as source:
            r.adjust_for_ambient_noise(source)  # учитываем шум
            audio = r.record(source)
        try:
            text_chunk = r.recognize_google(audio, language=""ru"")
            text_array.append(text_chunk)
            # print(text_chunk)
        except:
            pass
    # объединяем распознанные тексты
    text = combine_text(text_array)
    # удаляем ненужные файлы
    delete_tmp_slices(chunks_src)

    return text


# In[9]:


# print(recognize_with_noise('audio/test1.wav'))


# Итоговая функция распознавания, в которой выбирается наилучший вариант распознавания

# In[10]:


def wav_to_txt(audio_src, out_txt_src):
    no_noise_txt = recognize_no_noise(audio_src)
    noise_txt = recognize_with_noise(audio_src)

    text = no_noise_txt
    if len(noise_txt.split()) > len(text.split()):
        text = noise_txt

    # записываем в файл
    out = open(out_txt_src, ""a"")
    out.write(text)
    out.close()


# Для интеграции в main

# In[12]:


# wav_to_txt('audio/test1.wav', 'TEXT.txt')


# In[ ]:

if __name__ == ""__main__"":
    args = parser.parse_args()
    wav_to_txt(args.wav_path, args.out_path)

;
# -*- coding: utf-8 -*-

from test import Hello
import argparse
import sys
import socket
from TextFromPicture import Pic2Txt
import FFMPEGFrames
import glob

from SpeechRecognition import wav_to_txt

def main():
    parser = argparse.ArgumentParser()

    error_msg = ""Invalid Arguments\n\n"" \
                ""Commands: \n"" \
                ""  -t, --test                 Let's test it!\n"" \
                ""       Optional: --name='your_arg'  -   that'll print your string your_arg\n"" \
                ""  -v, --video             Convert video to pictures and then convert to text\n"" \
                ""       Mandatory: --in_filename='files/video.mp4' --out_filename='output.txt'  --fps='1'-  set input video, output file, frames per second ""

    if len(sys.argv) == 1:
        print(error_msg)

    elif str(sys.argv[1]) in ['-t', '--test']:
        parser.add_argument('-t', '--test', action='store_true')
        parser.add_argument(""--name"", default=socket.gethostname())

        args = parser.parse_args()

        test_class = Hello(args.name)
        test_class.print_hello()
    elif str(sys.argv[1]) in ['-v', '--video']:
        parser.add_argument('-v', '--video', action='store_true')
        parser.add_argument(""in_filename"", help='Input filename')
        parser.add_argument('out_filename', help='Output filename')
        parser.add_argument(""fps"", help='fps')
        args = vars(parser.parse_args())

        input = args[""in_filename""]
        output = args[""out_filename""]
        fps = args[""fps""]

        f = FFMPEGFrames.FFMPEGFrames(""images/"")
        f.extract_frames(input, fps)
        Pic2Txt(glob.glob(""images/*.png""), output)
    elif str(sys.argv[1] in ['-a', '--audio']):
        parser.add_argument('-a', '--audio', action='store_true')
        parser.add_argument(""in_filename"", help='Input filename')
        parser.add_argument('out_filename', help='Output filename')
        args = vars(parser.parse_args())

        input = args[""in_filename""]
        output = args[""out_filename""]

        wav_to_txt(input, output)
    else:
        print(error_msg)


if __name__ == '__main__':
    main()

;
","
# coding: utf-8

# ### Функции пред- и постобработки

# In[1]:


from pydub import AudioSegment
from scipy.io import wavfile
import os
import numpy as np


# Делим аудио (wav) на короткие части, сохраняем в папку tmp_slices

# In[2]:


def divide_audio(audio_src, slice_length_ms=3000, overlap_ms=500):
    audio = AudioSegment.from_file(audio_src, ""wav"")

    slices = np.arange(0, len(audio)-overlap_ms, slice_length_ms-overlap_ms)
    
    path = ""tmp_slices""
    os.mkdir(path)
    audio_slices_src = []
    i = 0
    
    for start, end in zip(slices[:-1], slices[1:]):
        slice_ = audio[start : end+overlap_ms]
        # сохраняем кусочки аудио
        slice_name = ""tmp_slices\slice{0}.wav"".format(i)
        audio_slices_src.append(slice_name)
        slice_.export(slice_name, format=""wav"")
        i+=1
        
    if len(audio) - end > overlap_ms:
        slice_ = audio[end : len(audio)]
        slice_name = ""tmp_slices\slice{0}.wav"".format(i)
        audio_slices_src.append(slice_name)
        slice_.export(slice_name, format=""wav"")
        
    return audio_slices_src


# Удаляем папку tmp_slices с частями аудио

# In[3]:


def delete_tmp_slices(audio_slices_src):
    for slice_ in audio_slices_src:
        os.remove(slice_)
    os.rmdir('tmp_slices')


# Соединяем распознанный по частям текст

# In[4]:


def combine_text(text_array):
    result_text = ''
    
    prev_splited = []
    
    for text in text_array:
        processed_text = ''
        
        splited = text.lower().split()
        
        j = 0
        while j < min(len(splited), len(prev_splited)):
            if splited[j] != prev_splited[-1-j]:
                break
            j += 1
        
        for i in range(j, len(splited)):
            processed_text += splited[i] + ' '
        
        result_text += processed_text
        
        prev_splited = splited        
        
    return result_text


# ### Распознавание речи

# Библиотека SpeechRecognition ( https://pypi.org/project/SpeechRecognition/ )
# 
# Используется распознавание при помощи Google Speech Recognition
# 
# Распознавание текста происходит непрерывно, даже когда речи нет, а есть только шум. Если распознать какие-то слова не удается, программа выдает ошибку. Поэтому нужно делить аудио на короткие части и распознавать их отдельно.
# 
# Список языковых кодов для Google Speech Recognition: https://www.science.co.il/language/Locale-codes.php

# In[5]:


import speech_recognition as sr


# Распознавание без учета шума

# In[6]:


def recognize_no_noise(audio_src):
    r = sr.Recognizer()
    
    # делим аудио на части
    chunks_src = divide_audio(audio_src)
    # распознаем каждую часть
    text_array = []
    for chunk_src in chunks_src:
        a = sr.AudioFile(chunk_src)
        #print('analyzing ', chunk_src)
        with a as source:
            audio = r.record(source)
        try:
            text_chunk = r.recognize_google(audio, language='ru')
            text_array.append(text_chunk)
            #print('!',text_chunk)
        except:
            pass
    # объединяем распознанные тексты
    text = combine_text(text_array)
    
    # удаляем ненужные файлы
    delete_tmp_slices(chunks_src)
    
    return text


# In[7]:


#print(recognize_no_noise('audio/test1.wav'))


# Распознавание с учетом шума: уровень шума определяется автоматически

# In[8]:


def recognize_with_noise(audio_src):
    r = sr.Recognizer()
    
    # делим аудио на части
    chunks_src = divide_audio(audio_src)
    # распознаем каждую часть
    text_array = []
    for chunk_src in chunks_src:
        a = sr.AudioFile(chunk_src)
        #print('analyzing ', chunk_src)
        with a as source:
            r.adjust_for_ambient_noise(source) # учитываем шум
            audio = r.record(source)
        try:
            text_chunk = r.recognize_google(audio, language='ru')
            text_array.append(text_chunk)
            #print(text_chunk)
        except:
            pass
    # объединяем распознанные тексты
    text = combine_text(text_array)
    # удаляем ненужные файлы
    delete_tmp_slices(chunks_src)
    
    return text


# In[9]:


#print(recognize_with_noise('audio/test1.wav'))


# Итоговая функция распознавания, в которой выбирается наилучший вариант распознавания

# In[10]:


def wav_to_txt(audio_src, out_txt_src):
    
    no_noise_txt = recognize_no_noise(audio_src)
    noise_txt = recognize_with_noise(audio_src)
    
    text = no_noise_txt
    if len(noise_txt.split()) > len(text.split()):
        text = noise_txt
        
    # записываем в файл
    out = open(out_txt_src, 'a')
    out.write(text)
    out.close()


# Для интеграции в main

# In[12]:


#wav_to_txt('audio/test1.wav', 'TEXT.txt')


# In[ ]:


parser = argparse.ArgumentParser(description='wav_to_txt')
parser.add_argument('wav_path', help='Path to .wav audio file')
parser.add_argument('out_path', help='Path to output .txt file')

if __name__ == '__main__':
    args = parser.parse_args()
    wav_to_txt(args.wav_path, args.out_path)


;
<<<<<<< HEAD:SpeechRecognition_2_mp3_to_text.py
# -*- coding: utf-8 -*-
=======
# coding: utf-8
>>>>>>> origin/KateShestakova:SpeechRecognition_mp3_to_text.py

# ### Функции пред- и постобработки

from pydub import AudioSegment
from pydub.utils import make_chunks
import os

import speech_recognition as sr

# Перевод из формата mp3 в wav

def mp3_to_wav(mp3_src, wav_src):
    sound = AudioSegment.from_mp3(mp3_src)
    sound.export(wav_src, format=""wav"")

# Делим аудио (wav) на короткие части, сохраняем в папку tmp_chunks

def divide_audio(audio_src, chunk_length_ms):
    audio = AudioSegment.from_file(audio_src, ""wav"") 
    chunks = make_chunks(audio, chunk_length_ms)
    
    path = ""tmp_chunks""
    os.mkdir(path)
    
    chunks_src = []
    for i, chunk in enumerate(chunks):
        chunk_name = ""tmp_chunks\chunk{0}.wav"".format(i)
        chunks_src.append(chunk_name)
        chunk.export(chunk_name, format=""wav"")
        
    return chunks_src


# Удаляем папку tmp_chunks с частями аудио

def delete_tmp_chunks(chunks_src):
    for chunk in chunks_src:
        os.remove(chunk)
    os.rmdir('tmp_chunks')

# Соединяем распознанный по частям текст

def combine_text(text_array):
    result_text = ''
    for text in text_array:
        result_text += text + ' '
    return result_text


# ### Распознавание речи

# Библиотека SpeechRecognition ( https://pypi.org/project/SpeechRecognition/ )
# 
# Используется распознавание при помощи Google Speech Recognition
# 
# Распознавание текста происходит непрерывно, даже когда речи нет, а есть только шум. Если распознать какие-то слова не удается, программа выдает ошибку. Поэтому нужно делить аудио на короткие части и распознавать их отдельно.
# 
# Список языковых кодов для Google Speech Recognition: https://www.science.co.il/language/Locale-codes.php


# Распознавание без учета шума

def recognize(audio_src):
    # делим аудио на части
    chunks_src = divide_audio(audio_src, 3000)
    # распознаем каждую часть
    text_array = []
    for chunk_src in chunks_src:
        a = sr.AudioFile(chunk_src)
        with a as source:
            audio = r.record(source)
        try:
            text_array.append(r.recognize_google(audio, language='ru'))
        except:
            pass
    # объединяем распознанные тексты
    text = combine_text(text_array)
    # удаляем ненужные файлы
    delete_tmp_chunks(chunks_src)
    
    return text

# Распознавание с учетом шума: уровень шума определяется автоматически

def recognize_with_noise(audio_src):
    # делим аудио на части
    chunks_src = divide_audio(audio_src, 3000)
    # распознаем каждую часть
    text_array = []
    for chunk_src in chunks_src:
        a = sr.AudioFile(chunk_src)
        with a as source:
            r.adjust_for_ambient_noise(source) # учитываем шум
            audio = r.record(source)
        try:
            text_chunk = r.recognize_google(audio, language='ru')
            text_array.append(text_chunk)
            #print(text_chunk)
        except:
            pass
    # объединяем распознанные тексты
    text = combine_text(text_array)
    # удаляем ненужные файлы
    delete_tmp_chunks(chunks_src)
    
    return text

# итоговая функция распознавания

def wav_to_txt(path):
    r = sr.Recognizer()
    recognize_with_noise(path)
    
# для интеграции в main

parser = argparse.ArgumentParser(description='wav_to_txt')
parser.add_argument('wav_path', help='Path to .wav audio file')
parser.add_argument('out_path', help='Path to output text file')

if __name__ == '__main__':
    args = parser.parse_args()
    txt = wav_to_txt(args.wav_path)
    
    f = open(args.out_path, ""a"")
    f.write(txt) 
    f.close() 


;
# -*- coding: utf-8 -*-

from test import Hello
import argparse
import sys
import socket
from TextFromPicture import Pic2Txt
import FFMPEGFrames
import glob


def main():
    parser = argparse.ArgumentParser()

    error_msg = ""Invalid Arguments\n\n"" \
                ""Commands: \n"" \
                ""  -t, --test                 Let's test it!\n"" \
                ""       Optional: --name='your_arg'  -   that'll print your string your_arg\n"" \
                ""  -v, --video             Convert video to pictures and then convert to text\n"" \
                ""       Mandatory: --in_filename='files/video.mp4' --out_filename='output.txt'  --fps='1'-  set input video, output file, frames per second ""

    if len(sys.argv) == 1:
        print(error_msg)

    elif str(sys.argv[1]) in ['-t', '--test']:
        parser.add_argument('-t', '--test', action='store_true')
        parser.add_argument(""--name"", default=socket.gethostname())

        args = parser.parse_args()

        test_class = Hello(args.name)
        test_class.print_hello()
    elif str(sys.argv[1]) in ['-v', '--video']:
        parser.add_argument('-v', '--video', action='store_true')
        parser.add_argument(""in_filename"", help='Input filename')
        parser.add_argument('out_filename', help='Output filename')
        parser.add_argument(""fps"", help='fps')
        args = vars(parser.parse_args())

        input = args[""in_filename""]
        output = args[""out_filename""]
        fps = args[""fps""]

        f = FFMPEGFrames.FFMPEGFrames(""images/"")
        f.extract_frames(input, fps)
        Pic2Txt(glob.glob(""images/*.png""), output)
    else:
        print(error_msg)


if __name__ == '__main__':
    main()

;
",3,"[{'SpeechRecognition.py': '\n# coding: utf-8\n\n# ### Функции пред- и постобработки\n\n# In[1]:\n\n\nfrom pydub import AudioSegment\nfrom scipy.io import wavfile\nimport os\nimport numpy as np\n\n\n# Делим аудио (wav) на короткие части, сохраняем в папку tmp_slices\n\n# In[2]:\n\n\ndef divide_audio(audio_src, slice_length_ms=3000, overlap_ms=500):\n    audio = AudioSegment.from_file(audio_src, ""wav"")\n\n    slices = np.arange(0, len(audio)-overlap_ms, slice_length_ms-overlap_ms)\n    \n    path = ""tmp_slices""\n    os.mkdir(path)\n    audio_slices_src = []\n    i = 0\n    \n    for start, end in zip(slices[:-1], slices[1:]):\n        slice_ = audio[start : end+overlap_ms]\n        # сохраняем кусочки аудио\n        slice_name = ""tmp_slices\\slice{0}.wav"".format(i)\n        audio_slices_src.append(slice_name)\n        slice_.export(slice_name, format=""wav"")\n        i+=1\n        \n    if len(audio) - end > overlap_ms:\n        slice_ = audio[end : len(audio)]\n        slice_name = ""tmp_slices\\slice{0}.wav"".format(i)\n        audio_slices_src.append(slice_name)\n        slice_.export(slice_name, format=""wav"")\n        \n    return audio_slices_src\n\n\n# Удаляем папку tmp_slices с частями аудио\n\n# In[3]:\n\n\ndef delete_tmp_slices(audio_slices_src):\n    for slice_ in audio_slices_src:\n        os.remove(slice_)\n    os.rmdir(\'tmp_slices\')\n\n\n# Соединяем распознанный по частям текст\n\n# In[4]:\n\n\ndef combine_text(text_array):\n    result_text = \'\'\n    \n    prev_splited = []\n    \n    for text in text_array:\n        processed_text = \'\'\n        \n        splited = text.lower().split()\n        \n        j = 0\n        while j < min(len(splited), len(prev_splited)):\n            if splited[j] != prev_splited[-1-j]:\n                break\n            j += 1\n        \n        for i in range(j, len(splited)):\n            processed_text += splited[i] + \' \'\n        \n        result_text += processed_text\n        \n        prev_splited = splited        \n        \n    return result_text\n\n\n# ### Распознавание речи\n\n# Библиотека SpeechRecognition ( https://pypi.org/project/SpeechRecognition/ )\n# \n# Используется распознавание при помощи Google Speech Recognition\n# \n# Распознавание текста происходит непрерывно, даже когда речи нет, а есть только шум. Если распознать какие-то слова не удается, программа выдает ошибку. Поэтому нужно делить аудио на короткие части и распознавать их отдельно.\n# \n# Список языковых кодов для Google Speech Recognition: https://www.science.co.il/language/Locale-codes.php\n\n# In[5]:\n\n\nimport speech_recognition as sr\n\n\n# Распознавание без учета шума\n\n# In[6]:\n\n\ndef recognize_no_noise(audio_src):\n    r = sr.Recognizer()\n    \n    # делим аудио на части\n    chunks_src = divide_audio(audio_src)\n    # распознаем каждую часть\n    text_array = []\n    for chunk_src in chunks_src:\n        a = sr.AudioFile(chunk_src)\n        #print(\'analyzing \', chunk_src)\n        with a as source:\n            audio = r.record(source)\n        try:\n            text_chunk = r.recognize_google(audio, language=\'ru\')\n            text_array.append(text_chunk)\n            #print(\'!\',text_chunk)\n        except:\n            pass\n    # объединяем распознанные тексты\n    text = combine_text(text_array)\n    \n    # удаляем ненужные файлы\n    delete_tmp_slices(chunks_src)\n    \n    return text\n\n\n# In[7]:\n\n\n#print(recognize_no_noise(\'audio/test1.wav\'))\n\n\n# Распознавание с учетом шума: уровень шума определяется автоматически\n\n# In[8]:\n\n\ndef recognize_with_noise(audio_src):\n    r = sr.Recognizer()\n    \n    # делим аудио на части\n    chunks_src = divide_audio(audio_src)\n    # распознаем каждую часть\n    text_array = []\n    for chunk_src in chunks_src:\n        a = sr.AudioFile(chunk_src)\n        #print(\'analyzing \', chunk_src)\n        with a as source:\n            r.adjust_for_ambient_noise(source) # учитываем шум\n            audio = r.record(source)\n        try:\n            text_chunk = r.recognize_google(audio, language=\'ru\')\n            text_array.append(text_chunk)\n            #print(text_chunk)\n        except:\n            pass\n    # объединяем распознанные тексты\n    text = combine_text(text_array)\n    # удаляем ненужные файлы\n    delete_tmp_slices(chunks_src)\n    \n    return text\n\n\n# In[9]:\n\n\n#print(recognize_with_noise(\'audio/test1.wav\'))\n\n\n# Итоговая функция распознавания, в которой выбирается наилучший вариант распознавания\n\n# In[10]:\n\n\ndef wav_to_txt(audio_src, out_txt_src):\n    \n    no_noise_txt = recognize_no_noise(audio_src)\n    noise_txt = recognize_with_noise(audio_src)\n    \n    text = no_noise_txt\n    if len(noise_txt.split()) > len(text.split()):\n        text = noise_txt\n        \n    # записываем в файл\n    out = open(out_txt_src, \'a\')\n    out.write(text)\n    out.close()\n\n\n# Для интеграции в main\n\n# In[12]:\n\n\n#wav_to_txt(\'audio/test1.wav\', \'TEXT.txt\')\n\n\n# In[ ]:\n\n\nparser = argparse.ArgumentParser(description=\'wav_to_txt\')\nparser.add_argument(\'wav_path\', help=\'Path to .wav audio file\')\nparser.add_argument(\'out_path\', help=\'Path to output .txt file\')\n\nif __name__ == \'__main__\':\n    args = parser.parse_args()\n    wav_to_txt(args.wav_path, args.out_path)\n\n\n;\n'}, {'SpeechRecognition_mp3_to_text.py': '<<<<<<< HEAD:SpeechRecognition_2_mp3_to_text.py\n# -*- coding: utf-8 -*-\n=======\n# coding: utf-8\n>>>>>>> origin/KateShestakova:SpeechRecognition_mp3_to_text.py\n\n# ### Функции пред- и постобработки\n\nfrom pydub import AudioSegment\nfrom pydub.utils import make_chunks\nimport os\n\nimport speech_recognition as sr\n\n# Перевод из формата mp3 в wav\n\ndef mp3_to_wav(mp3_src, wav_src):\n    sound = AudioSegment.from_mp3(mp3_src)\n    sound.export(wav_src, format=""wav"")\n\n# Делим аудио (wav) на короткие части, сохраняем в папку tmp_chunks\n\ndef divide_audio(audio_src, chunk_length_ms):\n    audio = AudioSegment.from_file(audio_src, ""wav"") \n    chunks = make_chunks(audio, chunk_length_ms)\n    \n    path = ""tmp_chunks""\n    os.mkdir(path)\n    \n    chunks_src = []\n    for i, chunk in enumerate(chunks):\n        chunk_name = ""tmp_chunks\\chunk{0}.wav"".format(i)\n        chunks_src.append(chunk_name)\n        chunk.export(chunk_name, format=""wav"")\n        \n    return chunks_src\n\n\n# Удаляем папку tmp_chunks с частями аудио\n\ndef delete_tmp_chunks(chunks_src):\n    for chunk in chunks_src:\n        os.remove(chunk)\n    os.rmdir(\'tmp_chunks\')\n\n# Соединяем распознанный по частям текст\n\ndef combine_text(text_array):\n    result_text = \'\'\n    for text in text_array:\n        result_text += text + \' \'\n    return result_text\n\n\n# ### Распознавание речи\n\n# Библиотека SpeechRecognition ( https://pypi.org/project/SpeechRecognition/ )\n# \n# Используется распознавание при помощи Google Speech Recognition\n# \n# Распознавание текста происходит непрерывно, даже когда речи нет, а есть только шум. Если распознать какие-то слова не удается, программа выдает ошибку. Поэтому нужно делить аудио на короткие части и распознавать их отдельно.\n# \n# Список языковых кодов для Google Speech Recognition: https://www.science.co.il/language/Locale-codes.php\n\n\n# Распознавание без учета шума\n\ndef recognize(audio_src):\n    # делим аудио на части\n    chunks_src = divide_audio(audio_src, 3000)\n    # распознаем каждую часть\n    text_array = []\n    for chunk_src in chunks_src:\n        a = sr.AudioFile(chunk_src)\n        with a as source:\n            audio = r.record(source)\n        try:\n            text_array.append(r.recognize_google(audio, language=\'ru\'))\n        except:\n            pass\n    # объединяем распознанные тексты\n    text = combine_text(text_array)\n    # удаляем ненужные файлы\n    delete_tmp_chunks(chunks_src)\n    \n    return text\n\n# Распознавание с учетом шума: уровень шума определяется автоматически\n\ndef recognize_with_noise(audio_src):\n    # делим аудио на части\n    chunks_src = divide_audio(audio_src, 3000)\n    # распознаем каждую часть\n    text_array = []\n    for chunk_src in chunks_src:\n        a = sr.AudioFile(chunk_src)\n        with a as source:\n            r.adjust_for_ambient_noise(source) # учитываем шум\n            audio = r.record(source)\n        try:\n            text_chunk = r.recognize_google(audio, language=\'ru\')\n            text_array.append(text_chunk)\n            #print(text_chunk)\n        except:\n            pass\n    # объединяем распознанные тексты\n    text = combine_text(text_array)\n    # удаляем ненужные файлы\n    delete_tmp_chunks(chunks_src)\n    \n    return text\n\n# итоговая функция распознавания\n\ndef wav_to_txt(path):\n    r = sr.Recognizer()\n    recognize_with_noise(path)\n    \n# для интеграции в main\n\nparser = argparse.ArgumentParser(description=\'wav_to_txt\')\nparser.add_argument(\'wav_path\', help=\'Path to .wav audio file\')\nparser.add_argument(\'out_path\', help=\'Path to output text file\')\n\nif __name__ == \'__main__\':\n    args = parser.parse_args()\n    txt = wav_to_txt(args.wav_path)\n    \n    f = open(args.out_path, ""a"")\n    f.write(txt) \n    f.close() \n\n\n;\n'}, {'main.py': '# -*- coding: utf-8 -*-\n\nfrom test import Hello\nimport argparse\nimport sys\nimport socket\nfrom TextFromPicture import Pic2Txt\nimport FFMPEGFrames\nimport glob\n\n\ndef main():\n    parser = argparse.ArgumentParser()\n\n    error_msg = ""Invalid Arguments\\n\\n"" \\\n                ""Commands: \\n"" \\\n                ""  -t, --test                 Let\'s test it!\\n"" \\\n                ""       Optional: --name=\'your_arg\'  -   that\'ll print your string your_arg\\n"" \\\n                ""  -v, --video             Convert video to pictures and then convert to text\\n"" \\\n                ""       Mandatory: --in_filename=\'files/video.mp4\' --out_filename=\'output.txt\'  --fps=\'1\'-  set input video, output file, frames per second ""\n\n    if len(sys.argv) == 1:\n        print(error_msg)\n\n    elif str(sys.argv[1]) in [\'-t\', \'--test\']:\n        parser.add_argument(\'-t\', \'--test\', action=\'store_true\')\n        parser.add_argument(""--name"", default=socket.gethostname())\n\n        args = parser.parse_args()\n\n        test_class = Hello(args.name)\n        test_class.print_hello()\n    elif str(sys.argv[1]) in [\'-v\', \'--video\']:\n        parser.add_argument(\'-v\', \'--video\', action=\'store_true\')\n        parser.add_argument(""in_filename"", help=\'Input filename\')\n        parser.add_argument(\'out_filename\', help=\'Output filename\')\n        parser.add_argument(""fps"", help=\'fps\')\n        args = vars(parser.parse_args())\n\n        input = args[""in_filename""]\n        output = args[""out_filename""]\n        fps = args[""fps""]\n\n        f = FFMPEGFrames.FFMPEGFrames(""images/"")\n        f.extract_frames(input, fps)\n        Pic2Txt(glob.glob(""images/*.png""), output)\n    else:\n        print(error_msg)\n\n\nif __name__ == \'__main__\':\n    main()\n\n;\n'}]","[{'SpeechRecognition.py': '# coding: utf-8\n\n# ### Функции пред- и постобработки\n\n# In[1]:\n\n\nfrom pydub import AudioSegment\nfrom scipy.io import wavfile\nimport os\nimport numpy as np\nimport speech_recognition as sr\nimport argparse\n\nparser = argparse.ArgumentParser(description=""wav_to_txt"")\nparser.add_argument(""wav_path"", help=""Path to .wav audio file"")\nparser.add_argument(""out_path"", help=""Path to output .txt file"")\n# Делим аудио (wav) на короткие части, сохраняем в папку tmp_slices\n\n# In[2]:\n\n\ndef divide_audio(audio_src, slice_length_ms=3000, overlap_ms=500):\n    audio = AudioSegment.from_file(audio_src, ""wav"")\n\n    slices = np.arange(0, len(audio) - overlap_ms, slice_length_ms - overlap_ms)\n\n    path = ""tmp_slices""\n    os.mkdir(path)\n    audio_slices_src = []\n    i = 0\n\n    for start, end in zip(slices[:-1], slices[1:]):\n        slice_ = audio[start : end + overlap_ms]\n        # сохраняем кусочки аудио\n        slice_name = ""tmp_slices\\slice{0}.wav"".format(i)\n        audio_slices_src.append(slice_name)\n        slice_.export(slice_name, format=""wav"")\n        i += 1\n\n    if len(audio) - end > overlap_ms:\n        slice_ = audio[end : len(audio)]\n        slice_name = ""tmp_slices\\slice{0}.wav"".format(i)\n        audio_slices_src.append(slice_name)\n        slice_.export(slice_name, format=""wav"")\n\n    return audio_slices_src\n\n\n# Удаляем папку tmp_slices с частями аудио\n\n# In[3]:\n\n\ndef delete_tmp_slices(audio_slices_src):\n    for slice_ in audio_slices_src:\n        os.remove(slice_)\n    os.rmdir(""tmp_slices"")\n\n\n# Соединяем распознанный по частям текст\n\n# In[4]:\n\n\ndef combine_text(text_array):\n    result_text = """"\n\n    prev_splited = []\n\n    for text in text_array:\n        processed_text = """"\n\n        splited = text.lower().split()\n\n        j = 0\n        while j < min(len(splited), len(prev_splited)):\n            if splited[j] != prev_splited[-1 - j]:\n                break\n            j += 1\n\n        for i in range(j, len(splited)):\n            processed_text += splited[i] + "" ""\n\n        result_text += processed_text\n\n        prev_splited = splited\n\n    return result_text\n\n\n# ### Распознавание речи\n\n# Библиотека SpeechRecognition ( https://pypi.org/project/SpeechRecognition/ )\n#\n# Используется распознавание при помощи Google Speech Recognition\n#\n# Распознавание текста происходит непрерывно, даже когда речи нет, а есть только шум. Если распознать какие-то слова не удается, программа выдает ошибку. Поэтому нужно делить аудио на короткие части и распознавать их отдельно.\n#\n# Список языковых кодов для Google Speech Recognition: https://www.science.co.il/language/Locale-codes.php\n\n# In[5]:\n\n\n# Распознавание без учета шума\n\n# In[6]:\n\n\ndef recognize_no_noise(audio_src):\n    r = sr.Recognizer()\n\n    # делим аудио на части\n    chunks_src = divide_audio(audio_src)\n    # распознаем каждую часть\n    text_array = []\n    for chunk_src in chunks_src:\n        a = sr.AudioFile(chunk_src)\n        # print(\'analyzing \', chunk_src)\n        with a as source:\n            audio = r.record(source)\n        try:\n            text_chunk = r.recognize_google(audio, language=""ru"")\n            text_array.append(text_chunk)\n            # print(\'!\',text_chunk)\n        except:\n            pass\n    # объединяем распознанные тексты\n    text = combine_text(text_array)\n\n    # удаляем ненужные файлы\n    delete_tmp_slices(chunks_src)\n\n    return text\n\n\n# In[7]:\n\n\n# print(recognize_no_noise(\'audio/test1.wav\'))\n\n\n# Распознавание с учетом шума: уровень шума определяется автоматически\n\n# In[8]:\n\n\ndef recognize_with_noise(audio_src):\n    r = sr.Recognizer()\n\n    # делим аудио на части\n    chunks_src = divide_audio(audio_src)\n    # распознаем каждую часть\n    text_array = []\n    for chunk_src in chunks_src:\n        a = sr.AudioFile(chunk_src)\n        # print(\'analyzing \', chunk_src)\n        with a as source:\n            r.adjust_for_ambient_noise(source)  # учитываем шум\n            audio = r.record(source)\n        try:\n            text_chunk = r.recognize_google(audio, language=""ru"")\n            text_array.append(text_chunk)\n            # print(text_chunk)\n        except:\n            pass\n    # объединяем распознанные тексты\n    text = combine_text(text_array)\n    # удаляем ненужные файлы\n    delete_tmp_slices(chunks_src)\n\n    return text\n\n\n# In[9]:\n\n\n# print(recognize_with_noise(\'audio/test1.wav\'))\n\n\n# Итоговая функция распознавания, в которой выбирается наилучший вариант распознавания\n\n# In[10]:\n\n\ndef wav_to_txt(audio_src, out_txt_src):\n    no_noise_txt = recognize_no_noise(audio_src)\n    noise_txt = recognize_with_noise(audio_src)\n\n    text = no_noise_txt\n    if len(noise_txt.split()) > len(text.split()):\n        text = noise_txt\n\n    # записываем в файл\n    out = open(out_txt_src, ""a"")\n    out.write(text)\n    out.close()\n\n\n# Для интеграции в main\n\n# In[12]:\n\n\n# wav_to_txt(\'audio/test1.wav\', \'TEXT.txt\')\n\n\n# In[ ]:\n\nif __name__ == ""__main__"":\n    args = parser.parse_args()\n    wav_to_txt(args.wav_path, args.out_path)\n\n;\n'}, {'SpeechRecognition_mp3_to_text.py': ''}, {'main.py': '# -*- coding: utf-8 -*-\n\nfrom test import Hello\nimport argparse\nimport sys\nimport socket\nfrom TextFromPicture import Pic2Txt\nimport FFMPEGFrames\nimport glob\n\nfrom SpeechRecognition import wav_to_txt\n\ndef main():\n    parser = argparse.ArgumentParser()\n\n    error_msg = ""Invalid Arguments\\n\\n"" \\\n                ""Commands: \\n"" \\\n                ""  -t, --test                 Let\'s test it!\\n"" \\\n                ""       Optional: --name=\'your_arg\'  -   that\'ll print your string your_arg\\n"" \\\n                ""  -v, --video             Convert video to pictures and then convert to text\\n"" \\\n                ""       Mandatory: --in_filename=\'files/video.mp4\' --out_filename=\'output.txt\'  --fps=\'1\'-  set input video, output file, frames per second ""\n\n    if len(sys.argv) == 1:\n        print(error_msg)\n\n    elif str(sys.argv[1]) in [\'-t\', \'--test\']:\n        parser.add_argument(\'-t\', \'--test\', action=\'store_true\')\n        parser.add_argument(""--name"", default=socket.gethostname())\n\n        args = parser.parse_args()\n\n        test_class = Hello(args.name)\n        test_class.print_hello()\n    elif str(sys.argv[1]) in [\'-v\', \'--video\']:\n        parser.add_argument(\'-v\', \'--video\', action=\'store_true\')\n        parser.add_argument(""in_filename"", help=\'Input filename\')\n        parser.add_argument(\'out_filename\', help=\'Output filename\')\n        parser.add_argument(""fps"", help=\'fps\')\n        args = vars(parser.parse_args())\n\n        input = args[""in_filename""]\n        output = args[""out_filename""]\n        fps = args[""fps""]\n\n        f = FFMPEGFrames.FFMPEGFrames(""images/"")\n        f.extract_frames(input, fps)\n        Pic2Txt(glob.glob(""images/*.png""), output)\n    elif str(sys.argv[1] in [\'-a\', \'--audio\']):\n        parser.add_argument(\'-a\', \'--audio\', action=\'store_true\')\n        parser.add_argument(""in_filename"", help=\'Input filename\')\n        parser.add_argument(\'out_filename\', help=\'Output filename\')\n        args = vars(parser.parse_args())\n\n        input = args[""in_filename""]\n        output = args[""out_filename""]\n\n        wav_to_txt(input, output)\n    else:\n        print(error_msg)\n\n\nif __name__ == \'__main__\':\n    main()\n\n;\n'}]","{'def': 0, 'class': 0}","{'def': 0, 'class': 0}",['update']
2,155,b30446a3,"Integrated video-to-frame module into the main.py
",4,11,6,"[{'new_path': '.gitignore', 'diff': '@@ -46,4 +46,7 @@ docs/_build/\n \n #output files\n output.txt\n-./images\n\\ No newline at end of file\n+./images\n+\n+# IDE folder\n+.vscode\n\\ No newline at end of file\n'}, {'new_path': 'FFMPEGFrames.py', 'diff': '@@ -1,16 +1,20 @@\n import os\n import subprocess\n \n+\n class FFMPEGFrames:\n+\n     def __init__(self, output):\n         self.output = output\n \n     def extract_frames(self, input, fps):\n-        output = input.split(\'/\')[-1].split(\'.\')[0]\n+        self.output = input.split(\'/\')[-1].split(\'.\')[0]\n \n         if not os.path.exists(self.output):\n             os.makedirs(self.output)\n \n-        query = ""ffmpeg -i "" + input + "" -vf fps="" + str(fps) + "" "" + self.output + ""output%02d.png""\n-        response = subprocess.Popen(query, shell=True, stdout=subprocess.PIPE).stdout.read()\n+        query = ""ffmpeg -i "" + input + "" -vf fps="" + \\\n+            str(fps) + "" "" + self.output + ""output%02d.png""\n+        response = subprocess.Popen(\n+            query, shell=True, stdout=subprocess.PIPE).stdout.read()\n         s = str(response).encode(\'utf-8\')\n'}, {'new_path': 'main.py', 'diff': '@@ -8,6 +8,7 @@ from TextFromPicture import Pic2Txt\n import FFMPEGFrames\n import glob\n \n+\n def main():\n     parser = argparse.ArgumentParser()\n \n@@ -18,7 +19,6 @@ def main():\n                 ""  -v, --video             Convert video to pictures and then convert to text\\n"" \\\n                 ""       Mandatory: --in_filename=\'files/video.mp4\' --out_filename=\'output.txt\'  --fps=\'1\'-  set input video, output file, frames per second ""\n \n-\n     if len(sys.argv) == 1:\n         print(error_msg)\n \n@@ -47,5 +47,6 @@ def main():\n     else:\n         print(error_msg)\n \n+\n if __name__ == \'__main__\':\n     main()\n'}, {'new_path': 'requirements.txt', 'diff': '@@ -1,5 +1,6 @@\n SpeechRecognition==3.8.1\n-ffmpeg==1.4\n+ffmpeg-python==0.2.0\n+opencv-python==4.2.0.32\n pdf2image==1.12.1\n pydub==0.23.1\n-pytesseract==0.3.2\n+pytesseract==0.3.3\n'}]", ;,"[{'diff': '@@ -46,4 +46,7 @@ docs/_build/\n \n #output files\n output.txt\n-./images\n\\ No newline at end of file\n+./images\n+\n+# IDE folder\n+.vscode\n\\ No newline at end of file\n'}, {'diff': '@@ -1,16 +1,20 @@\n import os\n import subprocess\n \n+\n class FFMPEGFrames:\n+\n     def __init__(self, output):\n         self.output = output\n \n     def extract_frames(self, input, fps):\n-        output = input.split(\'/\')[-1].split(\'.\')[0]\n+        self.output = input.split(\'/\')[-1].split(\'.\')[0]\n \n         if not os.path.exists(self.output):\n             os.makedirs(self.output)\n \n-        query = ""ffmpeg -i "" + input + "" -vf fps="" + str(fps) + "" "" + self.output + ""output%02d.png""\n-        response = subprocess.Popen(query, shell=True, stdout=subprocess.PIPE).stdout.read()\n+        query = ""ffmpeg -i "" + input + "" -vf fps="" + \\\n+            str(fps) + "" "" + self.output + ""output%02d.png""\n+        response = subprocess.Popen(\n+            query, shell=True, stdout=subprocess.PIPE).stdout.read()\n         s = str(response).encode(\'utf-8\')\n'}, {'diff': '@@ -8,6 +8,7 @@ from TextFromPicture import Pic2Txt\n import FFMPEGFrames\n import glob\n \n+\n def main():\n     parser = argparse.ArgumentParser()\n \n@@ -18,7 +19,6 @@ def main():\n                 ""  -v, --video             Convert video to pictures and then convert to text\\n"" \\\n                 ""       Mandatory: --in_filename=\'files/video.mp4\' --out_filename=\'output.txt\'  --fps=\'1\'-  set input video, output file, frames per second ""\n \n-\n     if len(sys.argv) == 1:\n         print(error_msg)\n \n@@ -47,5 +47,6 @@ def main():\n     else:\n         print(error_msg)\n \n+\n if __name__ == \'__main__\':\n     main()\n'}, {'diff': '@@ -1,5 +1,6 @@\n SpeechRecognition==3.8.1\n-ffmpeg==1.4\n+ffmpeg-python==0.2.0\n+opencv-python==4.2.0.32\n pdf2image==1.12.1\n pydub==0.23.1\n-pytesseract==0.3.2\n+pytesseract==0.3.3\n'}]","./images;# IDE folder;.vscode;        self.output = input.split('/')[-1].split('.')[0];        query = ""ffmpeg -i "" + input + "" -vf fps="" + \;            str(fps) + "" "" + self.output + ""output%02d.png"";        response = subprocess.Popen(;            query, shell=True, stdout=subprocess.PIPE).stdout.read();ffmpeg-python==0.2.0;opencv-python==4.2.0.32;pytesseract==0.3.3;","./images;        output = input.split('/')[-1].split('.')[0];        query = ""ffmpeg -i "" + input + "" -vf fps="" + str(fps) + "" "" + self.output + ""output%02d.png"";        response = subprocess.Popen(query, shell=True, stdout=subprocess.PIPE).stdout.read();ffmpeg==1.4;pytesseract==0.3.2;",https://git.miem.hse.ru/19121/recognition_miem/-/commit/b30446a3b78d0a59edb1e42bd358f28da15f4d54,0,0,"['.gitignore', 'FFMPEGFrames.py', 'main.py', 'requirements.txt']","import os
import subprocess


class FFMPEGFrames:

    def __init__(self, output):
        self.output = output

    def extract_frames(self, input, fps):
        self.output = input.split('/')[-1].split('.')[0]

        if not os.path.exists(self.output):
            os.makedirs(self.output)

        query = ""ffmpeg -i "" + input + "" -vf fps="" + \
            str(fps) + "" "" + self.output + ""output%02d.png""
        response = subprocess.Popen(
            query, shell=True, stdout=subprocess.PIPE).stdout.read()
        s = str(response).encode('utf-8')

;
# -*- coding: utf-8 -*-

from test import Hello
import argparse
import sys
import socket
from TextFromPicture import Pic2Txt
import FFMPEGFrames
import glob


def main():
    parser = argparse.ArgumentParser()

    error_msg = ""Invalid Arguments\n\n"" \
                ""Commands: \n"" \
                ""  -t, --test                 Let's test it!\n"" \
                ""       Optional: --name='your_arg'  -   that'll print your string your_arg\n"" \
                ""  -v, --video             Convert video to pictures and then convert to text\n"" \
                ""       Mandatory: --in_filename='files/video.mp4' --out_filename='output.txt'  --fps='1'-  set input video, output file, frames per second ""

    if len(sys.argv) == 1:
        print(error_msg)

    elif str(sys.argv[1]) in ['-t', '--test']:
        parser.add_argument('-t', '--test', action='store_true')
        parser.add_argument(""--name"", default=socket.gethostname())

        args = parser.parse_args()

        test_class = Hello(args.name)
        test_class.print_hello()
    elif str(sys.argv[1]) in ['-v', '--video']:
        parser.add_argument('-v', '--video', action='store_true')
        parser.add_argument(""in_filename"", help='Input filename')
        parser.add_argument('out_filename', help='Output filename')
        parser.add_argument(""fps"", help='fps')
        args = vars(parser.parse_args())

        input = args[""in_filename""]
        output = args[""out_filename""]
        fps = args[""fps""]

        f = FFMPEGFrames.FFMPEGFrames(""images/"")
        f.extract_frames(input, fps)
        Pic2Txt(glob.glob(""images/*.png""), output)
    else:
        print(error_msg)


if __name__ == '__main__':
    main()

;
","import os
import subprocess

class FFMPEGFrames:
    def __init__(self, output):
        self.output = output

    def extract_frames(self, input, fps):
        output = input.split('/')[-1].split('.')[0]

        if not os.path.exists(self.output):
            os.makedirs(self.output)

        query = ""ffmpeg -i "" + input + "" -vf fps="" + str(fps) + "" "" + self.output + ""output%02d.png""
        response = subprocess.Popen(query, shell=True, stdout=subprocess.PIPE).stdout.read()
        s = str(response).encode('utf-8')

;
# -*- coding: utf-8 -*-

from test import Hello
import argparse
import sys
import socket
from TextFromPicture import Pic2Txt
import FFMPEGFrames
import glob

def main():
    parser = argparse.ArgumentParser()

    error_msg = ""Invalid Arguments\n\n"" \
                ""Commands: \n"" \
                ""  -t, --test                 Let's test it!\n"" \
                ""       Optional: --name='your_arg'  -   that'll print your string your_arg\n"" \
                ""  -v, --video             Convert video to pictures and then convert to text\n"" \
                ""       Mandatory: --in_filename='files/video.mp4' --out_filename='output.txt'  --fps='1'-  set input video, output file, frames per second ""


    if len(sys.argv) == 1:
        print(error_msg)

    elif str(sys.argv[1]) in ['-t', '--test']:
        parser.add_argument('-t', '--test', action='store_true')
        parser.add_argument(""--name"", default=socket.gethostname())

        args = parser.parse_args()

        test_class = Hello(args.name)
        test_class.print_hello()
    elif str(sys.argv[1]) in ['-v', '--video']:
        parser.add_argument('-v', '--video', action='store_true')
        parser.add_argument(""in_filename"", help='Input filename')
        parser.add_argument('out_filename', help='Output filename')
        parser.add_argument(""fps"", help='fps')
        args = vars(parser.parse_args())

        input = args[""in_filename""]
        output = args[""out_filename""]
        fps = args[""fps""]

        f = FFMPEGFrames.FFMPEGFrames(""images/"")
        f.extract_frames(input, fps)
        Pic2Txt(glob.glob(""images/*.png""), output)
    else:
        print(error_msg)

if __name__ == '__main__':
    main()

;
",2,"[{'FFMPEGFrames.py': 'import os\nimport subprocess\n\nclass FFMPEGFrames:\n    def __init__(self, output):\n        self.output = output\n\n    def extract_frames(self, input, fps):\n        output = input.split(\'/\')[-1].split(\'.\')[0]\n\n        if not os.path.exists(self.output):\n            os.makedirs(self.output)\n\n        query = ""ffmpeg -i "" + input + "" -vf fps="" + str(fps) + "" "" + self.output + ""output%02d.png""\n        response = subprocess.Popen(query, shell=True, stdout=subprocess.PIPE).stdout.read()\n        s = str(response).encode(\'utf-8\')\n\n;\n'}, {'main.py': '# -*- coding: utf-8 -*-\n\nfrom test import Hello\nimport argparse\nimport sys\nimport socket\nfrom TextFromPicture import Pic2Txt\nimport FFMPEGFrames\nimport glob\n\ndef main():\n    parser = argparse.ArgumentParser()\n\n    error_msg = ""Invalid Arguments\\n\\n"" \\\n                ""Commands: \\n"" \\\n                ""  -t, --test                 Let\'s test it!\\n"" \\\n                ""       Optional: --name=\'your_arg\'  -   that\'ll print your string your_arg\\n"" \\\n                ""  -v, --video             Convert video to pictures and then convert to text\\n"" \\\n                ""       Mandatory: --in_filename=\'files/video.mp4\' --out_filename=\'output.txt\'  --fps=\'1\'-  set input video, output file, frames per second ""\n\n\n    if len(sys.argv) == 1:\n        print(error_msg)\n\n    elif str(sys.argv[1]) in [\'-t\', \'--test\']:\n        parser.add_argument(\'-t\', \'--test\', action=\'store_true\')\n        parser.add_argument(""--name"", default=socket.gethostname())\n\n        args = parser.parse_args()\n\n        test_class = Hello(args.name)\n        test_class.print_hello()\n    elif str(sys.argv[1]) in [\'-v\', \'--video\']:\n        parser.add_argument(\'-v\', \'--video\', action=\'store_true\')\n        parser.add_argument(""in_filename"", help=\'Input filename\')\n        parser.add_argument(\'out_filename\', help=\'Output filename\')\n        parser.add_argument(""fps"", help=\'fps\')\n        args = vars(parser.parse_args())\n\n        input = args[""in_filename""]\n        output = args[""out_filename""]\n        fps = args[""fps""]\n\n        f = FFMPEGFrames.FFMPEGFrames(""images/"")\n        f.extract_frames(input, fps)\n        Pic2Txt(glob.glob(""images/*.png""), output)\n    else:\n        print(error_msg)\n\nif __name__ == \'__main__\':\n    main()\n\n;\n'}]","[{'FFMPEGFrames.py': 'import os\nimport subprocess\n\n\nclass FFMPEGFrames:\n\n    def __init__(self, output):\n        self.output = output\n\n    def extract_frames(self, input, fps):\n        self.output = input.split(\'/\')[-1].split(\'.\')[0]\n\n        if not os.path.exists(self.output):\n            os.makedirs(self.output)\n\n        query = ""ffmpeg -i "" + input + "" -vf fps="" + \\\n            str(fps) + "" "" + self.output + ""output%02d.png""\n        response = subprocess.Popen(\n            query, shell=True, stdout=subprocess.PIPE).stdout.read()\n        s = str(response).encode(\'utf-8\')\n\n;\n'}, {'main.py': '# -*- coding: utf-8 -*-\n\nfrom test import Hello\nimport argparse\nimport sys\nimport socket\nfrom TextFromPicture import Pic2Txt\nimport FFMPEGFrames\nimport glob\n\n\ndef main():\n    parser = argparse.ArgumentParser()\n\n    error_msg = ""Invalid Arguments\\n\\n"" \\\n                ""Commands: \\n"" \\\n                ""  -t, --test                 Let\'s test it!\\n"" \\\n                ""       Optional: --name=\'your_arg\'  -   that\'ll print your string your_arg\\n"" \\\n                ""  -v, --video             Convert video to pictures and then convert to text\\n"" \\\n                ""       Mandatory: --in_filename=\'files/video.mp4\' --out_filename=\'output.txt\'  --fps=\'1\'-  set input video, output file, frames per second ""\n\n    if len(sys.argv) == 1:\n        print(error_msg)\n\n    elif str(sys.argv[1]) in [\'-t\', \'--test\']:\n        parser.add_argument(\'-t\', \'--test\', action=\'store_true\')\n        parser.add_argument(""--name"", default=socket.gethostname())\n\n        args = parser.parse_args()\n\n        test_class = Hello(args.name)\n        test_class.print_hello()\n    elif str(sys.argv[1]) in [\'-v\', \'--video\']:\n        parser.add_argument(\'-v\', \'--video\', action=\'store_true\')\n        parser.add_argument(""in_filename"", help=\'Input filename\')\n        parser.add_argument(\'out_filename\', help=\'Output filename\')\n        parser.add_argument(""fps"", help=\'fps\')\n        args = vars(parser.parse_args())\n\n        input = args[""in_filename""]\n        output = args[""out_filename""]\n        fps = args[""fps""]\n\n        f = FFMPEGFrames.FFMPEGFrames(""images/"")\n        f.extract_frames(input, fps)\n        Pic2Txt(glob.glob(""images/*.png""), output)\n    else:\n        print(error_msg)\n\n\nif __name__ == \'__main__\':\n    main()\n\n;\n'}]","{'def': 0, 'class': 0}","{'def': 0, 'class': 0}",[]
3,155,88eb4ac7,"Integrated video-to-frame module into the main.py
",5,41,15,"[{'new_path': '.gitignore', 'diff': '@@ -43,3 +43,7 @@ coverage.xml\n \n # Sphinx documentation\n docs/_build/\n+\n+#output files\n+output.txt\n+./images\n\\ No newline at end of file\n'}, {'new_path': 'FFMPEGFrames.py', 'diff': '@@ -0,0 +1,16 @@\n+import os\n+import subprocess\n+\n+class FFMPEGFrames:\n+    def __init__(self, output):\n+        self.output = output\n+\n+    def extract_frames(self, input, fps):\n+        output = input.split(\'/\')[-1].split(\'.\')[0]\n+\n+        if not os.path.exists(self.output):\n+            os.makedirs(self.output)\n+\n+        query = ""ffmpeg -i "" + input + "" -vf fps="" + str(fps) + "" "" + self.output + ""output%02d.png""\n+        response = subprocess.Popen(query, shell=True, stdout=subprocess.PIPE).stdout.read()\n+        s = str(response).encode(\'utf-8\')\n'}, {'new_path': 'README.md', 'diff': '@@ -2,11 +2,14 @@\n \n To run this script, you need to:\n \n-1. Download ffmpeg for [Windows](https://ffmpeg.org/download.html#build-windows) or [MacOS](https://ffmpeg.org/download.html#build-mac\n-)\n-2. Put your video file into the folder ./videos in the root of the project\n+1. Install ffmpeg, pytesseract, cv2\n+    ```bash\n+        sudo pip3 install ffmpeg-python pytesseract opencv-python\n+    ```\n+2. Put your video file into the folder ./files in the root of the project\n 3. Run from cli\n-```bash\n-    ffmpeg -i videos/{video-name.format} -vf fps=1 images/out%d.png\n-```\n-This command will convert video into the series of images with 1 frame per second and put them info ./images folder\n\\ No newline at end of file\n+    ```bash\n+        python3 main.py -v files/videoplayback.mp4 output.txt 1\n+    ```\n+    This command will convert video into the series of images with 1 frame per second.\n+    After that, array of images are going to be parsed into .txt file as text.\n\\ No newline at end of file\n'}, {'new_path': 'get-video-stream.py', 'diff': ""@@ -1,35 +0,0 @@\n-#!/usr/bin/env python\n-from __future__ import unicode_literals, print_function\n-import argparse\n-import ffmpeg\n-import sys\n-\n-\n-parser = argparse.ArgumentParser(description='Generate video thumbnail')\n-parser.add_argument('in_filename', help='Input filename')\n-parser.add_argument('out_filename', help='Output filename')\n-parser.add_argument(\n-    '--time', type=int, default=0.1, help='Time offset')\n-parser.add_argument(\n-    '--width', type=int, default=120,\n-    help='Width of output thumbnail (height automatically determined by aspect ratio)')\n-\n-\n-def generate_thumbnail(in_filename, out_filename, time, width):\n-    try:\n-        (\n-            ffmpeg\n-            .input(in_filename, ss=time)\n-            .filter('scale', width, -1)\n-            .output(out_filename, vframes=1)\n-            .overwrite_output()\n-            .run(capture_stdout=True, capture_stderr=True)\n-        )\n-    except ffmpeg.Error as e:\n-        print(e.stderr.decode(), file=sys.stderr)\n-        sys.exit(1)\n-\n-\n-if __name__ == '__main__':\n-    args = parser.parse_args()\n-    generate_thumbnail(args.in_filename, args.out_filename, args.time, args.width)\n\\ No newline at end of file\n""}, {'new_path': 'main.py', 'diff': '@@ -4,8 +4,9 @@ from test import Hello\n import argparse\n import sys\n import socket\n-from  TextFromPicture import Pic2Txt\n-\n+from TextFromPicture import Pic2Txt\n+import FFMPEGFrames\n+import glob\n \n def main():\n     parser = argparse.ArgumentParser()\n@@ -14,8 +15,8 @@ def main():\n                 ""Commands: \\n"" \\\n                 ""  -t, --test                 Let\'s test it!\\n"" \\\n                 ""       Optional: --name=\'your_arg\'  -   that\'ll print your string your_arg\\n"" \\\n-                ""  -p, --pictures             Convert pictures to text\\n"" \\\n-                ""       Mandatory: --in_filenames=\'img1.jpg(optional:,img2.(format))\' --out_filename=\'output.txt\'  -  set input image(s) and output file ""\n+                ""  -v, --video             Convert video to pictures and then convert to text\\n"" \\\n+                ""       Mandatory: --in_filename=\'files/video.mp4\' --out_filename=\'output.txt\'  --fps=\'1\'-  set input video, output file, frames per second ""\n \n \n     if len(sys.argv) == 1:\n@@ -29,18 +30,22 @@ def main():\n \n         test_class = Hello(args.name)\n         test_class.print_hello()\n-    elif str(sys.argv[1]) in [\'-p\', \'--pictures\']:\n-        parser.add_argument(\'-p\', \'--pictures\', action=\'store_true\')\n-        parser.add_argument(\'in_filenames\', help=\'Input filenames\')\n+    elif str(sys.argv[1]) in [\'-v\', \'--video\']:\n+        parser.add_argument(\'-v\', \'--video\', action=\'store_true\')\n+        parser.add_argument(""in_filename"", help=\'Input filename\')\n         parser.add_argument(\'out_filename\', help=\'Output filename\')\n+        parser.add_argument(""fps"", help=\'fps\')\n+        args = vars(parser.parse_args())\n \n-        args = parser.parse_args()\n+        input = args[""in_filename""]\n+        output = args[""out_filename""]\n+        fps = args[""fps""]\n \n-        Pic2Txt(args.in_filenames.split(\',\'), args.out_filename)\n-        \n+        f = FFMPEGFrames.FFMPEGFrames(""images/"")\n+        f.extract_frames(input, fps)\n+        Pic2Txt(glob.glob(""images/*.png""), output)\n     else:\n         print(error_msg)\n \n-\n if __name__ == \'__main__\':\n     main()\n'}]", ;,"[{'diff': '@@ -43,3 +43,7 @@ coverage.xml\n \n # Sphinx documentation\n docs/_build/\n+\n+#output files\n+output.txt\n+./images\n\\ No newline at end of file\n'}, {'diff': '@@ -0,0 +1,16 @@\n+import os\n+import subprocess\n+\n+class FFMPEGFrames:\n+    def __init__(self, output):\n+        self.output = output\n+\n+    def extract_frames(self, input, fps):\n+        output = input.split(\'/\')[-1].split(\'.\')[0]\n+\n+        if not os.path.exists(self.output):\n+            os.makedirs(self.output)\n+\n+        query = ""ffmpeg -i "" + input + "" -vf fps="" + str(fps) + "" "" + self.output + ""output%02d.png""\n+        response = subprocess.Popen(query, shell=True, stdout=subprocess.PIPE).stdout.read()\n+        s = str(response).encode(\'utf-8\')\n'}, {'diff': '@@ -2,11 +2,14 @@\n \n To run this script, you need to:\n \n-1. Download ffmpeg for [Windows](https://ffmpeg.org/download.html#build-windows) or [MacOS](https://ffmpeg.org/download.html#build-mac\n-)\n-2. Put your video file into the folder ./videos in the root of the project\n+1. Install ffmpeg, pytesseract, cv2\n+    ```bash\n+        sudo pip3 install ffmpeg-python pytesseract opencv-python\n+    ```\n+2. Put your video file into the folder ./files in the root of the project\n 3. Run from cli\n-```bash\n-    ffmpeg -i videos/{video-name.format} -vf fps=1 images/out%d.png\n-```\n-This command will convert video into the series of images with 1 frame per second and put them info ./images folder\n\\ No newline at end of file\n+    ```bash\n+        python3 main.py -v files/videoplayback.mp4 output.txt 1\n+    ```\n+    This command will convert video into the series of images with 1 frame per second.\n+    After that, array of images are going to be parsed into .txt file as text.\n\\ No newline at end of file\n'}, {'diff': ""@@ -1,35 +0,0 @@\n-#!/usr/bin/env python\n-from __future__ import unicode_literals, print_function\n-import argparse\n-import ffmpeg\n-import sys\n-\n-\n-parser = argparse.ArgumentParser(description='Generate video thumbnail')\n-parser.add_argument('in_filename', help='Input filename')\n-parser.add_argument('out_filename', help='Output filename')\n-parser.add_argument(\n-    '--time', type=int, default=0.1, help='Time offset')\n-parser.add_argument(\n-    '--width', type=int, default=120,\n-    help='Width of output thumbnail (height automatically determined by aspect ratio)')\n-\n-\n-def generate_thumbnail(in_filename, out_filename, time, width):\n-    try:\n-        (\n-            ffmpeg\n-            .input(in_filename, ss=time)\n-            .filter('scale', width, -1)\n-            .output(out_filename, vframes=1)\n-            .overwrite_output()\n-            .run(capture_stdout=True, capture_stderr=True)\n-        )\n-    except ffmpeg.Error as e:\n-        print(e.stderr.decode(), file=sys.stderr)\n-        sys.exit(1)\n-\n-\n-if __name__ == '__main__':\n-    args = parser.parse_args()\n-    generate_thumbnail(args.in_filename, args.out_filename, args.time, args.width)\n\\ No newline at end of file\n""}, {'diff': '@@ -4,8 +4,9 @@ from test import Hello\n import argparse\n import sys\n import socket\n-from  TextFromPicture import Pic2Txt\n-\n+from TextFromPicture import Pic2Txt\n+import FFMPEGFrames\n+import glob\n \n def main():\n     parser = argparse.ArgumentParser()\n@@ -14,8 +15,8 @@ def main():\n                 ""Commands: \\n"" \\\n                 ""  -t, --test                 Let\'s test it!\\n"" \\\n                 ""       Optional: --name=\'your_arg\'  -   that\'ll print your string your_arg\\n"" \\\n-                ""  -p, --pictures             Convert pictures to text\\n"" \\\n-                ""       Mandatory: --in_filenames=\'img1.jpg(optional:,img2.(format))\' --out_filename=\'output.txt\'  -  set input image(s) and output file ""\n+                ""  -v, --video             Convert video to pictures and then convert to text\\n"" \\\n+                ""       Mandatory: --in_filename=\'files/video.mp4\' --out_filename=\'output.txt\'  --fps=\'1\'-  set input video, output file, frames per second ""\n \n \n     if len(sys.argv) == 1:\n@@ -29,18 +30,22 @@ def main():\n \n         test_class = Hello(args.name)\n         test_class.print_hello()\n-    elif str(sys.argv[1]) in [\'-p\', \'--pictures\']:\n-        parser.add_argument(\'-p\', \'--pictures\', action=\'store_true\')\n-        parser.add_argument(\'in_filenames\', help=\'Input filenames\')\n+    elif str(sys.argv[1]) in [\'-v\', \'--video\']:\n+        parser.add_argument(\'-v\', \'--video\', action=\'store_true\')\n+        parser.add_argument(""in_filename"", help=\'Input filename\')\n         parser.add_argument(\'out_filename\', help=\'Output filename\')\n+        parser.add_argument(""fps"", help=\'fps\')\n+        args = vars(parser.parse_args())\n \n-        args = parser.parse_args()\n+        input = args[""in_filename""]\n+        output = args[""out_filename""]\n+        fps = args[""fps""]\n \n-        Pic2Txt(args.in_filenames.split(\',\'), args.out_filename)\n-        \n+        f = FFMPEGFrames.FFMPEGFrames(""images/"")\n+        f.extract_frames(input, fps)\n+        Pic2Txt(glob.glob(""images/*.png""), output)\n     else:\n         print(error_msg)\n \n-\n if __name__ == \'__main__\':\n     main()\n'}]","#output files;output.txt;./images;import os;import subprocess;class FFMPEGFrames:;    def __init__(self, output):;        self.output = output;    def extract_frames(self, input, fps):;        output = input.split('/')[-1].split('.')[0];        if not os.path.exists(self.output):;            os.makedirs(self.output);        query = ""ffmpeg -i "" + input + "" -vf fps="" + str(fps) + "" "" + self.output + ""output%02d.png"";        response = subprocess.Popen(query, shell=True, stdout=subprocess.PIPE).stdout.read();        s = str(response).encode('utf-8');1. Install ffmpeg, pytesseract, cv2;    ```bash;        sudo pip3 install ffmpeg-python pytesseract opencv-python;    ```;2. Put your video file into the folder ./files in the root of the project;    ```bash;        python3 main.py -v files/videoplayback.mp4 output.txt 1;    ```;    This command will convert video into the series of images with 1 frame per second.;    After that, array of images are going to be parsed into .txt file as text.;from TextFromPicture import Pic2Txt;import FFMPEGFrames;import glob;                ""  -v, --video             Convert video to pictures and then convert to text\n"" \;                ""       Mandatory: --in_filename='files/video.mp4' --out_filename='output.txt'  --fps='1'-  set input video, output file, frames per second "";    elif str(sys.argv[1]) in ['-v', '--video']:;        parser.add_argument('-v', '--video', action='store_true');        parser.add_argument(""in_filename"", help='Input filename');        parser.add_argument(""fps"", help='fps');        args = vars(parser.parse_args());        input = args[""in_filename""];        output = args[""out_filename""];        fps = args[""fps""];        f = FFMPEGFrames.FFMPEGFrames(""images/"");        f.extract_frames(input, fps);        Pic2Txt(glob.glob(""images/*.png""), output);","1. Download ffmpeg for [Windows](https://ffmpeg.org/download.html#build-windows) or [MacOS](https://ffmpeg.org/download.html#build-mac;);2. Put your video file into the folder ./videos in the root of the project;```bash;    ffmpeg -i videos/{video-name.format} -vf fps=1 images/out%d.png;```;This command will convert video into the series of images with 1 frame per second and put them info ./images folder;from  TextFromPicture import Pic2Txt;                ""  -p, --pictures             Convert pictures to text\n"" \;                ""       Mandatory: --in_filenames='img1.jpg(optional:,img2.(format))' --out_filename='output.txt'  -  set input image(s) and output file "";    elif str(sys.argv[1]) in ['-p', '--pictures']:;        parser.add_argument('-p', '--pictures', action='store_true');        parser.add_argument('in_filenames', help='Input filenames');        args = parser.parse_args();        Pic2Txt(args.in_filenames.split(','), args.out_filename);        ;",https://git.miem.hse.ru/19121/recognition_miem/-/commit/88eb4ac7cb6c44f307b4a54d1141d21b4986a2d8,5,1,"['.gitignore', 'FFMPEGFrames.py', 'README.md', 'get-video-stream.py', 'main.py']","import os
import subprocess

class FFMPEGFrames:
    def __init__(self, output):
        self.output = output

    def extract_frames(self, input, fps):
        output = input.split('/')[-1].split('.')[0]

        if not os.path.exists(self.output):
            os.makedirs(self.output)

        query = ""ffmpeg -i "" + input + "" -vf fps="" + str(fps) + "" "" + self.output + ""output%02d.png""
        response = subprocess.Popen(query, shell=True, stdout=subprocess.PIPE).stdout.read()
        s = str(response).encode('utf-8')

;
# -*- coding: utf-8 -*-

from test import Hello
import argparse
import sys
import socket
from TextFromPicture import Pic2Txt
import FFMPEGFrames
import glob

def main():
    parser = argparse.ArgumentParser()

    error_msg = ""Invalid Arguments\n\n"" \
                ""Commands: \n"" \
                ""  -t, --test                 Let's test it!\n"" \
                ""       Optional: --name='your_arg'  -   that'll print your string your_arg\n"" \
                ""  -v, --video             Convert video to pictures and then convert to text\n"" \
                ""       Mandatory: --in_filename='files/video.mp4' --out_filename='output.txt'  --fps='1'-  set input video, output file, frames per second ""


    if len(sys.argv) == 1:
        print(error_msg)

    elif str(sys.argv[1]) in ['-t', '--test']:
        parser.add_argument('-t', '--test', action='store_true')
        parser.add_argument(""--name"", default=socket.gethostname())

        args = parser.parse_args()

        test_class = Hello(args.name)
        test_class.print_hello()
    elif str(sys.argv[1]) in ['-v', '--video']:
        parser.add_argument('-v', '--video', action='store_true')
        parser.add_argument(""in_filename"", help='Input filename')
        parser.add_argument('out_filename', help='Output filename')
        parser.add_argument(""fps"", help='fps')
        args = vars(parser.parse_args())

        input = args[""in_filename""]
        output = args[""out_filename""]
        fps = args[""fps""]

        f = FFMPEGFrames.FFMPEGFrames(""images/"")
        f.extract_frames(input, fps)
        Pic2Txt(glob.glob(""images/*.png""), output)
    else:
        print(error_msg)

if __name__ == '__main__':
    main()

;
","#!/usr/bin/env python
from __future__ import unicode_literals, print_function
import argparse
import ffmpeg
import sys


parser = argparse.ArgumentParser(description='Generate video thumbnail')
parser.add_argument('in_filename', help='Input filename')
parser.add_argument('out_filename', help='Output filename')
parser.add_argument(
    '--time', type=int, default=0.1, help='Time offset')
parser.add_argument(
    '--width', type=int, default=120,
    help='Width of output thumbnail (height automatically determined by aspect ratio)')


def generate_thumbnail(in_filename, out_filename, time, width):
    try:
        (
            ffmpeg
            .input(in_filename, ss=time)
            .filter('scale', width, -1)
            .output(out_filename, vframes=1)
            .overwrite_output()
            .run(capture_stdout=True, capture_stderr=True)
        )
    except ffmpeg.Error as e:
        print(e.stderr.decode(), file=sys.stderr)
        sys.exit(1)


if __name__ == '__main__':
    args = parser.parse_args()
    generate_thumbnail(args.in_filename, args.out_filename, args.time, args.width)
;
# -*- coding: utf-8 -*-

from test import Hello
import argparse
import sys
import socket
from  TextFromPicture import Pic2Txt


def main():
    parser = argparse.ArgumentParser()

    error_msg = ""Invalid Arguments\n\n"" \
                ""Commands: \n"" \
                ""  -t, --test                 Let's test it!\n"" \
                ""       Optional: --name='your_arg'  -   that'll print your string your_arg\n"" \
                ""  -p, --pictures             Convert pictures to text\n"" \
                ""       Mandatory: --in_filenames='img1.jpg(optional:,img2.(format))' --out_filename='output.txt'  -  set input image(s) and output file ""


    if len(sys.argv) == 1:
        print(error_msg)

    elif str(sys.argv[1]) in ['-t', '--test']:
        parser.add_argument('-t', '--test', action='store_true')
        parser.add_argument(""--name"", default=socket.gethostname())

        args = parser.parse_args()

        test_class = Hello(args.name)
        test_class.print_hello()
    elif str(sys.argv[1]) in ['-p', '--pictures']:
        parser.add_argument('-p', '--pictures', action='store_true')
        parser.add_argument('in_filenames', help='Input filenames')
        parser.add_argument('out_filename', help='Output filename')

        args = parser.parse_args()

        Pic2Txt(args.in_filenames.split(','), args.out_filename)
        
    else:
        print(error_msg)


if __name__ == '__main__':
    main()

;
",3,"[{'FFMPEGFrames.py': ''}, {'get-video-stream.py': ""#!/usr/bin/env python\nfrom __future__ import unicode_literals, print_function\nimport argparse\nimport ffmpeg\nimport sys\n\n\nparser = argparse.ArgumentParser(description='Generate video thumbnail')\nparser.add_argument('in_filename', help='Input filename')\nparser.add_argument('out_filename', help='Output filename')\nparser.add_argument(\n    '--time', type=int, default=0.1, help='Time offset')\nparser.add_argument(\n    '--width', type=int, default=120,\n    help='Width of output thumbnail (height automatically determined by aspect ratio)')\n\n\ndef generate_thumbnail(in_filename, out_filename, time, width):\n    try:\n        (\n            ffmpeg\n            .input(in_filename, ss=time)\n            .filter('scale', width, -1)\n            .output(out_filename, vframes=1)\n            .overwrite_output()\n            .run(capture_stdout=True, capture_stderr=True)\n        )\n    except ffmpeg.Error as e:\n        print(e.stderr.decode(), file=sys.stderr)\n        sys.exit(1)\n\n\nif __name__ == '__main__':\n    args = parser.parse_args()\n    generate_thumbnail(args.in_filename, args.out_filename, args.time, args.width)\n;\n""}, {'main.py': '# -*- coding: utf-8 -*-\n\nfrom test import Hello\nimport argparse\nimport sys\nimport socket\nfrom  TextFromPicture import Pic2Txt\n\n\ndef main():\n    parser = argparse.ArgumentParser()\n\n    error_msg = ""Invalid Arguments\\n\\n"" \\\n                ""Commands: \\n"" \\\n                ""  -t, --test                 Let\'s test it!\\n"" \\\n                ""       Optional: --name=\'your_arg\'  -   that\'ll print your string your_arg\\n"" \\\n                ""  -p, --pictures             Convert pictures to text\\n"" \\\n                ""       Mandatory: --in_filenames=\'img1.jpg(optional:,img2.(format))\' --out_filename=\'output.txt\'  -  set input image(s) and output file ""\n\n\n    if len(sys.argv) == 1:\n        print(error_msg)\n\n    elif str(sys.argv[1]) in [\'-t\', \'--test\']:\n        parser.add_argument(\'-t\', \'--test\', action=\'store_true\')\n        parser.add_argument(""--name"", default=socket.gethostname())\n\n        args = parser.parse_args()\n\n        test_class = Hello(args.name)\n        test_class.print_hello()\n    elif str(sys.argv[1]) in [\'-p\', \'--pictures\']:\n        parser.add_argument(\'-p\', \'--pictures\', action=\'store_true\')\n        parser.add_argument(\'in_filenames\', help=\'Input filenames\')\n        parser.add_argument(\'out_filename\', help=\'Output filename\')\n\n        args = parser.parse_args()\n\n        Pic2Txt(args.in_filenames.split(\',\'), args.out_filename)\n        \n    else:\n        print(error_msg)\n\n\nif __name__ == \'__main__\':\n    main()\n\n;\n'}]","[{'FFMPEGFrames.py': 'import os\nimport subprocess\n\nclass FFMPEGFrames:\n    def __init__(self, output):\n        self.output = output\n\n    def extract_frames(self, input, fps):\n        output = input.split(\'/\')[-1].split(\'.\')[0]\n\n        if not os.path.exists(self.output):\n            os.makedirs(self.output)\n\n        query = ""ffmpeg -i "" + input + "" -vf fps="" + str(fps) + "" "" + self.output + ""output%02d.png""\n        response = subprocess.Popen(query, shell=True, stdout=subprocess.PIPE).stdout.read()\n        s = str(response).encode(\'utf-8\')\n\n;\n'}, {'get-video-stream.py': ''}, {'main.py': '# -*- coding: utf-8 -*-\n\nfrom test import Hello\nimport argparse\nimport sys\nimport socket\nfrom TextFromPicture import Pic2Txt\nimport FFMPEGFrames\nimport glob\n\ndef main():\n    parser = argparse.ArgumentParser()\n\n    error_msg = ""Invalid Arguments\\n\\n"" \\\n                ""Commands: \\n"" \\\n                ""  -t, --test                 Let\'s test it!\\n"" \\\n                ""       Optional: --name=\'your_arg\'  -   that\'ll print your string your_arg\\n"" \\\n                ""  -v, --video             Convert video to pictures and then convert to text\\n"" \\\n                ""       Mandatory: --in_filename=\'files/video.mp4\' --out_filename=\'output.txt\'  --fps=\'1\'-  set input video, output file, frames per second ""\n\n\n    if len(sys.argv) == 1:\n        print(error_msg)\n\n    elif str(sys.argv[1]) in [\'-t\', \'--test\']:\n        parser.add_argument(\'-t\', \'--test\', action=\'store_true\')\n        parser.add_argument(""--name"", default=socket.gethostname())\n\n        args = parser.parse_args()\n\n        test_class = Hello(args.name)\n        test_class.print_hello()\n    elif str(sys.argv[1]) in [\'-v\', \'--video\']:\n        parser.add_argument(\'-v\', \'--video\', action=\'store_true\')\n        parser.add_argument(""in_filename"", help=\'Input filename\')\n        parser.add_argument(\'out_filename\', help=\'Output filename\')\n        parser.add_argument(""fps"", help=\'fps\')\n        args = vars(parser.parse_args())\n\n        input = args[""in_filename""]\n        output = args[""out_filename""]\n        fps = args[""fps""]\n\n        f = FFMPEGFrames.FFMPEGFrames(""images/"")\n        f.extract_frames(input, fps)\n        Pic2Txt(glob.glob(""images/*.png""), output)\n    else:\n        print(error_msg)\n\nif __name__ == \'__main__\':\n    main()\n\n;\n'}]","{'def': 2, 'class': 1}","{'def': 2, 'class': 1}",[]
4,155,3a9348b9,Update SpeechRecognition_mp3_to_text.py,1,12,4,"[{'new_path': 'SpeechRecognition_mp3_to_text.py', 'diff': '@@ -14,9 +14,6 @@ def mp3_to_wav(mp3_src, wav_src):\n     sound = AudioSegment.from_mp3(mp3_src)\n     sound.export(wav_src, format=""wav"")\n \n-# mp3_to_wav(\'audio\\grob.mp3\', \'audio\\grob.wav\')\n-\n-\n # Делим аудио (wav) на короткие части, сохраняем в папку tmp_chunks\n \n def divide_audio(audio_src, chunk_length_ms):\n@@ -84,10 +81,6 @@ def recognize(audio_src):\n     \n     return text\n \n-\n-#print(recognize(\'audio/vsyo_idet_po_planu.wav\'))\n-\n-\n # Распознавание с учетом шума: уровень шума определяется автоматически\n \n def recognize_with_noise(audio_src):\n@@ -97,7 +90,6 @@ def recognize_with_noise(audio_src):\n     text_array = []\n     for chunk_src in chunks_src:\n         a = sr.AudioFile(chunk_src)\n-        #print(\'analyzing \', chunk_src)\n         with a as source:\n             r.adjust_for_ambient_noise(source) # учитываем шум\n             audio = r.record(source)\n@@ -114,12 +106,23 @@ def recognize_with_noise(audio_src):\n     \n     return text\n \n-#print(recognize_with_noise(\'audio/vsyo_idet_po_planu.wav\'))\n-\n # итоговая функция распознавания\n \n-def mp3_to_txt():\n-\n+def wav_to_txt(path):\n     r = sr.Recognizer()\n-    mp3_to_wav(\'audio/grob.mp3\', \'audio/grob.wav\')\n-    recognize_with_noise(\'audio/grob.wav\')\n+    recognize_with_noise(path)\n+    \n+# для интеграции в main\n+\n+parser = argparse.ArgumentParser(description=\'wav_to_txt\')\n+parser.add_argument(\'wav_path\', help=\'Path to .wav audio file\')\n+parser.add_argument(\'out_path\', help=\'Path to output text file\')\n+\n+if __name__ == \'__main__\':\n+    args = parser.parse_args()\n+    txt = wav_to_txt(args.wav_path)\n+    \n+    f = open(args.out_path, ""a"")\n+    f.write(txt) \n+    f.close() \n+\n'}]", ;,"[{'diff': '@@ -14,9 +14,6 @@ def mp3_to_wav(mp3_src, wav_src):\n     sound = AudioSegment.from_mp3(mp3_src)\n     sound.export(wav_src, format=""wav"")\n \n-# mp3_to_wav(\'audio\\grob.mp3\', \'audio\\grob.wav\')\n-\n-\n # Делим аудио (wav) на короткие части, сохраняем в папку tmp_chunks\n \n def divide_audio(audio_src, chunk_length_ms):\n@@ -84,10 +81,6 @@ def recognize(audio_src):\n     \n     return text\n \n-\n-#print(recognize(\'audio/vsyo_idet_po_planu.wav\'))\n-\n-\n # Распознавание с учетом шума: уровень шума определяется автоматически\n \n def recognize_with_noise(audio_src):\n@@ -97,7 +90,6 @@ def recognize_with_noise(audio_src):\n     text_array = []\n     for chunk_src in chunks_src:\n         a = sr.AudioFile(chunk_src)\n-        #print(\'analyzing \', chunk_src)\n         with a as source:\n             r.adjust_for_ambient_noise(source) # учитываем шум\n             audio = r.record(source)\n@@ -114,12 +106,23 @@ def recognize_with_noise(audio_src):\n     \n     return text\n \n-#print(recognize_with_noise(\'audio/vsyo_idet_po_planu.wav\'))\n-\n # итоговая функция распознавания\n \n-def mp3_to_txt():\n-\n+def wav_to_txt(path):\n     r = sr.Recognizer()\n-    mp3_to_wav(\'audio/grob.mp3\', \'audio/grob.wav\')\n-    recognize_with_noise(\'audio/grob.wav\')\n+    recognize_with_noise(path)\n+    \n+# для интеграции в main\n+\n+parser = argparse.ArgumentParser(description=\'wav_to_txt\')\n+parser.add_argument(\'wav_path\', help=\'Path to .wav audio file\')\n+parser.add_argument(\'out_path\', help=\'Path to output text file\')\n+\n+if __name__ == \'__main__\':\n+    args = parser.parse_args()\n+    txt = wav_to_txt(args.wav_path)\n+    \n+    f = open(args.out_path, ""a"")\n+    f.write(txt) \n+    f.close() \n+\n'}]","def wav_to_txt(path):;    recognize_with_noise(path);    ;# для интеграции в main;parser = argparse.ArgumentParser(description='wav_to_txt');parser.add_argument('wav_path', help='Path to .wav audio file');parser.add_argument('out_path', help='Path to output text file');if __name__ == '__main__':;    args = parser.parse_args();    txt = wav_to_txt(args.wav_path);    ;    f = open(args.out_path, ""a"");    f.write(txt) ;    f.close() ;","#print(recognize_with_noise('audio/vsyo_idet_po_planu.wav'));def mp3_to_txt():;    mp3_to_wav('audio/grob.mp3', 'audio/grob.wav');    recognize_with_noise('audio/grob.wav');",https://git.miem.hse.ru/19121/recognition_miem/-/commit/3a9348b9c1d2c3a7380a44c179fa33a4d1fd87be,0,0,['SpeechRecognition_mp3_to_text.py'],"# coding: utf-8

# ### Функции пред- и постобработки

from pydub import AudioSegment
from pydub.utils import make_chunks
import os

import speech_recognition as sr

# Перевод из формата mp3 в wav

def mp3_to_wav(mp3_src, wav_src):
    sound = AudioSegment.from_mp3(mp3_src)
    sound.export(wav_src, format=""wav"")

# Делим аудио (wav) на короткие части, сохраняем в папку tmp_chunks

def divide_audio(audio_src, chunk_length_ms):
    audio = AudioSegment.from_file(audio_src, ""wav"") 
    chunks = make_chunks(audio, chunk_length_ms)
    
    path = ""tmp_chunks""
    os.mkdir(path)
    
    chunks_src = []
    for i, chunk in enumerate(chunks):
        chunk_name = ""tmp_chunks\chunk{0}.wav"".format(i)
        chunks_src.append(chunk_name)
        chunk.export(chunk_name, format=""wav"")
        
    return chunks_src


# Удаляем папку tmp_chunks с частями аудио

def delete_tmp_chunks(chunks_src):
    for chunk in chunks_src:
        os.remove(chunk)
    os.rmdir('tmp_chunks')

# Соединяем распознанный по частям текст

def combine_text(text_array):
    result_text = ''
    for text in text_array:
        result_text += text + ' '
    return result_text


# ### Распознавание речи

# Библиотека SpeechRecognition ( https://pypi.org/project/SpeechRecognition/ )
# 
# Используется распознавание при помощи Google Speech Recognition
# 
# Распознавание текста происходит непрерывно, даже когда речи нет, а есть только шум. Если распознать какие-то слова не удается, программа выдает ошибку. Поэтому нужно делить аудио на короткие части и распознавать их отдельно.
# 
# Список языковых кодов для Google Speech Recognition: https://www.science.co.il/language/Locale-codes.php


# Распознавание без учета шума

def recognize(audio_src):
    # делим аудио на части
    chunks_src = divide_audio(audio_src, 3000)
    # распознаем каждую часть
    text_array = []
    for chunk_src in chunks_src:
        a = sr.AudioFile(chunk_src)
        with a as source:
            audio = r.record(source)
        try:
            text_array.append(r.recognize_google(audio, language='ru'))
        except:
            pass
    # объединяем распознанные тексты
    text = combine_text(text_array)
    # удаляем ненужные файлы
    delete_tmp_chunks(chunks_src)
    
    return text

# Распознавание с учетом шума: уровень шума определяется автоматически

def recognize_with_noise(audio_src):
    # делим аудио на части
    chunks_src = divide_audio(audio_src, 3000)
    # распознаем каждую часть
    text_array = []
    for chunk_src in chunks_src:
        a = sr.AudioFile(chunk_src)
        with a as source:
            r.adjust_for_ambient_noise(source) # учитываем шум
            audio = r.record(source)
        try:
            text_chunk = r.recognize_google(audio, language='ru')
            text_array.append(text_chunk)
            #print(text_chunk)
        except:
            pass
    # объединяем распознанные тексты
    text = combine_text(text_array)
    # удаляем ненужные файлы
    delete_tmp_chunks(chunks_src)
    
    return text

# итоговая функция распознавания

def wav_to_txt(path):
    r = sr.Recognizer()
    recognize_with_noise(path)
    
# для интеграции в main

parser = argparse.ArgumentParser(description='wav_to_txt')
parser.add_argument('wav_path', help='Path to .wav audio file')
parser.add_argument('out_path', help='Path to output text file')

if __name__ == '__main__':
    args = parser.parse_args()
    txt = wav_to_txt(args.wav_path)
    
    f = open(args.out_path, ""a"")
    f.write(txt) 
    f.close() 


;
","# coding: utf-8

# ### Функции пред- и постобработки

from pydub import AudioSegment
from pydub.utils import make_chunks
import os

import speech_recognition as sr

# Перевод из формата mp3 в wav

def mp3_to_wav(mp3_src, wav_src):
    sound = AudioSegment.from_mp3(mp3_src)
    sound.export(wav_src, format=""wav"")

# mp3_to_wav('audio\grob.mp3', 'audio\grob.wav')


# Делим аудио (wav) на короткие части, сохраняем в папку tmp_chunks

def divide_audio(audio_src, chunk_length_ms):
    audio = AudioSegment.from_file(audio_src, ""wav"") 
    chunks = make_chunks(audio, chunk_length_ms)
    
    path = ""tmp_chunks""
    os.mkdir(path)
    
    chunks_src = []
    for i, chunk in enumerate(chunks):
        chunk_name = ""tmp_chunks\chunk{0}.wav"".format(i)
        chunks_src.append(chunk_name)
        chunk.export(chunk_name, format=""wav"")
        
    return chunks_src


# Удаляем папку tmp_chunks с частями аудио

def delete_tmp_chunks(chunks_src):
    for chunk in chunks_src:
        os.remove(chunk)
    os.rmdir('tmp_chunks')

# Соединяем распознанный по частям текст

def combine_text(text_array):
    result_text = ''
    for text in text_array:
        result_text += text + ' '
    return result_text


# ### Распознавание речи

# Библиотека SpeechRecognition ( https://pypi.org/project/SpeechRecognition/ )
# 
# Используется распознавание при помощи Google Speech Recognition
# 
# Распознавание текста происходит непрерывно, даже когда речи нет, а есть только шум. Если распознать какие-то слова не удается, программа выдает ошибку. Поэтому нужно делить аудио на короткие части и распознавать их отдельно.
# 
# Список языковых кодов для Google Speech Recognition: https://www.science.co.il/language/Locale-codes.php


# Распознавание без учета шума

def recognize(audio_src):
    # делим аудио на части
    chunks_src = divide_audio(audio_src, 3000)
    # распознаем каждую часть
    text_array = []
    for chunk_src in chunks_src:
        a = sr.AudioFile(chunk_src)
        with a as source:
            audio = r.record(source)
        try:
            text_array.append(r.recognize_google(audio, language='ru'))
        except:
            pass
    # объединяем распознанные тексты
    text = combine_text(text_array)
    # удаляем ненужные файлы
    delete_tmp_chunks(chunks_src)
    
    return text


#print(recognize('audio/vsyo_idet_po_planu.wav'))


# Распознавание с учетом шума: уровень шума определяется автоматически

def recognize_with_noise(audio_src):
    # делим аудио на части
    chunks_src = divide_audio(audio_src, 3000)
    # распознаем каждую часть
    text_array = []
    for chunk_src in chunks_src:
        a = sr.AudioFile(chunk_src)
        #print('analyzing ', chunk_src)
        with a as source:
            r.adjust_for_ambient_noise(source) # учитываем шум
            audio = r.record(source)
        try:
            text_chunk = r.recognize_google(audio, language='ru')
            text_array.append(text_chunk)
            #print(text_chunk)
        except:
            pass
    # объединяем распознанные тексты
    text = combine_text(text_array)
    # удаляем ненужные файлы
    delete_tmp_chunks(chunks_src)
    
    return text

#print(recognize_with_noise('audio/vsyo_idet_po_planu.wav'))

# итоговая функция распознавания

def mp3_to_txt():

    r = sr.Recognizer()
    mp3_to_wav('audio/grob.mp3', 'audio/grob.wav')
    recognize_with_noise('audio/grob.wav')

;
",1,"[{'SpeechRecognition_mp3_to_text.py': '# coding: utf-8\n\n# ### Функции пред- и постобработки\n\nfrom pydub import AudioSegment\nfrom pydub.utils import make_chunks\nimport os\n\nimport speech_recognition as sr\n\n# Перевод из формата mp3 в wav\n\ndef mp3_to_wav(mp3_src, wav_src):\n    sound = AudioSegment.from_mp3(mp3_src)\n    sound.export(wav_src, format=""wav"")\n\n# mp3_to_wav(\'audio\\grob.mp3\', \'audio\\grob.wav\')\n\n\n# Делим аудио (wav) на короткие части, сохраняем в папку tmp_chunks\n\ndef divide_audio(audio_src, chunk_length_ms):\n    audio = AudioSegment.from_file(audio_src, ""wav"") \n    chunks = make_chunks(audio, chunk_length_ms)\n    \n    path = ""tmp_chunks""\n    os.mkdir(path)\n    \n    chunks_src = []\n    for i, chunk in enumerate(chunks):\n        chunk_name = ""tmp_chunks\\chunk{0}.wav"".format(i)\n        chunks_src.append(chunk_name)\n        chunk.export(chunk_name, format=""wav"")\n        \n    return chunks_src\n\n\n# Удаляем папку tmp_chunks с частями аудио\n\ndef delete_tmp_chunks(chunks_src):\n    for chunk in chunks_src:\n        os.remove(chunk)\n    os.rmdir(\'tmp_chunks\')\n\n# Соединяем распознанный по частям текст\n\ndef combine_text(text_array):\n    result_text = \'\'\n    for text in text_array:\n        result_text += text + \' \'\n    return result_text\n\n\n# ### Распознавание речи\n\n# Библиотека SpeechRecognition ( https://pypi.org/project/SpeechRecognition/ )\n# \n# Используется распознавание при помощи Google Speech Recognition\n# \n# Распознавание текста происходит непрерывно, даже когда речи нет, а есть только шум. Если распознать какие-то слова не удается, программа выдает ошибку. Поэтому нужно делить аудио на короткие части и распознавать их отдельно.\n# \n# Список языковых кодов для Google Speech Recognition: https://www.science.co.il/language/Locale-codes.php\n\n\n# Распознавание без учета шума\n\ndef recognize(audio_src):\n    # делим аудио на части\n    chunks_src = divide_audio(audio_src, 3000)\n    # распознаем каждую часть\n    text_array = []\n    for chunk_src in chunks_src:\n        a = sr.AudioFile(chunk_src)\n        with a as source:\n            audio = r.record(source)\n        try:\n            text_array.append(r.recognize_google(audio, language=\'ru\'))\n        except:\n            pass\n    # объединяем распознанные тексты\n    text = combine_text(text_array)\n    # удаляем ненужные файлы\n    delete_tmp_chunks(chunks_src)\n    \n    return text\n\n\n#print(recognize(\'audio/vsyo_idet_po_planu.wav\'))\n\n\n# Распознавание с учетом шума: уровень шума определяется автоматически\n\ndef recognize_with_noise(audio_src):\n    # делим аудио на части\n    chunks_src = divide_audio(audio_src, 3000)\n    # распознаем каждую часть\n    text_array = []\n    for chunk_src in chunks_src:\n        a = sr.AudioFile(chunk_src)\n        #print(\'analyzing \', chunk_src)\n        with a as source:\n            r.adjust_for_ambient_noise(source) # учитываем шум\n            audio = r.record(source)\n        try:\n            text_chunk = r.recognize_google(audio, language=\'ru\')\n            text_array.append(text_chunk)\n            #print(text_chunk)\n        except:\n            pass\n    # объединяем распознанные тексты\n    text = combine_text(text_array)\n    # удаляем ненужные файлы\n    delete_tmp_chunks(chunks_src)\n    \n    return text\n\n#print(recognize_with_noise(\'audio/vsyo_idet_po_planu.wav\'))\n\n# итоговая функция распознавания\n\ndef mp3_to_txt():\n\n    r = sr.Recognizer()\n    mp3_to_wav(\'audio/grob.mp3\', \'audio/grob.wav\')\n    recognize_with_noise(\'audio/grob.wav\')\n\n;\n'}]","[{'SpeechRecognition_mp3_to_text.py': '# coding: utf-8\n\n# ### Функции пред- и постобработки\n\nfrom pydub import AudioSegment\nfrom pydub.utils import make_chunks\nimport os\n\nimport speech_recognition as sr\n\n# Перевод из формата mp3 в wav\n\ndef mp3_to_wav(mp3_src, wav_src):\n    sound = AudioSegment.from_mp3(mp3_src)\n    sound.export(wav_src, format=""wav"")\n\n# Делим аудио (wav) на короткие части, сохраняем в папку tmp_chunks\n\ndef divide_audio(audio_src, chunk_length_ms):\n    audio = AudioSegment.from_file(audio_src, ""wav"") \n    chunks = make_chunks(audio, chunk_length_ms)\n    \n    path = ""tmp_chunks""\n    os.mkdir(path)\n    \n    chunks_src = []\n    for i, chunk in enumerate(chunks):\n        chunk_name = ""tmp_chunks\\chunk{0}.wav"".format(i)\n        chunks_src.append(chunk_name)\n        chunk.export(chunk_name, format=""wav"")\n        \n    return chunks_src\n\n\n# Удаляем папку tmp_chunks с частями аудио\n\ndef delete_tmp_chunks(chunks_src):\n    for chunk in chunks_src:\n        os.remove(chunk)\n    os.rmdir(\'tmp_chunks\')\n\n# Соединяем распознанный по частям текст\n\ndef combine_text(text_array):\n    result_text = \'\'\n    for text in text_array:\n        result_text += text + \' \'\n    return result_text\n\n\n# ### Распознавание речи\n\n# Библиотека SpeechRecognition ( https://pypi.org/project/SpeechRecognition/ )\n# \n# Используется распознавание при помощи Google Speech Recognition\n# \n# Распознавание текста происходит непрерывно, даже когда речи нет, а есть только шум. Если распознать какие-то слова не удается, программа выдает ошибку. Поэтому нужно делить аудио на короткие части и распознавать их отдельно.\n# \n# Список языковых кодов для Google Speech Recognition: https://www.science.co.il/language/Locale-codes.php\n\n\n# Распознавание без учета шума\n\ndef recognize(audio_src):\n    # делим аудио на части\n    chunks_src = divide_audio(audio_src, 3000)\n    # распознаем каждую часть\n    text_array = []\n    for chunk_src in chunks_src:\n        a = sr.AudioFile(chunk_src)\n        with a as source:\n            audio = r.record(source)\n        try:\n            text_array.append(r.recognize_google(audio, language=\'ru\'))\n        except:\n            pass\n    # объединяем распознанные тексты\n    text = combine_text(text_array)\n    # удаляем ненужные файлы\n    delete_tmp_chunks(chunks_src)\n    \n    return text\n\n# Распознавание с учетом шума: уровень шума определяется автоматически\n\ndef recognize_with_noise(audio_src):\n    # делим аудио на части\n    chunks_src = divide_audio(audio_src, 3000)\n    # распознаем каждую часть\n    text_array = []\n    for chunk_src in chunks_src:\n        a = sr.AudioFile(chunk_src)\n        with a as source:\n            r.adjust_for_ambient_noise(source) # учитываем шум\n            audio = r.record(source)\n        try:\n            text_chunk = r.recognize_google(audio, language=\'ru\')\n            text_array.append(text_chunk)\n            #print(text_chunk)\n        except:\n            pass\n    # объединяем распознанные тексты\n    text = combine_text(text_array)\n    # удаляем ненужные файлы\n    delete_tmp_chunks(chunks_src)\n    \n    return text\n\n# итоговая функция распознавания\n\ndef wav_to_txt(path):\n    r = sr.Recognizer()\n    recognize_with_noise(path)\n    \n# для интеграции в main\n\nparser = argparse.ArgumentParser(description=\'wav_to_txt\')\nparser.add_argument(\'wav_path\', help=\'Path to .wav audio file\')\nparser.add_argument(\'out_path\', help=\'Path to output text file\')\n\nif __name__ == \'__main__\':\n    args = parser.parse_args()\n    txt = wav_to_txt(args.wav_path)\n    \n    f = open(args.out_path, ""a"")\n    f.write(txt) \n    f.close() \n\n\n;\n'}]","{'def': 1, 'class': 0}","{'def': 1, 'class': 0}",['update']
5,155,3fe6883e,"TextFromPicture gets input parameters and called from main file with -p
arg
",2,38,64,"[{'new_path': 'TextFromPicture.py', 'diff': '@@ -1,85 +1,42 @@\n-# -*- coding: utf-8 -*-\n-\n # Import libraries\n # from PIL import Image хуже распознается\n import cv2 \n import pytesseract \n import sys \n-from pdf2image import convert_from_path \n import os \n-\n-# Path of the pdf \n-PDF_file = ""FileName.pdf""\n-\n-\'\'\' \n-Part #1 : Converting PDF to images \n-\'\'\'\n-\n-# Store all the pages of the PDF in a variable \n-pages = convert_from_path(PDF_file, 500) \n-\n-# Counter to store images of each page of PDF to image \n-image_counter = 1\n-\n-# Iterate through all the pages stored above \n-for page in pages: \n-\n-\t# Declaring filename for each page of PDF as JPG \n-\t# For each page, filename will be: \n-\t# PDF page 1 -> page_1.jpg \n-\t# PDF page 2 -> page_2.jpg \n-\t# PDF page 3 -> page_3.jpg \n-\t# .... \n-\t# PDF page n -> page_n.jpg \n-\tfilename = ""page_""+str(image_counter)+"".jpg""\n-\t\n-\t# Save the image of the page in system \n-\tpage.save(filename, \'JPEG\') \n-\n-\t# Increment the counter to update filename \n-\timage_counter = image_counter + 1\n-\n-\'\'\' \n-Part #2 - Recognizing text from the images using OCR \n-\'\'\'\n-# Variable to get count of total number of pages \n-filelimit = image_counter-1\n-\n-# Creating a text file to write the output \n-outfile = ""out_text.txt""\n-\n-# Open the file in append mode so that \n-# All contents of all images are added to the same file \n-f = open(outfile, ""a"") \n-\n-# Iterate from 1 to total number of pages \n-for i in range(1, filelimit + 1): \n-\n-\t# Set filename to recognize text from \n-\t# Again, these files will be: \n-\t# page_1.jpg \n-\t# page_2.jpg \n-\t# .... \n-\t# page_n.jpg \n-\tfilename = ""page_""+str(i)+"".jpg""\n-\t\t\n-\t# Recognize the text as string in image using pytesserct \n-\ttext = str(((pytesseract.image_to_string(cv2.imread(filename),lang = \'eng+rus\')))) \n-\n-\t# The recognized text is stored in variable text \n-\t# Any string processing may be applied on text \n-\t# Here, basic formatting has been done: \n-\t# In many PDFs, at line ending, if a word can\'t \n-\t# be written fully, a \'hyphen\' is added. \n-\t# The rest of the word is written in the next line \n-\t# Eg: This is a sample text this word here GeeksF- \n-\t# orGeeks is half on first line, remaining on next. \n-\t# To remove this, we replace every \'-\\n\' to \'\'. \n-\ttext = text.replace(\'-\\n\', \'\')\t \n-\n-\t# Finally, write the processed text to the file. \n-\t#with open(fname, ""w"", encoding=""utf-8"") as f:\n-\tf.write(text) \n-\n-# Close the file after writing all the text. \n-f.close() \n+import argparse\n+\n+parser = argparse.ArgumentParser(description=\'OCR\')\n+parser.add_argument(\'in_filenames\', help=\'Input filenames\')\n+parser.add_argument(\'out_filename\', help=\'Output filename\')\n+\n+def Pic2Txt(listImg, outfile):\n+\n+\tf = open(outfile, ""a"") \n+\t# Iterate through all the image\n+\tfor img in listImg: \n+\n+\t\t# Recognize the text as string in image using pytesserct \n+\t\ttext = str(((pytesseract.image_to_string(cv2.imread(img),lang = \'eng+rus\')))) \n+\n+\t\t# The recognized text is stored in variable text \n+\t\t# Any string processing may be applied on text \n+\t\t# Here, basic formatting has been done: \n+\t\t# In many PDFs, at line ending, if a word can\'t \n+\t\t# be written fully, a \'hyphen\' is added. \n+\t\t# The rest of the word is written in the next line \n+\t\t# Eg: This is a sample text this word here GeeksF- \n+\t\t# orGeeks is half on first line, remaining on next. \n+\t\t# To remove this, we replace every \'-\\n\' to \'\'. \n+\t\ttext = text.replace(\'-\\n\', \'\')\t \n+\n+\t\t# Finally, write the processed text to the file. \n+\t\t#with open(fname, ""w"", encoding=""utf-8"") as f:\n+\t\tf.write(text) \n+\n+\t# Close the file after writing all the text. \n+\tf.close() \n+\n+if __name__ == \'__main__\':\n+    args = parser.parse_args()\n+    Pic2Txt(args.in_filenames.split(\',\'), args.out_filename)\n\\ No newline at end of file\n'}, {'new_path': 'main.py', 'diff': '@@ -4,6 +4,7 @@ from test import Hello\n import argparse\n import sys\n import socket\n+from  TextFromPicture import Pic2Txt\n \n \n def main():\n@@ -12,7 +13,9 @@ def main():\n     error_msg = ""Invalid Arguments\\n\\n"" \\\n                 ""Commands: \\n"" \\\n                 ""  -t, --test                 Let\'s test it!\\n"" \\\n-                ""       Optional: --name=\'your_arg\'  -   that\'ll print your string your_arg""\n+                ""       Optional: --name=\'your_arg\'  -   that\'ll print your string your_arg\\n"" \\\n+                ""  -p, --pictures             Convert pictures to text\\n"" \\\n+                ""       Mandatory: --in_filenames=\'img1.jpg(optional:,img2.(format))\' --out_filename=\'output.txt\'  -  set input image(s) and output file ""\n \n \n     if len(sys.argv) == 1:\n@@ -26,7 +29,15 @@ def main():\n \n         test_class = Hello(args.name)\n         test_class.print_hello()\n+    elif str(sys.argv[1]) in [\'-p\', \'--pictures\']:\n+        parser.add_argument(\'-p\', \'--pictures\', action=\'store_true\')\n+        parser.add_argument(\'in_filenames\', help=\'Input filenames\')\n+        parser.add_argument(\'out_filename\', help=\'Output filename\')\n \n+        args = parser.parse_args()\n+\n+        Pic2Txt(args.in_filenames.split(\',\'), args.out_filename)\n+        \n     else:\n         print(error_msg)\n \n'}]", ;,"[{'diff': '@@ -1,85 +1,42 @@\n-# -*- coding: utf-8 -*-\n-\n # Import libraries\n # from PIL import Image хуже распознается\n import cv2 \n import pytesseract \n import sys \n-from pdf2image import convert_from_path \n import os \n-\n-# Path of the pdf \n-PDF_file = ""FileName.pdf""\n-\n-\'\'\' \n-Part #1 : Converting PDF to images \n-\'\'\'\n-\n-# Store all the pages of the PDF in a variable \n-pages = convert_from_path(PDF_file, 500) \n-\n-# Counter to store images of each page of PDF to image \n-image_counter = 1\n-\n-# Iterate through all the pages stored above \n-for page in pages: \n-\n-\t# Declaring filename for each page of PDF as JPG \n-\t# For each page, filename will be: \n-\t# PDF page 1 -> page_1.jpg \n-\t# PDF page 2 -> page_2.jpg \n-\t# PDF page 3 -> page_3.jpg \n-\t# .... \n-\t# PDF page n -> page_n.jpg \n-\tfilename = ""page_""+str(image_counter)+"".jpg""\n-\t\n-\t# Save the image of the page in system \n-\tpage.save(filename, \'JPEG\') \n-\n-\t# Increment the counter to update filename \n-\timage_counter = image_counter + 1\n-\n-\'\'\' \n-Part #2 - Recognizing text from the images using OCR \n-\'\'\'\n-# Variable to get count of total number of pages \n-filelimit = image_counter-1\n-\n-# Creating a text file to write the output \n-outfile = ""out_text.txt""\n-\n-# Open the file in append mode so that \n-# All contents of all images are added to the same file \n-f = open(outfile, ""a"") \n-\n-# Iterate from 1 to total number of pages \n-for i in range(1, filelimit + 1): \n-\n-\t# Set filename to recognize text from \n-\t# Again, these files will be: \n-\t# page_1.jpg \n-\t# page_2.jpg \n-\t# .... \n-\t# page_n.jpg \n-\tfilename = ""page_""+str(i)+"".jpg""\n-\t\t\n-\t# Recognize the text as string in image using pytesserct \n-\ttext = str(((pytesseract.image_to_string(cv2.imread(filename),lang = \'eng+rus\')))) \n-\n-\t# The recognized text is stored in variable text \n-\t# Any string processing may be applied on text \n-\t# Here, basic formatting has been done: \n-\t# In many PDFs, at line ending, if a word can\'t \n-\t# be written fully, a \'hyphen\' is added. \n-\t# The rest of the word is written in the next line \n-\t# Eg: This is a sample text this word here GeeksF- \n-\t# orGeeks is half on first line, remaining on next. \n-\t# To remove this, we replace every \'-\\n\' to \'\'. \n-\ttext = text.replace(\'-\\n\', \'\')\t \n-\n-\t# Finally, write the processed text to the file. \n-\t#with open(fname, ""w"", encoding=""utf-8"") as f:\n-\tf.write(text) \n-\n-# Close the file after writing all the text. \n-f.close() \n+import argparse\n+\n+parser = argparse.ArgumentParser(description=\'OCR\')\n+parser.add_argument(\'in_filenames\', help=\'Input filenames\')\n+parser.add_argument(\'out_filename\', help=\'Output filename\')\n+\n+def Pic2Txt(listImg, outfile):\n+\n+\tf = open(outfile, ""a"") \n+\t# Iterate through all the image\n+\tfor img in listImg: \n+\n+\t\t# Recognize the text as string in image using pytesserct \n+\t\ttext = str(((pytesseract.image_to_string(cv2.imread(img),lang = \'eng+rus\')))) \n+\n+\t\t# The recognized text is stored in variable text \n+\t\t# Any string processing may be applied on text \n+\t\t# Here, basic formatting has been done: \n+\t\t# In many PDFs, at line ending, if a word can\'t \n+\t\t# be written fully, a \'hyphen\' is added. \n+\t\t# The rest of the word is written in the next line \n+\t\t# Eg: This is a sample text this word here GeeksF- \n+\t\t# orGeeks is half on first line, remaining on next. \n+\t\t# To remove this, we replace every \'-\\n\' to \'\'. \n+\t\ttext = text.replace(\'-\\n\', \'\')\t \n+\n+\t\t# Finally, write the processed text to the file. \n+\t\t#with open(fname, ""w"", encoding=""utf-8"") as f:\n+\t\tf.write(text) \n+\n+\t# Close the file after writing all the text. \n+\tf.close() \n+\n+if __name__ == \'__main__\':\n+    args = parser.parse_args()\n+    Pic2Txt(args.in_filenames.split(\',\'), args.out_filename)\n\\ No newline at end of file\n'}, {'diff': '@@ -4,6 +4,7 @@ from test import Hello\n import argparse\n import sys\n import socket\n+from  TextFromPicture import Pic2Txt\n \n \n def main():\n@@ -12,7 +13,9 @@ def main():\n     error_msg = ""Invalid Arguments\\n\\n"" \\\n                 ""Commands: \\n"" \\\n                 ""  -t, --test                 Let\'s test it!\\n"" \\\n-                ""       Optional: --name=\'your_arg\'  -   that\'ll print your string your_arg""\n+                ""       Optional: --name=\'your_arg\'  -   that\'ll print your string your_arg\\n"" \\\n+                ""  -p, --pictures             Convert pictures to text\\n"" \\\n+                ""       Mandatory: --in_filenames=\'img1.jpg(optional:,img2.(format))\' --out_filename=\'output.txt\'  -  set input image(s) and output file ""\n \n \n     if len(sys.argv) == 1:\n@@ -26,7 +29,15 @@ def main():\n \n         test_class = Hello(args.name)\n         test_class.print_hello()\n+    elif str(sys.argv[1]) in [\'-p\', \'--pictures\']:\n+        parser.add_argument(\'-p\', \'--pictures\', action=\'store_true\')\n+        parser.add_argument(\'in_filenames\', help=\'Input filenames\')\n+        parser.add_argument(\'out_filename\', help=\'Output filename\')\n \n+        args = parser.parse_args()\n+\n+        Pic2Txt(args.in_filenames.split(\',\'), args.out_filename)\n+        \n     else:\n         print(error_msg)\n \n'}]","import argparse;parser = argparse.ArgumentParser(description='OCR');parser.add_argument('in_filenames', help='Input filenames');parser.add_argument('out_filename', help='Output filename');def Pic2Txt(listImg, outfile):;	f = open(outfile, ""a"") ;	# Iterate through all the image;	for img in listImg: ;		# Recognize the text as string in image using pytesserct ;		text = str(((pytesseract.image_to_string(cv2.imread(img),lang = 'eng+rus')))) ;		# The recognized text is stored in variable text ;		# Any string processing may be applied on text ;		# Here, basic formatting has been done: ;		# In many PDFs, at line ending, if a word can't ;		# be written fully, a 'hyphen' is added. ;		# The rest of the word is written in the next line ;		# Eg: This is a sample text this word here GeeksF- ;		# orGeeks is half on first line, remaining on next. ;		# To remove this, we replace every '-\n' to ''. ;		text = text.replace('-\n', '')	 ;		# Finally, write the processed text to the file. ;		#with open(fname, ""w"", encoding=""utf-8"") as f:;		f.write(text) ;	# Close the file after writing all the text. ;	f.close() ;if __name__ == '__main__':;    args = parser.parse_args();    Pic2Txt(args.in_filenames.split(','), args.out_filename);from  TextFromPicture import Pic2Txt;                ""       Optional: --name='your_arg'  -   that'll print your string your_arg\n"" \;                ""  -p, --pictures             Convert pictures to text\n"" \;                ""       Mandatory: --in_filenames='img1.jpg(optional:,img2.(format))' --out_filename='output.txt'  -  set input image(s) and output file "";    elif str(sys.argv[1]) in ['-p', '--pictures']:;        parser.add_argument('-p', '--pictures', action='store_true');        parser.add_argument('in_filenames', help='Input filenames');        parser.add_argument('out_filename', help='Output filename');        args = parser.parse_args();        Pic2Txt(args.in_filenames.split(','), args.out_filename);        ;","# -*- coding: utf-8 -*-;from pdf2image import convert_from_path ;# Path of the pdf ;PDF_file = ""FileName.pdf"";''' ;Part #1 : Converting PDF to images ;''';# Store all the pages of the PDF in a variable ;pages = convert_from_path(PDF_file, 500) ;# Counter to store images of each page of PDF to image ;image_counter = 1;# Iterate through all the pages stored above ;for page in pages: ;	# Declaring filename for each page of PDF as JPG ;	# For each page, filename will be: ;	# PDF page 1 -> page_1.jpg ;	# PDF page 2 -> page_2.jpg ;	# PDF page 3 -> page_3.jpg ;	# .... ;	# PDF page n -> page_n.jpg ;	filename = ""page_""+str(image_counter)+"".jpg"";	;	# Save the image of the page in system ;	page.save(filename, 'JPEG') ;	# Increment the counter to update filename ;	image_counter = image_counter + 1;''' ;Part #2 - Recognizing text from the images using OCR ;''';# Variable to get count of total number of pages ;filelimit = image_counter-1;# Creating a text file to write the output ;outfile = ""out_text.txt"";# Open the file in append mode so that ;# All contents of all images are added to the same file ;f = open(outfile, ""a"") ;# Iterate from 1 to total number of pages ;for i in range(1, filelimit + 1): ;	# Set filename to recognize text from ;	# Again, these files will be: ;	# page_1.jpg ;	# page_2.jpg ;	# .... ;	# page_n.jpg ;	filename = ""page_""+str(i)+"".jpg"";		;	# Recognize the text as string in image using pytesserct ;	text = str(((pytesseract.image_to_string(cv2.imread(filename),lang = 'eng+rus')))) ;	# The recognized text is stored in variable text ;	# Any string processing may be applied on text ;	# Here, basic formatting has been done: ;	# In many PDFs, at line ending, if a word can't ;	# be written fully, a 'hyphen' is added. ;	# The rest of the word is written in the next line ;	# Eg: This is a sample text this word here GeeksF- ;	# orGeeks is half on first line, remaining on next. ;	# To remove this, we replace every '-\n' to ''. ;	text = text.replace('-\n', '')	 ;	# Finally, write the processed text to the file. ;	#with open(fname, ""w"", encoding=""utf-8"") as f:;	f.write(text) ;# Close the file after writing all the text. ;f.close() ;                ""       Optional: --name='your_arg'  -   that'll print your string your_arg"";",https://git.miem.hse.ru/19121/recognition_miem/-/commit/3fe6883e40216b9e57ce6f187aa4fd46bc21c784,2,1,"['TextFromPicture.py', 'main.py']","# Import libraries
# from PIL import Image хуже распознается
import cv2 
import pytesseract 
import sys 
import os 
import argparse

parser = argparse.ArgumentParser(description='OCR')
parser.add_argument('in_filenames', help='Input filenames')
parser.add_argument('out_filename', help='Output filename')

def Pic2Txt(listImg, outfile):

	f = open(outfile, ""a"") 
	# Iterate through all the image
	for img in listImg: 

		# Recognize the text as string in image using pytesserct 
		text = str(((pytesseract.image_to_string(cv2.imread(img),lang = 'eng+rus')))) 

		# The recognized text is stored in variable text 
		# Any string processing may be applied on text 
		# Here, basic formatting has been done: 
		# In many PDFs, at line ending, if a word can't 
		# be written fully, a 'hyphen' is added. 
		# The rest of the word is written in the next line 
		# Eg: This is a sample text this word here GeeksF- 
		# orGeeks is half on first line, remaining on next. 
		# To remove this, we replace every '-\n' to ''. 
		text = text.replace('-\n', '')	 

		# Finally, write the processed text to the file. 
		#with open(fname, ""w"", encoding=""utf-8"") as f:
		f.write(text) 

	# Close the file after writing all the text. 
	f.close() 

if __name__ == '__main__':
    args = parser.parse_args()
    Pic2Txt(args.in_filenames.split(','), args.out_filename)
;
# -*- coding: utf-8 -*-

from test import Hello
import argparse
import sys
import socket
from  TextFromPicture import Pic2Txt


def main():
    parser = argparse.ArgumentParser()

    error_msg = ""Invalid Arguments\n\n"" \
                ""Commands: \n"" \
                ""  -t, --test                 Let's test it!\n"" \
                ""       Optional: --name='your_arg'  -   that'll print your string your_arg\n"" \
                ""  -p, --pictures             Convert pictures to text\n"" \
                ""       Mandatory: --in_filenames='img1.jpg(optional:,img2.(format))' --out_filename='output.txt'  -  set input image(s) and output file ""


    if len(sys.argv) == 1:
        print(error_msg)

    elif str(sys.argv[1]) in ['-t', '--test']:
        parser.add_argument('-t', '--test', action='store_true')
        parser.add_argument(""--name"", default=socket.gethostname())

        args = parser.parse_args()

        test_class = Hello(args.name)
        test_class.print_hello()
    elif str(sys.argv[1]) in ['-p', '--pictures']:
        parser.add_argument('-p', '--pictures', action='store_true')
        parser.add_argument('in_filenames', help='Input filenames')
        parser.add_argument('out_filename', help='Output filename')

        args = parser.parse_args()

        Pic2Txt(args.in_filenames.split(','), args.out_filename)
        
    else:
        print(error_msg)


if __name__ == '__main__':
    main()

;
","# -*- coding: utf-8 -*-

# Import libraries
# from PIL import Image хуже распознается
import cv2 
import pytesseract 
import sys 
from pdf2image import convert_from_path 
import os 

# Path of the pdf 
PDF_file = ""FileName.pdf""

''' 
Part #1 : Converting PDF to images 
'''

# Store all the pages of the PDF in a variable 
pages = convert_from_path(PDF_file, 500) 

# Counter to store images of each page of PDF to image 
image_counter = 1

# Iterate through all the pages stored above 
for page in pages: 

	# Declaring filename for each page of PDF as JPG 
	# For each page, filename will be: 
	# PDF page 1 -> page_1.jpg 
	# PDF page 2 -> page_2.jpg 
	# PDF page 3 -> page_3.jpg 
	# .... 
	# PDF page n -> page_n.jpg 
	filename = ""page_""+str(image_counter)+"".jpg""
	
	# Save the image of the page in system 
	page.save(filename, 'JPEG') 

	# Increment the counter to update filename 
	image_counter = image_counter + 1

''' 
Part #2 - Recognizing text from the images using OCR 
'''
# Variable to get count of total number of pages 
filelimit = image_counter-1

# Creating a text file to write the output 
outfile = ""out_text.txt""

# Open the file in append mode so that 
# All contents of all images are added to the same file 
f = open(outfile, ""a"") 

# Iterate from 1 to total number of pages 
for i in range(1, filelimit + 1): 

	# Set filename to recognize text from 
	# Again, these files will be: 
	# page_1.jpg 
	# page_2.jpg 
	# .... 
	# page_n.jpg 
	filename = ""page_""+str(i)+"".jpg""
		
	# Recognize the text as string in image using pytesserct 
	text = str(((pytesseract.image_to_string(cv2.imread(filename),lang = 'eng+rus')))) 

	# The recognized text is stored in variable text 
	# Any string processing may be applied on text 
	# Here, basic formatting has been done: 
	# In many PDFs, at line ending, if a word can't 
	# be written fully, a 'hyphen' is added. 
	# The rest of the word is written in the next line 
	# Eg: This is a sample text this word here GeeksF- 
	# orGeeks is half on first line, remaining on next. 
	# To remove this, we replace every '-\n' to ''. 
	text = text.replace('-\n', '')	 

	# Finally, write the processed text to the file. 
	#with open(fname, ""w"", encoding=""utf-8"") as f:
	f.write(text) 

# Close the file after writing all the text. 
f.close() 

;
# -*- coding: utf-8 -*-

from test import Hello
import argparse
import sys
import socket


def main():
    parser = argparse.ArgumentParser()

    error_msg = ""Invalid Arguments\n\n"" \
                ""Commands: \n"" \
                ""  -t, --test                 Let's test it!\n"" \
                ""       Optional: --name='your_arg'  -   that'll print your string your_arg""


    if len(sys.argv) == 1:
        print(error_msg)

    elif str(sys.argv[1]) in ['-t', '--test']:
        parser.add_argument('-t', '--test', action='store_true')
        parser.add_argument(""--name"", default=socket.gethostname())

        args = parser.parse_args()

        test_class = Hello(args.name)
        test_class.print_hello()

    else:
        print(error_msg)


if __name__ == '__main__':
    main()

;
",2,"[{'TextFromPicture.py': '# -*- coding: utf-8 -*-\n\n# Import libraries\n# from PIL import Image хуже распознается\nimport cv2 \nimport pytesseract \nimport sys \nfrom pdf2image import convert_from_path \nimport os \n\n# Path of the pdf \nPDF_file = ""FileName.pdf""\n\n\'\'\' \nPart #1 : Converting PDF to images \n\'\'\'\n\n# Store all the pages of the PDF in a variable \npages = convert_from_path(PDF_file, 500) \n\n# Counter to store images of each page of PDF to image \nimage_counter = 1\n\n# Iterate through all the pages stored above \nfor page in pages: \n\n\t# Declaring filename for each page of PDF as JPG \n\t# For each page, filename will be: \n\t# PDF page 1 -> page_1.jpg \n\t# PDF page 2 -> page_2.jpg \n\t# PDF page 3 -> page_3.jpg \n\t# .... \n\t# PDF page n -> page_n.jpg \n\tfilename = ""page_""+str(image_counter)+"".jpg""\n\t\n\t# Save the image of the page in system \n\tpage.save(filename, \'JPEG\') \n\n\t# Increment the counter to update filename \n\timage_counter = image_counter + 1\n\n\'\'\' \nPart #2 - Recognizing text from the images using OCR \n\'\'\'\n# Variable to get count of total number of pages \nfilelimit = image_counter-1\n\n# Creating a text file to write the output \noutfile = ""out_text.txt""\n\n# Open the file in append mode so that \n# All contents of all images are added to the same file \nf = open(outfile, ""a"") \n\n# Iterate from 1 to total number of pages \nfor i in range(1, filelimit + 1): \n\n\t# Set filename to recognize text from \n\t# Again, these files will be: \n\t# page_1.jpg \n\t# page_2.jpg \n\t# .... \n\t# page_n.jpg \n\tfilename = ""page_""+str(i)+"".jpg""\n\t\t\n\t# Recognize the text as string in image using pytesserct \n\ttext = str(((pytesseract.image_to_string(cv2.imread(filename),lang = \'eng+rus\')))) \n\n\t# The recognized text is stored in variable text \n\t# Any string processing may be applied on text \n\t# Here, basic formatting has been done: \n\t# In many PDFs, at line ending, if a word can\'t \n\t# be written fully, a \'hyphen\' is added. \n\t# The rest of the word is written in the next line \n\t# Eg: This is a sample text this word here GeeksF- \n\t# orGeeks is half on first line, remaining on next. \n\t# To remove this, we replace every \'-\\n\' to \'\'. \n\ttext = text.replace(\'-\\n\', \'\')\t \n\n\t# Finally, write the processed text to the file. \n\t#with open(fname, ""w"", encoding=""utf-8"") as f:\n\tf.write(text) \n\n# Close the file after writing all the text. \nf.close() \n\n;\n'}, {'main.py': '# -*- coding: utf-8 -*-\n\nfrom test import Hello\nimport argparse\nimport sys\nimport socket\n\n\ndef main():\n    parser = argparse.ArgumentParser()\n\n    error_msg = ""Invalid Arguments\\n\\n"" \\\n                ""Commands: \\n"" \\\n                ""  -t, --test                 Let\'s test it!\\n"" \\\n                ""       Optional: --name=\'your_arg\'  -   that\'ll print your string your_arg""\n\n\n    if len(sys.argv) == 1:\n        print(error_msg)\n\n    elif str(sys.argv[1]) in [\'-t\', \'--test\']:\n        parser.add_argument(\'-t\', \'--test\', action=\'store_true\')\n        parser.add_argument(""--name"", default=socket.gethostname())\n\n        args = parser.parse_args()\n\n        test_class = Hello(args.name)\n        test_class.print_hello()\n\n    else:\n        print(error_msg)\n\n\nif __name__ == \'__main__\':\n    main()\n\n;\n'}]","[{'TextFromPicture.py': '# Import libraries\n# from PIL import Image хуже распознается\nimport cv2 \nimport pytesseract \nimport sys \nimport os \nimport argparse\n\nparser = argparse.ArgumentParser(description=\'OCR\')\nparser.add_argument(\'in_filenames\', help=\'Input filenames\')\nparser.add_argument(\'out_filename\', help=\'Output filename\')\n\ndef Pic2Txt(listImg, outfile):\n\n\tf = open(outfile, ""a"") \n\t# Iterate through all the image\n\tfor img in listImg: \n\n\t\t# Recognize the text as string in image using pytesserct \n\t\ttext = str(((pytesseract.image_to_string(cv2.imread(img),lang = \'eng+rus\')))) \n\n\t\t# The recognized text is stored in variable text \n\t\t# Any string processing may be applied on text \n\t\t# Here, basic formatting has been done: \n\t\t# In many PDFs, at line ending, if a word can\'t \n\t\t# be written fully, a \'hyphen\' is added. \n\t\t# The rest of the word is written in the next line \n\t\t# Eg: This is a sample text this word here GeeksF- \n\t\t# orGeeks is half on first line, remaining on next. \n\t\t# To remove this, we replace every \'-\\n\' to \'\'. \n\t\ttext = text.replace(\'-\\n\', \'\')\t \n\n\t\t# Finally, write the processed text to the file. \n\t\t#with open(fname, ""w"", encoding=""utf-8"") as f:\n\t\tf.write(text) \n\n\t# Close the file after writing all the text. \n\tf.close() \n\nif __name__ == \'__main__\':\n    args = parser.parse_args()\n    Pic2Txt(args.in_filenames.split(\',\'), args.out_filename)\n;\n'}, {'main.py': '# -*- coding: utf-8 -*-\n\nfrom test import Hello\nimport argparse\nimport sys\nimport socket\nfrom  TextFromPicture import Pic2Txt\n\n\ndef main():\n    parser = argparse.ArgumentParser()\n\n    error_msg = ""Invalid Arguments\\n\\n"" \\\n                ""Commands: \\n"" \\\n                ""  -t, --test                 Let\'s test it!\\n"" \\\n                ""       Optional: --name=\'your_arg\'  -   that\'ll print your string your_arg\\n"" \\\n                ""  -p, --pictures             Convert pictures to text\\n"" \\\n                ""       Mandatory: --in_filenames=\'img1.jpg(optional:,img2.(format))\' --out_filename=\'output.txt\'  -  set input image(s) and output file ""\n\n\n    if len(sys.argv) == 1:\n        print(error_msg)\n\n    elif str(sys.argv[1]) in [\'-t\', \'--test\']:\n        parser.add_argument(\'-t\', \'--test\', action=\'store_true\')\n        parser.add_argument(""--name"", default=socket.gethostname())\n\n        args = parser.parse_args()\n\n        test_class = Hello(args.name)\n        test_class.print_hello()\n    elif str(sys.argv[1]) in [\'-p\', \'--pictures\']:\n        parser.add_argument(\'-p\', \'--pictures\', action=\'store_true\')\n        parser.add_argument(\'in_filenames\', help=\'Input filenames\')\n        parser.add_argument(\'out_filename\', help=\'Output filename\')\n\n        args = parser.parse_args()\n\n        Pic2Txt(args.in_filenames.split(\',\'), args.out_filename)\n        \n    else:\n        print(error_msg)\n\n\nif __name__ == \'__main__\':\n    main()\n\n;\n'}]","{'def': 1, 'class': 0}","{'def': 1, 'class': 0}",[]
6,155,15819229,"Merge remote-tracking branch 'origin/master' into SofiaKochemasova
",6,129,1,"[{'new_path': '.gitattributes', 'diff': '@@ -0,0 +1,2 @@\n+# Auto detect text files and perform LF normalization\n+* text=auto\n'}, {'new_path': 'SpeechRecognition_2_mp3_to_text.py', 'diff': '@@ -0,0 +1,125 @@\n+# -*- coding: utf-8 -*-\n+\n+# ### Функции пред- и постобработки\n+\n+from pydub import AudioSegment\n+from pydub.utils import make_chunks\n+import os\n+\n+import speech_recognition as sr\n+\n+# Перевод из формата mp3 в wav\n+\n+def mp3_to_wav(mp3_src, wav_src):\n+    sound = AudioSegment.from_mp3(mp3_src)\n+    sound.export(wav_src, format=""wav"")\n+\n+# mp3_to_wav(\'audio\\grob.mp3\', \'audio\\grob.wav\')\n+\n+\n+# Делим аудио (wav) на короткие части, сохраняем в папку tmp_chunks\n+\n+def divide_audio(audio_src, chunk_length_ms):\n+    audio = AudioSegment.from_file(audio_src, ""wav"") \n+    chunks = make_chunks(audio, chunk_length_ms)\n+    \n+    path = ""tmp_chunks""\n+    os.mkdir(path)\n+    \n+    chunks_src = []\n+    for i, chunk in enumerate(chunks):\n+        chunk_name = ""tmp_chunks\\chunk{0}.wav"".format(i)\n+        chunks_src.append(chunk_name)\n+        chunk.export(chunk_name, format=""wav"")\n+        \n+    return chunks_src\n+\n+\n+# Удаляем папку tmp_chunks с частями аудио\n+\n+def delete_tmp_chunks(chunks_src):\n+    for chunk in chunks_src:\n+        os.remove(chunk)\n+    os.rmdir(\'tmp_chunks\')\n+\n+# Соединяем распознанный по частям текст\n+\n+def combine_text(text_array):\n+    result_text = \'\'\n+    for text in text_array:\n+        result_text += text + \' \'\n+    return result_text\n+\n+\n+# ### Распознавание речи\n+\n+# Библиотека SpeechRecognition ( https://pypi.org/project/SpeechRecognition/ )\n+# \n+# Используется распознавание при помощи Google Speech Recognition\n+# \n+# Распознавание текста происходит непрерывно, даже когда речи нет, а есть только шум. Если распознать какие-то слова не удается, программа выдает ошибку. Поэтому нужно делить аудио на короткие части и распознавать их отдельно.\n+# \n+# Список языковых кодов для Google Speech Recognition: https://www.science.co.il/language/Locale-codes.php\n+\n+\n+# Распознавание без учета шума\n+\n+def recognize(audio_src):\n+    # делим аудио на части\n+    chunks_src = divide_audio(audio_src, 3000)\n+    # распознаем каждую часть\n+    text_array = []\n+    for chunk_src in chunks_src:\n+        a = sr.AudioFile(chunk_src)\n+        with a as source:\n+            audio = r.record(source)\n+        try:\n+            text_array.append(r.recognize_google(audio, language=\'ru\'))\n+        except:\n+            pass\n+    # объединяем распознанные тексты\n+    text = combine_text(text_array)\n+    # удаляем ненужные файлы\n+    delete_tmp_chunks(chunks_src)\n+    \n+    return text\n+\n+\n+#print(recognize(\'audio/vsyo_idet_po_planu.wav\'))\n+\n+\n+# Распознавание с учетом шума: уровень шума определяется автоматически\n+\n+def recognize_with_noise(audio_src):\n+    # делим аудио на части\n+    chunks_src = divide_audio(audio_src, 3000)\n+    # распознаем каждую часть\n+    text_array = []\n+    for chunk_src in chunks_src:\n+        a = sr.AudioFile(chunk_src)\n+        #print(\'analyzing \', chunk_src)\n+        with a as source:\n+            r.adjust_for_ambient_noise(source) # учитываем шум\n+            audio = r.record(source)\n+        try:\n+            text_chunk = r.recognize_google(audio, language=\'ru\')\n+            text_array.append(text_chunk)\n+            #print(text_chunk)\n+        except:\n+            pass\n+    # объединяем распознанные тексты\n+    text = combine_text(text_array)\n+    # удаляем ненужные файлы\n+    delete_tmp_chunks(chunks_src)\n+    \n+    return text\n+\n+#print(recognize_with_noise(\'audio/vsyo_idet_po_planu.wav\'))\n+\n+# итоговая функция распознавания\n+\n+def mp3_to_txt():\n+\n+    r = sr.Recognizer()\n+    mp3_to_wav(\'audio/grob.mp3\', \'audio/grob.wav\')\n+    recognize_with_noise(\'audio/grob.wav\')\n'}, {'new_path': 'TextFromPicture.py', 'diff': '@@ -1,4 +1,6 @@\n-# Import libraries \n+# -*- coding: utf-8 -*-\n+\n+# Import libraries\n # from PIL import Image хуже распознается\n import cv2 \n import pytesseract \n'}, {'new_path': 'get-video-stream.py', 'diff': ""@@ -0,0 +1,35 @@\n+#!/usr/bin/env python\n+from __future__ import unicode_literals, print_function\n+import argparse\n+import ffmpeg\n+import sys\n+\n+\n+parser = argparse.ArgumentParser(description='Generate video thumbnail')\n+parser.add_argument('in_filename', help='Input filename')\n+parser.add_argument('out_filename', help='Output filename')\n+parser.add_argument(\n+    '--time', type=int, default=0.1, help='Time offset')\n+parser.add_argument(\n+    '--width', type=int, default=120,\n+    help='Width of output thumbnail (height automatically determined by aspect ratio)')\n+\n+\n+def generate_thumbnail(in_filename, out_filename, time, width):\n+    try:\n+        (\n+            ffmpeg\n+            .input(in_filename, ss=time)\n+            .filter('scale', width, -1)\n+            .output(out_filename, vframes=1)\n+            .overwrite_output()\n+            .run(capture_stdout=True, capture_stderr=True)\n+        )\n+    except ffmpeg.Error as e:\n+        print(e.stderr.decode(), file=sys.stderr)\n+        sys.exit(1)\n+\n+\n+if __name__ == '__main__':\n+    args = parser.parse_args()\n+    generate_thumbnail(args.in_filename, args.out_filename, args.time, args.width)\n\\ No newline at end of file\n""}, {'new_path': 'main.py', 'diff': '@@ -1,4 +1,5 @@\n # -*- coding: utf-8 -*-\n+\n from test import Hello\n import argparse\n import sys\n'}, {'new_path': 'requirements.txt', 'diff': '@@ -1 +1,5 @@\n-\n+SpeechRecognition==3.8.1\n+ffmpeg==1.4\n+pdf2image==1.12.1\n+pydub==0.23.1\n+pytesseract==0.3.2\n'}]", ;,"[{'diff': '@@ -0,0 +1,2 @@\n+# Auto detect text files and perform LF normalization\n+* text=auto\n'}, {'diff': '@@ -0,0 +1,125 @@\n+# -*- coding: utf-8 -*-\n+\n+# ### Функции пред- и постобработки\n+\n+from pydub import AudioSegment\n+from pydub.utils import make_chunks\n+import os\n+\n+import speech_recognition as sr\n+\n+# Перевод из формата mp3 в wav\n+\n+def mp3_to_wav(mp3_src, wav_src):\n+    sound = AudioSegment.from_mp3(mp3_src)\n+    sound.export(wav_src, format=""wav"")\n+\n+# mp3_to_wav(\'audio\\grob.mp3\', \'audio\\grob.wav\')\n+\n+\n+# Делим аудио (wav) на короткие части, сохраняем в папку tmp_chunks\n+\n+def divide_audio(audio_src, chunk_length_ms):\n+    audio = AudioSegment.from_file(audio_src, ""wav"") \n+    chunks = make_chunks(audio, chunk_length_ms)\n+    \n+    path = ""tmp_chunks""\n+    os.mkdir(path)\n+    \n+    chunks_src = []\n+    for i, chunk in enumerate(chunks):\n+        chunk_name = ""tmp_chunks\\chunk{0}.wav"".format(i)\n+        chunks_src.append(chunk_name)\n+        chunk.export(chunk_name, format=""wav"")\n+        \n+    return chunks_src\n+\n+\n+# Удаляем папку tmp_chunks с частями аудио\n+\n+def delete_tmp_chunks(chunks_src):\n+    for chunk in chunks_src:\n+        os.remove(chunk)\n+    os.rmdir(\'tmp_chunks\')\n+\n+# Соединяем распознанный по частям текст\n+\n+def combine_text(text_array):\n+    result_text = \'\'\n+    for text in text_array:\n+        result_text += text + \' \'\n+    return result_text\n+\n+\n+# ### Распознавание речи\n+\n+# Библиотека SpeechRecognition ( https://pypi.org/project/SpeechRecognition/ )\n+# \n+# Используется распознавание при помощи Google Speech Recognition\n+# \n+# Распознавание текста происходит непрерывно, даже когда речи нет, а есть только шум. Если распознать какие-то слова не удается, программа выдает ошибку. Поэтому нужно делить аудио на короткие части и распознавать их отдельно.\n+# \n+# Список языковых кодов для Google Speech Recognition: https://www.science.co.il/language/Locale-codes.php\n+\n+\n+# Распознавание без учета шума\n+\n+def recognize(audio_src):\n+    # делим аудио на части\n+    chunks_src = divide_audio(audio_src, 3000)\n+    # распознаем каждую часть\n+    text_array = []\n+    for chunk_src in chunks_src:\n+        a = sr.AudioFile(chunk_src)\n+        with a as source:\n+            audio = r.record(source)\n+        try:\n+            text_array.append(r.recognize_google(audio, language=\'ru\'))\n+        except:\n+            pass\n+    # объединяем распознанные тексты\n+    text = combine_text(text_array)\n+    # удаляем ненужные файлы\n+    delete_tmp_chunks(chunks_src)\n+    \n+    return text\n+\n+\n+#print(recognize(\'audio/vsyo_idet_po_planu.wav\'))\n+\n+\n+# Распознавание с учетом шума: уровень шума определяется автоматически\n+\n+def recognize_with_noise(audio_src):\n+    # делим аудио на части\n+    chunks_src = divide_audio(audio_src, 3000)\n+    # распознаем каждую часть\n+    text_array = []\n+    for chunk_src in chunks_src:\n+        a = sr.AudioFile(chunk_src)\n+        #print(\'analyzing \', chunk_src)\n+        with a as source:\n+            r.adjust_for_ambient_noise(source) # учитываем шум\n+            audio = r.record(source)\n+        try:\n+            text_chunk = r.recognize_google(audio, language=\'ru\')\n+            text_array.append(text_chunk)\n+            #print(text_chunk)\n+        except:\n+            pass\n+    # объединяем распознанные тексты\n+    text = combine_text(text_array)\n+    # удаляем ненужные файлы\n+    delete_tmp_chunks(chunks_src)\n+    \n+    return text\n+\n+#print(recognize_with_noise(\'audio/vsyo_idet_po_planu.wav\'))\n+\n+# итоговая функция распознавания\n+\n+def mp3_to_txt():\n+\n+    r = sr.Recognizer()\n+    mp3_to_wav(\'audio/grob.mp3\', \'audio/grob.wav\')\n+    recognize_with_noise(\'audio/grob.wav\')\n'}, {'diff': '@@ -1,4 +1,6 @@\n-# Import libraries \n+# -*- coding: utf-8 -*-\n+\n+# Import libraries\n # from PIL import Image хуже распознается\n import cv2 \n import pytesseract \n'}, {'diff': ""@@ -0,0 +1,35 @@\n+#!/usr/bin/env python\n+from __future__ import unicode_literals, print_function\n+import argparse\n+import ffmpeg\n+import sys\n+\n+\n+parser = argparse.ArgumentParser(description='Generate video thumbnail')\n+parser.add_argument('in_filename', help='Input filename')\n+parser.add_argument('out_filename', help='Output filename')\n+parser.add_argument(\n+    '--time', type=int, default=0.1, help='Time offset')\n+parser.add_argument(\n+    '--width', type=int, default=120,\n+    help='Width of output thumbnail (height automatically determined by aspect ratio)')\n+\n+\n+def generate_thumbnail(in_filename, out_filename, time, width):\n+    try:\n+        (\n+            ffmpeg\n+            .input(in_filename, ss=time)\n+            .filter('scale', width, -1)\n+            .output(out_filename, vframes=1)\n+            .overwrite_output()\n+            .run(capture_stdout=True, capture_stderr=True)\n+        )\n+    except ffmpeg.Error as e:\n+        print(e.stderr.decode(), file=sys.stderr)\n+        sys.exit(1)\n+\n+\n+if __name__ == '__main__':\n+    args = parser.parse_args()\n+    generate_thumbnail(args.in_filename, args.out_filename, args.time, args.width)\n\\ No newline at end of file\n""}, {'diff': '@@ -1,4 +1,5 @@\n # -*- coding: utf-8 -*-\n+\n from test import Hello\n import argparse\n import sys\n'}, {'diff': '@@ -1 +1,5 @@\n-\n+SpeechRecognition==3.8.1\n+ffmpeg==1.4\n+pdf2image==1.12.1\n+pydub==0.23.1\n+pytesseract==0.3.2\n'}]","# Auto detect text files and perform LF normalization;* text=auto;# -*- coding: utf-8 -*-;# ### Функции пред- и постобработки;from pydub import AudioSegment;from pydub.utils import make_chunks;import os;import speech_recognition as sr;# Перевод из формата mp3 в wav;def mp3_to_wav(mp3_src, wav_src):;    sound = AudioSegment.from_mp3(mp3_src);    sound.export(wav_src, format=""wav"");# mp3_to_wav('audio\grob.mp3', 'audio\grob.wav');# Делим аудио (wav) на короткие части, сохраняем в папку tmp_chunks;def divide_audio(audio_src, chunk_length_ms):;    audio = AudioSegment.from_file(audio_src, ""wav"") ;    chunks = make_chunks(audio, chunk_length_ms);    ;    path = ""tmp_chunks"";    os.mkdir(path);    ;    chunks_src = [];    for i, chunk in enumerate(chunks):;        chunk_name = ""tmp_chunks\chunk{0}.wav"".format(i);        chunks_src.append(chunk_name);        chunk.export(chunk_name, format=""wav"");        ;    return chunks_src;# Удаляем папку tmp_chunks с частями аудио;def delete_tmp_chunks(chunks_src):;    for chunk in chunks_src:;        os.remove(chunk);    os.rmdir('tmp_chunks');# Соединяем распознанный по частям текст;def combine_text(text_array):;    result_text = '';    for text in text_array:;        result_text += text + ' ';    return result_text;# ### Распознавание речи;# Библиотека SpeechRecognition ( https://pypi.org/project/SpeechRecognition/ );# ;# Используется распознавание при помощи Google Speech Recognition;# ;# Распознавание текста происходит непрерывно, даже когда речи нет, а есть только шум. Если распознать какие-то слова не удается, программа выдает ошибку. Поэтому нужно делить аудио на короткие части и распознавать их отдельно.;# ;# Список языковых кодов для Google Speech Recognition: https://www.science.co.il/language/Locale-codes.php;# Распознавание без учета шума;def recognize(audio_src):;    # делим аудио на части;    chunks_src = divide_audio(audio_src, 3000);    # распознаем каждую часть;    text_array = [];    for chunk_src in chunks_src:;        a = sr.AudioFile(chunk_src);        with a as source:;            audio = r.record(source);        try:;            text_array.append(r.recognize_google(audio, language='ru'));        except:;            pass;    # объединяем распознанные тексты;    text = combine_text(text_array);    # удаляем ненужные файлы;    delete_tmp_chunks(chunks_src);    ;    return text;#print(recognize('audio/vsyo_idet_po_planu.wav'));# Распознавание с учетом шума: уровень шума определяется автоматически;def recognize_with_noise(audio_src):;    # делим аудио на части;    chunks_src = divide_audio(audio_src, 3000);    # распознаем каждую часть;    text_array = [];    for chunk_src in chunks_src:;        a = sr.AudioFile(chunk_src);        #print('analyzing ', chunk_src);        with a as source:;            r.adjust_for_ambient_noise(source) # учитываем шум;            audio = r.record(source);        try:;            text_chunk = r.recognize_google(audio, language='ru');            text_array.append(text_chunk);            #print(text_chunk);        except:;            pass;    # объединяем распознанные тексты;    text = combine_text(text_array);    # удаляем ненужные файлы;    delete_tmp_chunks(chunks_src);    ;    return text;#print(recognize_with_noise('audio/vsyo_idet_po_planu.wav'));# итоговая функция распознавания;def mp3_to_txt():;    r = sr.Recognizer();    mp3_to_wav('audio/grob.mp3', 'audio/grob.wav');    recognize_with_noise('audio/grob.wav');# -*- coding: utf-8 -*-;# Import libraries;#!/usr/bin/env python;from __future__ import unicode_literals, print_function;import argparse;import ffmpeg;import sys;parser = argparse.ArgumentParser(description='Generate video thumbnail');parser.add_argument('in_filename', help='Input filename');parser.add_argument('out_filename', help='Output filename');parser.add_argument(;    '--time', type=int, default=0.1, help='Time offset');parser.add_argument(;    '--width', type=int, default=120,;    help='Width of output thumbnail (height automatically determined by aspect ratio)');def generate_thumbnail(in_filename, out_filename, time, width):;    try:;        (;            ffmpeg;            .input(in_filename, ss=time);            .filter('scale', width, -1);            .output(out_filename, vframes=1);            .overwrite_output();            .run(capture_stdout=True, capture_stderr=True);        );    except ffmpeg.Error as e:;        print(e.stderr.decode(), file=sys.stderr);        sys.exit(1);if __name__ == '__main__':;    args = parser.parse_args();    generate_thumbnail(args.in_filename, args.out_filename, args.time, args.width);SpeechRecognition==3.8.1;ffmpeg==1.4;pdf2image==1.12.1;pydub==0.23.1;pytesseract==0.3.2;",# Import libraries ;,https://git.miem.hse.ru/19121/recognition_miem/-/commit/158192297d4e9db6b305a6120fb655369483500f,8,0,"['.gitattributes', 'SpeechRecognition_2_mp3_to_text.py', 'TextFromPicture.py', 'get-video-stream.py', 'main.py', 'requirements.txt']","# -*- coding: utf-8 -*-

# ### Функции пред- и постобработки

from pydub import AudioSegment
from pydub.utils import make_chunks
import os

import speech_recognition as sr

# Перевод из формата mp3 в wav

def mp3_to_wav(mp3_src, wav_src):
    sound = AudioSegment.from_mp3(mp3_src)
    sound.export(wav_src, format=""wav"")

# mp3_to_wav('audio\grob.mp3', 'audio\grob.wav')


# Делим аудио (wav) на короткие части, сохраняем в папку tmp_chunks

def divide_audio(audio_src, chunk_length_ms):
    audio = AudioSegment.from_file(audio_src, ""wav"") 
    chunks = make_chunks(audio, chunk_length_ms)
    
    path = ""tmp_chunks""
    os.mkdir(path)
    
    chunks_src = []
    for i, chunk in enumerate(chunks):
        chunk_name = ""tmp_chunks\chunk{0}.wav"".format(i)
        chunks_src.append(chunk_name)
        chunk.export(chunk_name, format=""wav"")
        
    return chunks_src


# Удаляем папку tmp_chunks с частями аудио

def delete_tmp_chunks(chunks_src):
    for chunk in chunks_src:
        os.remove(chunk)
    os.rmdir('tmp_chunks')

# Соединяем распознанный по частям текст

def combine_text(text_array):
    result_text = ''
    for text in text_array:
        result_text += text + ' '
    return result_text


# ### Распознавание речи

# Библиотека SpeechRecognition ( https://pypi.org/project/SpeechRecognition/ )
# 
# Используется распознавание при помощи Google Speech Recognition
# 
# Распознавание текста происходит непрерывно, даже когда речи нет, а есть только шум. Если распознать какие-то слова не удается, программа выдает ошибку. Поэтому нужно делить аудио на короткие части и распознавать их отдельно.
# 
# Список языковых кодов для Google Speech Recognition: https://www.science.co.il/language/Locale-codes.php


# Распознавание без учета шума

def recognize(audio_src):
    # делим аудио на части
    chunks_src = divide_audio(audio_src, 3000)
    # распознаем каждую часть
    text_array = []
    for chunk_src in chunks_src:
        a = sr.AudioFile(chunk_src)
        with a as source:
            audio = r.record(source)
        try:
            text_array.append(r.recognize_google(audio, language='ru'))
        except:
            pass
    # объединяем распознанные тексты
    text = combine_text(text_array)
    # удаляем ненужные файлы
    delete_tmp_chunks(chunks_src)
    
    return text


#print(recognize('audio/vsyo_idet_po_planu.wav'))


# Распознавание с учетом шума: уровень шума определяется автоматически

def recognize_with_noise(audio_src):
    # делим аудио на части
    chunks_src = divide_audio(audio_src, 3000)
    # распознаем каждую часть
    text_array = []
    for chunk_src in chunks_src:
        a = sr.AudioFile(chunk_src)
        #print('analyzing ', chunk_src)
        with a as source:
            r.adjust_for_ambient_noise(source) # учитываем шум
            audio = r.record(source)
        try:
            text_chunk = r.recognize_google(audio, language='ru')
            text_array.append(text_chunk)
            #print(text_chunk)
        except:
            pass
    # объединяем распознанные тексты
    text = combine_text(text_array)
    # удаляем ненужные файлы
    delete_tmp_chunks(chunks_src)
    
    return text

#print(recognize_with_noise('audio/vsyo_idet_po_planu.wav'))

# итоговая функция распознавания

def mp3_to_txt():

    r = sr.Recognizer()
    mp3_to_wav('audio/grob.mp3', 'audio/grob.wav')
    recognize_with_noise('audio/grob.wav')

;
# -*- coding: utf-8 -*-

# Import libraries
# from PIL import Image хуже распознается
import cv2 
import pytesseract 
import sys 
from pdf2image import convert_from_path 
import os 

# Path of the pdf 
PDF_file = ""FileName.pdf""

''' 
Part #1 : Converting PDF to images 
'''

# Store all the pages of the PDF in a variable 
pages = convert_from_path(PDF_file, 500) 

# Counter to store images of each page of PDF to image 
image_counter = 1

# Iterate through all the pages stored above 
for page in pages: 

	# Declaring filename for each page of PDF as JPG 
	# For each page, filename will be: 
	# PDF page 1 -> page_1.jpg 
	# PDF page 2 -> page_2.jpg 
	# PDF page 3 -> page_3.jpg 
	# .... 
	# PDF page n -> page_n.jpg 
	filename = ""page_""+str(image_counter)+"".jpg""
	
	# Save the image of the page in system 
	page.save(filename, 'JPEG') 

	# Increment the counter to update filename 
	image_counter = image_counter + 1

''' 
Part #2 - Recognizing text from the images using OCR 
'''
# Variable to get count of total number of pages 
filelimit = image_counter-1

# Creating a text file to write the output 
outfile = ""out_text.txt""

# Open the file in append mode so that 
# All contents of all images are added to the same file 
f = open(outfile, ""a"") 

# Iterate from 1 to total number of pages 
for i in range(1, filelimit + 1): 

	# Set filename to recognize text from 
	# Again, these files will be: 
	# page_1.jpg 
	# page_2.jpg 
	# .... 
	# page_n.jpg 
	filename = ""page_""+str(i)+"".jpg""
		
	# Recognize the text as string in image using pytesserct 
	text = str(((pytesseract.image_to_string(cv2.imread(filename),lang = 'eng+rus')))) 

	# The recognized text is stored in variable text 
	# Any string processing may be applied on text 
	# Here, basic formatting has been done: 
	# In many PDFs, at line ending, if a word can't 
	# be written fully, a 'hyphen' is added. 
	# The rest of the word is written in the next line 
	# Eg: This is a sample text this word here GeeksF- 
	# orGeeks is half on first line, remaining on next. 
	# To remove this, we replace every '-\n' to ''. 
	text = text.replace('-\n', '')	 

	# Finally, write the processed text to the file. 
	#with open(fname, ""w"", encoding=""utf-8"") as f:
	f.write(text) 

# Close the file after writing all the text. 
f.close() 

;
#!/usr/bin/env python
from __future__ import unicode_literals, print_function
import argparse
import ffmpeg
import sys


parser = argparse.ArgumentParser(description='Generate video thumbnail')
parser.add_argument('in_filename', help='Input filename')
parser.add_argument('out_filename', help='Output filename')
parser.add_argument(
    '--time', type=int, default=0.1, help='Time offset')
parser.add_argument(
    '--width', type=int, default=120,
    help='Width of output thumbnail (height automatically determined by aspect ratio)')


def generate_thumbnail(in_filename, out_filename, time, width):
    try:
        (
            ffmpeg
            .input(in_filename, ss=time)
            .filter('scale', width, -1)
            .output(out_filename, vframes=1)
            .overwrite_output()
            .run(capture_stdout=True, capture_stderr=True)
        )
    except ffmpeg.Error as e:
        print(e.stderr.decode(), file=sys.stderr)
        sys.exit(1)


if __name__ == '__main__':
    args = parser.parse_args()
    generate_thumbnail(args.in_filename, args.out_filename, args.time, args.width)
;
# -*- coding: utf-8 -*-

from test import Hello
import argparse
import sys
import socket


def main():
    parser = argparse.ArgumentParser()

    error_msg = ""Invalid Arguments\n\n"" \
                ""Commands: \n"" \
                ""  -t, --test                 Let's test it!\n"" \
                ""       Optional: --name='your_arg'  -   that'll print your string your_arg""


    if len(sys.argv) == 1:
        print(error_msg)

    elif str(sys.argv[1]) in ['-t', '--test']:
        parser.add_argument('-t', '--test', action='store_true')
        parser.add_argument(""--name"", default=socket.gethostname())

        args = parser.parse_args()

        test_class = Hello(args.name)
        test_class.print_hello()

    else:
        print(error_msg)


if __name__ == '__main__':
    main()

;
","# Import libraries 
# from PIL import Image хуже распознается
import cv2 
import pytesseract 
import sys 
from pdf2image import convert_from_path 
import os 

# Path of the pdf 
PDF_file = ""FileName.pdf""

''' 
Part #1 : Converting PDF to images 
'''

# Store all the pages of the PDF in a variable 
pages = convert_from_path(PDF_file, 500) 

# Counter to store images of each page of PDF to image 
image_counter = 1

# Iterate through all the pages stored above 
for page in pages: 

	# Declaring filename for each page of PDF as JPG 
	# For each page, filename will be: 
	# PDF page 1 -> page_1.jpg 
	# PDF page 2 -> page_2.jpg 
	# PDF page 3 -> page_3.jpg 
	# .... 
	# PDF page n -> page_n.jpg 
	filename = ""page_""+str(image_counter)+"".jpg""
	
	# Save the image of the page in system 
	page.save(filename, 'JPEG') 

	# Increment the counter to update filename 
	image_counter = image_counter + 1

''' 
Part #2 - Recognizing text from the images using OCR 
'''
# Variable to get count of total number of pages 
filelimit = image_counter-1

# Creating a text file to write the output 
outfile = ""out_text.txt""

# Open the file in append mode so that 
# All contents of all images are added to the same file 
f = open(outfile, ""a"") 

# Iterate from 1 to total number of pages 
for i in range(1, filelimit + 1): 

	# Set filename to recognize text from 
	# Again, these files will be: 
	# page_1.jpg 
	# page_2.jpg 
	# .... 
	# page_n.jpg 
	filename = ""page_""+str(i)+"".jpg""
		
	# Recognize the text as string in image using pytesserct 
	text = str(((pytesseract.image_to_string(cv2.imread(filename),lang = 'eng+rus')))) 

	# The recognized text is stored in variable text 
	# Any string processing may be applied on text 
	# Here, basic formatting has been done: 
	# In many PDFs, at line ending, if a word can't 
	# be written fully, a 'hyphen' is added. 
	# The rest of the word is written in the next line 
	# Eg: This is a sample text this word here GeeksF- 
	# orGeeks is half on first line, remaining on next. 
	# To remove this, we replace every '-\n' to ''. 
	text = text.replace('-\n', '')	 

	# Finally, write the processed text to the file. 
	#with open(fname, ""w"", encoding=""utf-8"") as f:
	f.write(text) 

# Close the file after writing all the text. 
f.close() 

;
# -*- coding: utf-8 -*-
from test import Hello
import argparse
import sys
import socket


def main():
    parser = argparse.ArgumentParser()

    error_msg = ""Invalid Arguments\n\n"" \
                ""Commands: \n"" \
                ""  -t, --test                 Let's test it!\n"" \
                ""       Optional: --name='your_arg'  -   that'll print your string your_arg""


    if len(sys.argv) == 1:
        print(error_msg)

    elif str(sys.argv[1]) in ['-t', '--test']:
        parser.add_argument('-t', '--test', action='store_true')
        parser.add_argument(""--name"", default=socket.gethostname())

        args = parser.parse_args()

        test_class = Hello(args.name)
        test_class.print_hello()

    else:
        print(error_msg)


if __name__ == '__main__':
    main()

;
",4,"[{'SpeechRecognition_2_mp3_to_text.py': ''}, {'TextFromPicture.py': '# Import libraries \n# from PIL import Image хуже распознается\nimport cv2 \nimport pytesseract \nimport sys \nfrom pdf2image import convert_from_path \nimport os \n\n# Path of the pdf \nPDF_file = ""FileName.pdf""\n\n\'\'\' \nPart #1 : Converting PDF to images \n\'\'\'\n\n# Store all the pages of the PDF in a variable \npages = convert_from_path(PDF_file, 500) \n\n# Counter to store images of each page of PDF to image \nimage_counter = 1\n\n# Iterate through all the pages stored above \nfor page in pages: \n\n\t# Declaring filename for each page of PDF as JPG \n\t# For each page, filename will be: \n\t# PDF page 1 -> page_1.jpg \n\t# PDF page 2 -> page_2.jpg \n\t# PDF page 3 -> page_3.jpg \n\t# .... \n\t# PDF page n -> page_n.jpg \n\tfilename = ""page_""+str(image_counter)+"".jpg""\n\t\n\t# Save the image of the page in system \n\tpage.save(filename, \'JPEG\') \n\n\t# Increment the counter to update filename \n\timage_counter = image_counter + 1\n\n\'\'\' \nPart #2 - Recognizing text from the images using OCR \n\'\'\'\n# Variable to get count of total number of pages \nfilelimit = image_counter-1\n\n# Creating a text file to write the output \noutfile = ""out_text.txt""\n\n# Open the file in append mode so that \n# All contents of all images are added to the same file \nf = open(outfile, ""a"") \n\n# Iterate from 1 to total number of pages \nfor i in range(1, filelimit + 1): \n\n\t# Set filename to recognize text from \n\t# Again, these files will be: \n\t# page_1.jpg \n\t# page_2.jpg \n\t# .... \n\t# page_n.jpg \n\tfilename = ""page_""+str(i)+"".jpg""\n\t\t\n\t# Recognize the text as string in image using pytesserct \n\ttext = str(((pytesseract.image_to_string(cv2.imread(filename),lang = \'eng+rus\')))) \n\n\t# The recognized text is stored in variable text \n\t# Any string processing may be applied on text \n\t# Here, basic formatting has been done: \n\t# In many PDFs, at line ending, if a word can\'t \n\t# be written fully, a \'hyphen\' is added. \n\t# The rest of the word is written in the next line \n\t# Eg: This is a sample text this word here GeeksF- \n\t# orGeeks is half on first line, remaining on next. \n\t# To remove this, we replace every \'-\\n\' to \'\'. \n\ttext = text.replace(\'-\\n\', \'\')\t \n\n\t# Finally, write the processed text to the file. \n\t#with open(fname, ""w"", encoding=""utf-8"") as f:\n\tf.write(text) \n\n# Close the file after writing all the text. \nf.close() \n\n;\n'}, {'get-video-stream.py': ''}, {'main.py': '# -*- coding: utf-8 -*-\nfrom test import Hello\nimport argparse\nimport sys\nimport socket\n\n\ndef main():\n    parser = argparse.ArgumentParser()\n\n    error_msg = ""Invalid Arguments\\n\\n"" \\\n                ""Commands: \\n"" \\\n                ""  -t, --test                 Let\'s test it!\\n"" \\\n                ""       Optional: --name=\'your_arg\'  -   that\'ll print your string your_arg""\n\n\n    if len(sys.argv) == 1:\n        print(error_msg)\n\n    elif str(sys.argv[1]) in [\'-t\', \'--test\']:\n        parser.add_argument(\'-t\', \'--test\', action=\'store_true\')\n        parser.add_argument(""--name"", default=socket.gethostname())\n\n        args = parser.parse_args()\n\n        test_class = Hello(args.name)\n        test_class.print_hello()\n\n    else:\n        print(error_msg)\n\n\nif __name__ == \'__main__\':\n    main()\n\n;\n'}]","[{'SpeechRecognition_2_mp3_to_text.py': '# -*- coding: utf-8 -*-\n\n# ### Функции пред- и постобработки\n\nfrom pydub import AudioSegment\nfrom pydub.utils import make_chunks\nimport os\n\nimport speech_recognition as sr\n\n# Перевод из формата mp3 в wav\n\ndef mp3_to_wav(mp3_src, wav_src):\n    sound = AudioSegment.from_mp3(mp3_src)\n    sound.export(wav_src, format=""wav"")\n\n# mp3_to_wav(\'audio\\grob.mp3\', \'audio\\grob.wav\')\n\n\n# Делим аудио (wav) на короткие части, сохраняем в папку tmp_chunks\n\ndef divide_audio(audio_src, chunk_length_ms):\n    audio = AudioSegment.from_file(audio_src, ""wav"") \n    chunks = make_chunks(audio, chunk_length_ms)\n    \n    path = ""tmp_chunks""\n    os.mkdir(path)\n    \n    chunks_src = []\n    for i, chunk in enumerate(chunks):\n        chunk_name = ""tmp_chunks\\chunk{0}.wav"".format(i)\n        chunks_src.append(chunk_name)\n        chunk.export(chunk_name, format=""wav"")\n        \n    return chunks_src\n\n\n# Удаляем папку tmp_chunks с частями аудио\n\ndef delete_tmp_chunks(chunks_src):\n    for chunk in chunks_src:\n        os.remove(chunk)\n    os.rmdir(\'tmp_chunks\')\n\n# Соединяем распознанный по частям текст\n\ndef combine_text(text_array):\n    result_text = \'\'\n    for text in text_array:\n        result_text += text + \' \'\n    return result_text\n\n\n# ### Распознавание речи\n\n# Библиотека SpeechRecognition ( https://pypi.org/project/SpeechRecognition/ )\n# \n# Используется распознавание при помощи Google Speech Recognition\n# \n# Распознавание текста происходит непрерывно, даже когда речи нет, а есть только шум. Если распознать какие-то слова не удается, программа выдает ошибку. Поэтому нужно делить аудио на короткие части и распознавать их отдельно.\n# \n# Список языковых кодов для Google Speech Recognition: https://www.science.co.il/language/Locale-codes.php\n\n\n# Распознавание без учета шума\n\ndef recognize(audio_src):\n    # делим аудио на части\n    chunks_src = divide_audio(audio_src, 3000)\n    # распознаем каждую часть\n    text_array = []\n    for chunk_src in chunks_src:\n        a = sr.AudioFile(chunk_src)\n        with a as source:\n            audio = r.record(source)\n        try:\n            text_array.append(r.recognize_google(audio, language=\'ru\'))\n        except:\n            pass\n    # объединяем распознанные тексты\n    text = combine_text(text_array)\n    # удаляем ненужные файлы\n    delete_tmp_chunks(chunks_src)\n    \n    return text\n\n\n#print(recognize(\'audio/vsyo_idet_po_planu.wav\'))\n\n\n# Распознавание с учетом шума: уровень шума определяется автоматически\n\ndef recognize_with_noise(audio_src):\n    # делим аудио на части\n    chunks_src = divide_audio(audio_src, 3000)\n    # распознаем каждую часть\n    text_array = []\n    for chunk_src in chunks_src:\n        a = sr.AudioFile(chunk_src)\n        #print(\'analyzing \', chunk_src)\n        with a as source:\n            r.adjust_for_ambient_noise(source) # учитываем шум\n            audio = r.record(source)\n        try:\n            text_chunk = r.recognize_google(audio, language=\'ru\')\n            text_array.append(text_chunk)\n            #print(text_chunk)\n        except:\n            pass\n    # объединяем распознанные тексты\n    text = combine_text(text_array)\n    # удаляем ненужные файлы\n    delete_tmp_chunks(chunks_src)\n    \n    return text\n\n#print(recognize_with_noise(\'audio/vsyo_idet_po_planu.wav\'))\n\n# итоговая функция распознавания\n\ndef mp3_to_txt():\n\n    r = sr.Recognizer()\n    mp3_to_wav(\'audio/grob.mp3\', \'audio/grob.wav\')\n    recognize_with_noise(\'audio/grob.wav\')\n\n;\n'}, {'TextFromPicture.py': '# -*- coding: utf-8 -*-\n\n# Import libraries\n# from PIL import Image хуже распознается\nimport cv2 \nimport pytesseract \nimport sys \nfrom pdf2image import convert_from_path \nimport os \n\n# Path of the pdf \nPDF_file = ""FileName.pdf""\n\n\'\'\' \nPart #1 : Converting PDF to images \n\'\'\'\n\n# Store all the pages of the PDF in a variable \npages = convert_from_path(PDF_file, 500) \n\n# Counter to store images of each page of PDF to image \nimage_counter = 1\n\n# Iterate through all the pages stored above \nfor page in pages: \n\n\t# Declaring filename for each page of PDF as JPG \n\t# For each page, filename will be: \n\t# PDF page 1 -> page_1.jpg \n\t# PDF page 2 -> page_2.jpg \n\t# PDF page 3 -> page_3.jpg \n\t# .... \n\t# PDF page n -> page_n.jpg \n\tfilename = ""page_""+str(image_counter)+"".jpg""\n\t\n\t# Save the image of the page in system \n\tpage.save(filename, \'JPEG\') \n\n\t# Increment the counter to update filename \n\timage_counter = image_counter + 1\n\n\'\'\' \nPart #2 - Recognizing text from the images using OCR \n\'\'\'\n# Variable to get count of total number of pages \nfilelimit = image_counter-1\n\n# Creating a text file to write the output \noutfile = ""out_text.txt""\n\n# Open the file in append mode so that \n# All contents of all images are added to the same file \nf = open(outfile, ""a"") \n\n# Iterate from 1 to total number of pages \nfor i in range(1, filelimit + 1): \n\n\t# Set filename to recognize text from \n\t# Again, these files will be: \n\t# page_1.jpg \n\t# page_2.jpg \n\t# .... \n\t# page_n.jpg \n\tfilename = ""page_""+str(i)+"".jpg""\n\t\t\n\t# Recognize the text as string in image using pytesserct \n\ttext = str(((pytesseract.image_to_string(cv2.imread(filename),lang = \'eng+rus\')))) \n\n\t# The recognized text is stored in variable text \n\t# Any string processing may be applied on text \n\t# Here, basic formatting has been done: \n\t# In many PDFs, at line ending, if a word can\'t \n\t# be written fully, a \'hyphen\' is added. \n\t# The rest of the word is written in the next line \n\t# Eg: This is a sample text this word here GeeksF- \n\t# orGeeks is half on first line, remaining on next. \n\t# To remove this, we replace every \'-\\n\' to \'\'. \n\ttext = text.replace(\'-\\n\', \'\')\t \n\n\t# Finally, write the processed text to the file. \n\t#with open(fname, ""w"", encoding=""utf-8"") as f:\n\tf.write(text) \n\n# Close the file after writing all the text. \nf.close() \n\n;\n'}, {'get-video-stream.py': ""#!/usr/bin/env python\nfrom __future__ import unicode_literals, print_function\nimport argparse\nimport ffmpeg\nimport sys\n\n\nparser = argparse.ArgumentParser(description='Generate video thumbnail')\nparser.add_argument('in_filename', help='Input filename')\nparser.add_argument('out_filename', help='Output filename')\nparser.add_argument(\n    '--time', type=int, default=0.1, help='Time offset')\nparser.add_argument(\n    '--width', type=int, default=120,\n    help='Width of output thumbnail (height automatically determined by aspect ratio)')\n\n\ndef generate_thumbnail(in_filename, out_filename, time, width):\n    try:\n        (\n            ffmpeg\n            .input(in_filename, ss=time)\n            .filter('scale', width, -1)\n            .output(out_filename, vframes=1)\n            .overwrite_output()\n            .run(capture_stdout=True, capture_stderr=True)\n        )\n    except ffmpeg.Error as e:\n        print(e.stderr.decode(), file=sys.stderr)\n        sys.exit(1)\n\n\nif __name__ == '__main__':\n    args = parser.parse_args()\n    generate_thumbnail(args.in_filename, args.out_filename, args.time, args.width)\n;\n""}, {'main.py': '# -*- coding: utf-8 -*-\n\nfrom test import Hello\nimport argparse\nimport sys\nimport socket\n\n\ndef main():\n    parser = argparse.ArgumentParser()\n\n    error_msg = ""Invalid Arguments\\n\\n"" \\\n                ""Commands: \\n"" \\\n                ""  -t, --test                 Let\'s test it!\\n"" \\\n                ""       Optional: --name=\'your_arg\'  -   that\'ll print your string your_arg""\n\n\n    if len(sys.argv) == 1:\n        print(error_msg)\n\n    elif str(sys.argv[1]) in [\'-t\', \'--test\']:\n        parser.add_argument(\'-t\', \'--test\', action=\'store_true\')\n        parser.add_argument(""--name"", default=socket.gethostname())\n\n        args = parser.parse_args()\n\n        test_class = Hello(args.name)\n        test_class.print_hello()\n\n    else:\n        print(error_msg)\n\n\nif __name__ == \'__main__\':\n    main()\n\n;\n'}]","{'def': 10, 'class': 0}","{'def': 10, 'class': 0}",[]
